{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8259af8c-5e10-4758-80cb-70e855f9744a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==70.0.0\n",
      "  Using cached setuptools-70.0.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Using cached setuptools-70.0.0-py3-none-any.whl (863 kB)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 71.0.4\n",
      "    Uninstalling setuptools-71.0.4:\n",
      "      Successfully uninstalled setuptools-71.0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-70.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools==70.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bbc77f1-076a-4849-b31b-c31209155c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crewai\n",
      "  Using cached crewai-0.70.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting uvicorn==0.30.1 (from -r ../requirements.txt (line 1))\n",
      "  Using cached uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fastapi==0.110.3 (from -r ../requirements.txt (line 2))\n",
      "  Using cached fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting python-dotenv==1.0.0 (from -r ../requirements.txt (line 3))\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting crewai\n",
      "  Using cached crewai-0.51.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain==0.2.15 (from -r ../requirements.txt (line 5))\n",
      "  Using cached langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-aws==0.1.17 (from -r ../requirements.txt (line 6))\n",
      "  Using cached langchain_aws-0.1.17-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: sqlalchemy==2.0.31 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r ../requirements.txt (line 7)) (2.0.31)\n",
      "Collecting tiktoken==0.7.0 (from -r ../requirements.txt (line 8))\n",
      "  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting pydantic==2.8.2 (from -r ../requirements.txt (line 9))\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting durationpy==0.6 (from -r ../requirements.txt (line 10))\n",
      "  Using cached durationpy-0.6-py3-none-any.whl.metadata (365 bytes)\n",
      "Requirement already satisfied: async-timeout in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r ../requirements.txt (line 11)) (4.0.3)\n",
      "Requirement already satisfied: psycopg2-binary==2.9.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r ../requirements.txt (line 12)) (2.9.9)\n",
      "Collecting anthropic (from -r ../requirements.txt (line 13))\n",
      "  Using cached anthropic-0.36.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting langgraph (from -r ../requirements.txt (line 14))\n",
      "  Using cached langgraph-0.2.38-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: setuptools==70.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r ../requirements.txt (line 15)) (70.0.0)\n",
      "Collecting unstructured (from -r ../requirements.txt (line 16))\n",
      "  Using cached unstructured-0.15.14-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting sentence_transformers (from -r ../requirements.txt (line 17))\n",
      "  Using cached sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: openpyxl in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r ../requirements.txt (line 18)) (3.1.4)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from -r ../requirements.txt (line 19)) (3.8.1)\n",
      "Collecting appdirs<2.0.0,>=1.4.4 (from crewai)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from crewai) (8.1.7)\n",
      "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
      "  Using cached embedchain-0.1.123-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting instructor==1.3.3 (from crewai)\n",
      "  Using cached instructor-1.3.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting json-repair<0.26.0,>=0.25.2 (from crewai)\n",
      "  Using cached json_repair-0.25.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from crewai)\n",
      "  Using cached jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting openai<2.0.0,>=1.13.3 (from crewai)\n",
      "  Using cached openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting regex<2024.0.0,>=2023.12.25 (from crewai)\n",
      "  Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn==0.30.1->-r ../requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn==0.30.1->-r ../requirements.txt (line 1)) (4.12.2)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi==0.110.3->-r ../requirements.txt (line 2))\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.2.15->-r ../requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.2.15->-r ../requirements.txt (line 5)) (3.9.5)\n",
      "Collecting langchain-core<0.3.0,>=0.2.35 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Using cached langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Using cached langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Using cached langsmith-0.1.135-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.2.15->-r ../requirements.txt (line 5)) (1.22.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain==0.2.15->-r ../requirements.txt (line 5)) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting boto3<1.35.0,>=1.34.131 (from langchain-aws==0.1.17->-r ../requirements.txt (line 6))\n",
      "  Using cached boto3-1.34.162-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy==2.0.31->-r ../requirements.txt (line 7)) (3.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic==2.8.2->-r ../requirements.txt (line 9)) (0.7.0)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic==2.8.2->-r ../requirements.txt (line 9))\n",
      "  Using cached pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: psycopg2==2.9.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from psycopg2-binary==2.9.9->-r ../requirements.txt (line 12)) (2.9.9)\n",
      "Collecting docstring-parser<0.17,>=0.16 (from instructor==1.3.3->crewai)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jiter<0.5.0,>=0.4.1 (from instructor==1.3.3->crewai)\n",
      "  Using cached jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from instructor==1.3.3->crewai) (13.7.1)\n",
      "Collecting typer<1.0.0,>=0.9.0 (from instructor==1.3.3->crewai)\n",
      "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic->-r ../requirements.txt (line 13)) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic->-r ../requirements.txt (line 13))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic->-r ../requirements.txt (line 13)) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic->-r ../requirements.txt (line 13)) (1.3.1)\n",
      "Collecting tokenizers>=0.13.0 (from anthropic->-r ../requirements.txt (line 13))\n",
      "  Using cached tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph->-r ../requirements.txt (line 14))\n",
      "  Using cached langgraph_checkpoint-2.0.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph->-r ../requirements.txt (line 14))\n",
      "  Using cached langgraph_sdk-0.1.33-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: chardet in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured->-r ../requirements.txt (line 16)) (5.2.0)\n",
      "Collecting filetype (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Using cached lxml-5.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured->-r ../requirements.txt (line 16)) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured->-r ../requirements.txt (line 16)) (4.12.3)\n",
      "Collecting emoji (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Using cached emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dataclasses-json (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting python-iso639 (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Using cached python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rapidfuzz (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading unstructured_client-0.26.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured->-r ../requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured->-r ../requirements.txt (line 16)) (4.66.4)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured->-r ../requirements.txt (line 16)) (6.0.0)\n",
      "Collecting python-oxmsg (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.11.0 (from sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sentence_transformers->-r ../requirements.txt (line 17)) (1.5.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sentence_transformers->-r ../requirements.txt (line 17)) (1.14.0)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sentence_transformers->-r ../requirements.txt (line 17)) (10.4.0)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openpyxl->-r ../requirements.txt (line 18)) (1.1.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk->-r ../requirements.txt (line 19)) (1.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5)) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic->-r ../requirements.txt (line 13)) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic->-r ../requirements.txt (line 13)) (1.2.2)\n",
      "Collecting botocore<1.35.0,>=1.34.162 (from boto3<1.35.0,>=1.34.131->langchain-aws==0.1.17->-r ../requirements.txt (line 6))\n",
      "  Downloading botocore-1.34.162-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws==0.1.17->-r ../requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws==0.1.17->-r ../requirements.txt (line 6)) (0.10.2)\n",
      "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting chromadb<0.5.0,>=0.4.24 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading cohere-5.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.26.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
      "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
      "  Downloading embedchain-0.1.122-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.6 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting mem0ai<0.2.0,>=0.1.15 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mem0ai-0.1.19-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting posthog<4.0.0,>=3.0.2 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from embedchain<0.2.0,>=0.1.114->crewai) (0.7.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from beautifulsoup4->unstructured->-r ../requirements.txt (line 16)) (2.5)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic->-r ../requirements.txt (line 13)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic->-r ../requirements.txt (line 13)) (1.0.5)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ../requirements.txt (line 17)) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ../requirements.txt (line 17)) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ../requirements.txt (line 17)) (21.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.35->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging>=20.9 (from huggingface-hub>=0.20.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph->-r ../requirements.txt (line 14))\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting httpx-sse>=0.4.0 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph->-r ../requirements.txt (line 14))\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph->-r ../requirements.txt (line 14))\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai) (6.11.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-proto==1.27.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (4.25.4)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.2.15->-r ../requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.2.15->-r ../requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17)) (1.13.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17)) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r ../requirements.txt (line 17))\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langdetect->unstructured->-r ../requirements.txt (line 16)) (1.16.0)\n",
      "Collecting olefile (from python-oxmsg->unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn->sentence_transformers->-r ../requirements.txt (line 17)) (3.5.0)\n",
      "Collecting numpy<2,>=1 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured-client->unstructured->-r ../requirements.txt (line 16)) (42.0.8)\n",
      "Collecting eval-type-backport<0.3.0,>=0.2.0 (from unstructured-client->unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured-client->unstructured->-r ../requirements.txt (line 16)) (1.6.0)\n",
      "INFO: pip is looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unstructured-client (from unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading unstructured_client-0.26.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading unstructured_client-0.25.9-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting deepdiff>=6.0 (from unstructured-client->unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading deepdiff-8.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured-client->unstructured->-r ../requirements.txt (line 16)) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from unstructured-client->unstructured->-r ../requirements.txt (line 16)) (2.9.0)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (6.4.0)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sagemaker<3.0.0,>=2.232.1 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading sagemaker-2.232.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cryptography>=3.1->unstructured-client->unstructured->-r ../requirements.txt (line 16)) (1.16.0)\n",
      "Collecting orderly-set==5.2.2 (from deepdiff>=6.0->unstructured-client->unstructured->-r ../requirements.txt (line 16))\n",
      "  Downloading orderly_set-5.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_api_core-2.21.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting cachetools (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai) (3.19.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain==0.2.15->-r ../requirements.txt (line 5)) (3.0.0)\n",
      "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pandas>=1.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai) (2.2.2)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community<0.3.0,>=0.2.6 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
      "INFO: pip is looking at multiple versions of mem0ai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mem0ai<0.2.0,>=0.1.15 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mem0ai-0.1.18-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading mem0ai-0.1.17-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting neo4j<6.0.0,>=5.23.1 (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading neo4j-5.25.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pytz<2025.0,>=2024.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai) (2024.1)\n",
      "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading qdrant_client-1.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting rank-bm25<0.3.0,>=0.2.2 (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (2.18.0)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.9.0->instructor==1.3.3->crewai)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers->-r ../requirements.txt (line 17)) (1.3.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (2.0.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured->-r ../requirements.txt (line 16)) (2.22)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (4.7.2)\n",
      "Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "INFO: pip is looking at multiple versions of kubernetes to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_experimental-0.3.1.post1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading langchain_experimental-0.3.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading langchain_experimental-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading langchain_experimental-0.0.65-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_experimental-0.0.64-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (0.1.2)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.4.3->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai) (2024.1)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_tools-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (2.2.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.2.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (4.23.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (4.2.2)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.0.4)\n",
      "Collecting sagemaker-mlflow (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.0.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading httptools-0.6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.66.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.65.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_tools-1.64.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai) (4.1.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (0.6.1)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.19.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.70.16)\n",
      "Collecting mlflow>=2.8 (from sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mlflow-2.17.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai) (4.0.0)\n",
      "Collecting mlflow-skinny==2.17.0 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mlflow_skinny-2.17.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.0.3)\n",
      "Collecting graphene<4 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.8.4)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (17.0.0)\n",
      "Collecting gunicorn<24 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading databricks_sdk-0.34.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.8.2)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aniso8601<10,>=8 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.1.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading crewai-0.51.1-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_aws-0.1.17-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading durationpy-0.6-py3-none-any.whl (3.5 kB)\n",
      "Downloading instructor-1.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anthropic-0.36.1-py3-none-any.whl (939 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.8/939.8 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph-0.2.38-py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured-0.15.14-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading boto3-1.34.162-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading embedchain-0.1.122-py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading json_repair-0.25.3-py3-none-any.whl (12 kB)\n",
      "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.0/397.0 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_checkpoint-2.0.1-py3-none-any.whl (22 kB)\n",
      "Downloading langgraph_sdk-0.1.33-py3-none-any.whl (28 kB)\n",
      "Downloading langsmith-0.1.135-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m479.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m839.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m547.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m626.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading lxml-5.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.25.9-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.162-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.11.0-py3-none-any.whl (249 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading langchain_cohere-0.1.9-py3-none-any.whl (35 kB)\n",
      "Downloading langchain_community-0.2.15-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mem0ai-0.1.17-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.5/273.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.21.0-py3-none-any.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.1/239.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.9/341.9 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_experimental-0.0.64-py3-none-any.whl (204 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading neo4j-5.25.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading qdrant_client-1.12.0-py3-none-any.whl (266 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.4/266.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading sagemaker-2.232.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (420 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.0/420.0 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow-2.17.0-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.17.0-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.34.0-py3-none-any.whl (565 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.6/565.6 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading sqlparse-0.5.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: langdetect, pypika\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=968365efd992c913506920c9ee45a7522befe6d83687d154db40333554626da6\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=748004aef822e11a5cbdcfa3f09eec31521cde2168edab4c84026fe146344655\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built langdetect pypika\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, filetype, durationpy, appdirs, aniso8601, websockets, uvloop, uvicorn, typing-inspect, types-requests, triton, tenacity, sqlparse, smmap, shellingham, safetensors, regex, rapidfuzz, python-magic, python-iso639, python-dotenv, pysbd, pyproject_hooks, pypdf, pydantic-core, pyasn1-modules, pulsar-client, proto-plus, portalocker, parameterized, packaging, orjson, orderly-set, opentelemetry-util-http, opentelemetry-proto, olefile, oauthlib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, neo4j, msgpack, mmh3, markdown, Mako, lxml, langdetect, jsonref, jsonpath-python, jsonpatch, json-repair, jiter, humanfriendly, httpx-sse, httptools, grpcio, graphql-core, googleapis-common-protos, google-crc32c, fastavro, emoji, docstring-parser, distro, deprecated, cachetools, bcrypt, backoff, asgiref, watchfiles, tiktoken, starlette, shapely, requests-toolbelt, requests-oauthlib, rank-bm25, python-oxmsg, pydantic, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, huggingface-hub, gunicorn, grpcio-tools, grpcio-status, graphql-relay, gptcache, google-resumable-media, google-auth, gitdb, deepdiff, coloredlogs, chroma-hnswlib, build, botocore, alembic, typer, tokenizers, opentelemetry-semantic-conventions, opentelemetry-instrumentation, openai, onnxruntime, nvidia-cusolver-cu12, langsmith, langgraph-sdk, kubernetes, grpc-google-iam-v1, graphene, google-api-core, gitpython, fastapi, dataclasses-json, databricks-sdk, unstructured-client, transformers, torch, qdrant-client, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-core, instructor, google-cloud-core, boto3, anthropic, unstructured, sentence_transformers, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mlflow-skinny, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langchain-aws, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, mlflow, langgraph, langchain, google-cloud-aiplatform, chromadb, sagemaker-mlflow, langchain-community, sagemaker, mem0ai, langchain-experimental, cohere, langchain-cohere, embedchain, crewai\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.7.24\n",
      "    Uninstalling regex-2024.7.24:\n",
      "      Successfully uninstalled regex-2024.7.24\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.23.3\n",
      "    Uninstalling pydantic_core-2.23.3:\n",
      "      Successfully uninstalled pydantic_core-2.23.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.8\n",
      "    Uninstalling msgpack-1.0.8:\n",
      "      Successfully uninstalled msgpack-1.0.8\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.9.1\n",
      "    Uninstalling pydantic-2.9.1:\n",
      "      Successfully uninstalled pydantic-2.9.1\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.35.16\n",
      "    Uninstalling botocore-1.35.16:\n",
      "      Successfully uninstalled botocore-1.35.16\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.35.16\n",
      "    Uninstalling boto3-1.35.16:\n",
      "      Successfully uninstalled boto3-1.35.16\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.231.0\n",
      "    Uninstalling sagemaker-2.231.0:\n",
      "      Successfully uninstalled sagemaker-2.231.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mkl-fft 1.3.10 requires mkl, which is not installed.\n",
      "awscli 1.34.16 requires botocore==1.35.16, but you have botocore 1.34.162 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.2 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.2 which is incompatible.\n",
      "sphinx 8.0.2 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.3 aniso8601-9.0.1 anthropic-0.36.1 appdirs-1.4.4 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 boto3-1.34.162 botocore-1.34.162 build-1.2.2.post1 cachetools-5.5.0 chroma-hnswlib-0.7.3 chromadb-0.4.24 cohere-5.11.0 coloredlogs-15.0.1 crewai-0.51.1 databricks-sdk-0.34.0 dataclasses-json-0.6.7 deepdiff-8.0.1 deprecated-1.2.14 distro-1.9.0 docstring-parser-0.16 durationpy-0.6 embedchain-0.1.122 emoji-2.14.0 fastapi-0.110.3 fastavro-1.9.7 filetype-1.2.0 flatbuffers-24.3.25 gitdb-4.0.11 gitpython-3.1.43 google-api-core-2.21.0 google-auth-2.35.0 google-cloud-aiplatform-1.70.0 google-cloud-bigquery-3.26.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.5 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.65.0 gptcache-0.1.44 graphene-3.3 graphql-core-3.2.5 graphql-relay-3.2.0 grpc-google-iam-v1-0.13.1 grpcio-1.67.0 grpcio-status-1.62.3 grpcio-tools-1.62.3 gunicorn-23.0.0 httptools-0.6.2 httpx-sse-0.4.0 huggingface-hub-0.25.2 humanfriendly-10.0 instructor-1.3.3 jiter-0.4.2 json-repair-0.25.3 jsonpatch-1.33 jsonpath-python-1.0.6 jsonref-1.1.0 kubernetes-30.1.0 langchain-0.2.15 langchain-aws-0.1.17 langchain-cohere-0.1.9 langchain-community-0.2.15 langchain-core-0.2.41 langchain-experimental-0.0.64 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 langdetect-1.0.9 langgraph-0.2.38 langgraph-checkpoint-2.0.1 langgraph-sdk-0.1.33 langsmith-0.1.135 lxml-5.3.0 markdown-3.7 marshmallow-3.22.0 mem0ai-0.1.17 mlflow-2.17.0 mlflow-skinny-2.17.0 mmh3-5.0.1 monotonic-1.6 msgpack-1.1.0 neo4j-5.25.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 oauthlib-3.2.2 olefile-0.47 onnxruntime-1.16.3 openai-1.51.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-exporter-otlp-proto-http-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orderly-set-5.2.2 orjson-3.10.7 packaging-24.1 parameterized-0.9.0 portalocker-2.10.1 posthog-3.7.0 proto-plus-1.24.0 pulsar-client-3.5.0 pyasn1-modules-0.4.1 pydantic-2.8.2 pydantic-core-2.20.1 pypdf-4.3.1 pypika-0.48.9 pyproject_hooks-1.2.0 pysbd-0.3.4 python-dotenv-1.0.0 python-iso639-2024.4.27 python-magic-0.4.27 python-oxmsg-0.0.1 qdrant-client-1.12.0 rank-bm25-0.2.2 rapidfuzz-3.10.0 regex-2023.12.25 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 safetensors-0.4.5 sagemaker-2.232.2 sagemaker-mlflow-0.1.0 sentence_transformers-3.2.0 shapely-2.0.6 shellingham-1.5.4 smmap-5.0.1 sqlparse-0.5.1 starlette-0.37.2 tenacity-8.5.0 tiktoken-0.7.0 tokenizers-0.20.1 torch-2.4.1 transformers-4.45.2 triton-3.0.0 typer-0.12.5 types-requests-2.32.0.20241016 typing-inspect-0.9.0 unstructured-0.15.14 unstructured-client-0.25.9 uvicorn-0.30.1 uvloop-0.21.0 watchfiles-0.24.0 websockets-13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f962ac21-dc9c-4158-9592-a6765e817c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dotenv\n",
    "assert dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d40a8a48-2ac3-4b8e-9e30-da3066d20b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# Set up the model ID for Claude\n",
    "MODEL_ID3 = \"meta.llama3-8b-instruct-v1:0\"\n",
    "MODEL_ID5 = \"meta.llama3-70b-instruct-v1:0\"\n",
    "#MODEL_ID = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "MODEL_ID4 = \"mistral.mixtral-8x7b-instruct-v0:1\"\n",
    "MODEL_ID2 = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "MODEL_ID = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "\n",
    "# Initialize the ChatBedrock instance\n",
    "llm = ChatBedrock(model_id=MODEL_ID, model_kwargs={'temperature': 0})\n",
    "llm2 = ChatBedrock(model_id=MODEL_ID2, model_kwargs={'temperature': 0})\n",
    "llm3 = ChatBedrock(model_id=MODEL_ID3, model_kwargs={'temperature': 0})\n",
    "llm4 = ChatBedrock(model_id=MODEL_ID, model_kwargs={'temperature': 0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ba608c-fee7-42a4-b6e2-4ef8f36f2439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd6c5f-9b89-45aa-9372-10ea10126b58",
   "metadata": {},
   "source": [
    "### Data Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "179abe68-a1ae-4870-8834-4a515218dd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from sqlalchemy import text\n",
    "from static.util import ENGINE\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_database(query: str) -> str:\n",
    "    \"\"\"Query the PIRLS postgres database and return the results as a string.\n",
    "\n",
    "    Args:\n",
    "        query (str): The SQL query to execute.\n",
    "\n",
    "    Returns:\n",
    "        str: The results of the query as a string, where each row is separated by a newline.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the query is invalid or encounters an exception during execution.\n",
    "    \"\"\"\n",
    "    # lower_query = query.lower()\n",
    "    # record_limiters = ['count', 'where', 'limit', 'distinct', 'having', 'group by']\n",
    "    # if not any(word in lower_query for word in record_limiters):\n",
    "    #     return 'WARNING! The query you are about to perform has no record limitations! In case of large tables and ' \\\n",
    "    #            'joins this will return an incomprehensible output.'\n",
    "\n",
    "    with ENGINE.connect() as connection:\n",
    "        try:\n",
    "            res = connection.execute(text(query))\n",
    "        except Exception as e:\n",
    "            return f'Wrong query, encountered exception {e}.'\n",
    "\n",
    "    max_result_len = 3_000\n",
    "    ret = '\\n'.join(\", \".join(map(str, result)) for result in res)\n",
    "    if len(ret) > max_result_len:\n",
    "        ret = ret[:max_result_len] + '...\\n(results too long. Output truncated.)'\n",
    "\n",
    "    return f'Query: {query}\\nResult: {ret}'\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_possible_answers_to_question(\n",
    "        general_table: Literal['Students', 'Curricula', 'Homes', 'Teachers', 'Schools'],\n",
    "        questionnaire_answers_table: Literal['StudentQuestionnaireAnswers', 'CurriculumQuestionnaireAnswers', 'HomeQuestionnaireAnswers', 'TeacherQuestionnaireAnswers', 'SchoolQuestionnaireAnswers'],\n",
    "        questionnaire_entries_table: Literal['StudentQuestionnaireEntries', 'CurriculumQuestionnaireEntries', 'HomeQuestionnaireEntries', 'TeacherQuestionnaireEntries', 'SchoolQuestionnaireEntries'],\n",
    "        question_code: str\n",
    ") -> str:\n",
    "    \"\"\"Query the database and returns possible answer to a given question\n",
    "\n",
    "    Args:\n",
    "        general_table (str): the generic table related to the question topic. Can be one of: 'Students', 'Curricula', 'Homes', 'Teachers', 'Schools'\n",
    "        questionnaire_answers_table (str): the table related to the `general_table` containing answers.\n",
    "        questionnaire_entries_table (str): the table related to the `general_table` containing all possible questions.\n",
    "        question_code (str): the code of the question the full list of possible answers to is returned.\n",
    "\n",
    "    Returns:\n",
    "        str: The list of all possible answers to the question with the code given in `question_code`.\n",
    "    \"\"\"\n",
    "    entity_id = 'curriculum_id' if general_table.lower() == 'curricula' else f'{general_table.lower()[:-1]}_id'\n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT ATab.Answer\n",
    "        FROM {general_table} AS GTab\n",
    "        JOIN {questionnaire_answers_table} AS ATab ON ATab.{entity_id} = GTab.{entity_id}\n",
    "        JOIN {questionnaire_entries_table} AS ETab ON ETab.Code = ATab.Code\n",
    "        WHERE ETab.Code = '{question_code.replace(\"'\", \"\").replace('\"', '')}'\n",
    "    \"\"\"\n",
    "\n",
    "    with ENGINE.connect() as connection:\n",
    "        try:\n",
    "            res = connection.execute(text(query))\n",
    "        except Exception as e:\n",
    "            return f'Wrong query, encountered exception {e}.'\n",
    "\n",
    "    ret = \"\"\n",
    "    for result in res:\n",
    "        ret += \", \".join(map(str, result)) + \"\\n\"\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_questions_of_given_type(\n",
    "    general_table: Literal['Students', 'Curricula', 'Homes', 'Teachers', 'Schools'],\n",
    "    questionnaire_answers_table: Literal['StudentQuestionnaireAnswers', 'CurriculumQuestionnaireAnswers', 'HomeQuestionnaireAnswers', 'TeacherQuestionnaireAnswers', 'SchoolQuestionnaireAnswers'],\n",
    "    questionnaire_entries_table: Literal['StudentQuestionnaireEntries', 'CurriculumQuestionnaireEntries', 'HomeQuestionnaireEntries', 'TeacherQuestionnaireEntries', 'SchoolQuestionnaireEntries'],\n",
    "    question_type: str\n",
    ") -> str:\n",
    "    \"\"\"Query the database and returns questions of a given type with their codes.\n",
    "\n",
    "        Args:\n",
    "            general_table (str): the generic table related to the question topic. Can be one of: 'Students', 'Curricula', 'Homes', 'Teachers', 'Schools'\n",
    "            questionnaire_answers_table (str): the table related to the `general_table` containing answers.\n",
    "            questionnaire_entries_table (str): the table related to the `general_table` containing all possible questions.\n",
    "            question_type (str): the type of the question group.\n",
    "\n",
    "        Returns:\n",
    "            str: The list of all questions of type specified by `question_type`\n",
    "        \"\"\"\n",
    "    entity_id = 'curriculum_id' if general_table.lower() == 'curricula' else f'{general_table.lower()[:-1]}_id'\n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT ETab.Question, ETab.Code\n",
    "        FROM {general_table} AS GTab\n",
    "        JOIN {questionnaire_answers_table} AS ATab ON ATab.{entity_id} = GTab.{entity_id}\n",
    "        JOIN {questionnaire_entries_table} AS ETab ON ETab.Code = ATab.Code\n",
    "        WHERE ETab.Type = '{question_type.replace(\"'\", \"\").replace('\"', '')}'\n",
    "    \"\"\"\n",
    "\n",
    "    with ENGINE.connect() as connection:\n",
    "        try:\n",
    "            res = connection.execute(text(query))\n",
    "        except Exception as e:\n",
    "            return f'Wrong query, encountered exception {e}.'\n",
    "\n",
    "    questions = []\n",
    "    for question, code in res:\n",
    "        questions.append(f'(Code: {code}) {question}\\n')\n",
    "    return ''.join(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "332ba0e7-adcb-452a-828c-0e0d78653bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [query_database, get_possible_answers_to_question, get_questions_of_given_type]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3797729-ef69-4733-be62-90edb3aa5e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7970e920-016d-4744-86d9-4a959f2be84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Background information to guide the LLM's behavior\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"\"\"\n",
    "            Answer the following question:    \n",
    "            {user_question}\n",
    "\n",
    "            When applicable, search for relevant data in the PIRLS 2021 dataset.\n",
    "\n",
    "            When answering, always:    \n",
    "            - Do not initiate research for topics outside the area of your expertise.     \n",
    "            - Ensure that your dataset queries are accurate and relevant to the research questions.\n",
    "            - Unless instructed otherwise, explain how you come to your conclusions and provide evidence to support your claims with specific data.\n",
    "            - Prioritize specific findings including numbers and percentages in line with best practices in statistics\n",
    "            - Data and numbers should be provided in tables to increase readability.\n",
    "            - Try to go the extra mile for open questions (e.g. correlate data with socioeconomic status, compare across countries within a region, integrate suggestions that you have into your query)\n",
    "\n",
    "            expected_output:\n",
    "            A complete answer to the scientific questions from the domain expert with additional context on correlations and causations.\n",
    "            \n",
    "            You are the Data Engineer for the PIRLS project. \n",
    "            You are an expert PostgreQSL user and have access to the full PIRLS 2021 dataset. \n",
    "            You pride yourself on the quality of your data retrieval and manipulation skills.\n",
    "\n",
    "            You answer all queries with the most relevant data available and an explanation how you found it.\n",
    "            You know that the database has millions of entries. Always limit your queries to return only the necessary data.\n",
    "            If data is not provided in the dataset (e.g. trend data), stop the database search.\n",
    "            Before you make a query, plan ahead and determine first what kind of correlations you want to find. \n",
    "            Reduce the amount of queries to the dataset as much as possible.\n",
    "            NEVER return more than 100 rows of data.\n",
    "            NEVER use the ROUND function. Instead use the CAST function for queries.\n",
    "            For trend only rely on csv input. Don't try to merge the data with data from the database.\n",
    "            You write queries that return the required end results with as few steps as possible. \n",
    "            For example when trying to find a mean you return the mean value, not a list of values. \n",
    "\n",
    "            Ensure that your results follow best practices in statistics (e.g. check for relevancy, percentiles).\n",
    "\n",
    "            ### Trend data by country\n",
    "            Trend data by country is stored as a csv under \"trend_data/pirls_trends.csv\". It uses \";\" as a separator.\n",
    "\n",
    "            ## The PIRLS dataset structure\n",
    "            The data is stored in a PostgreQSL database.\n",
    "\n",
    "            # Schema and explanation\n",
    "            Students\n",
    "            Student_ID: Int (Primary Key) - uniquely identifies student\n",
    "            Country_ID: Int (Foreign Key) - uniquely identifies student's country\n",
    "            School_ID: Int (Foreign Key) - uniquely identifies student's school\n",
    "            Home_ID: Int (Foreign Key) - uniquely identifies student's home\n",
    "\n",
    "            StudentQuestionnaireEntries\n",
    "            Code: String (Primary Key) - uniquely identifies a question\n",
    "            Question: String - the question\n",
    "            Type: String - describes the type of the question\n",
    "\n",
    "            StudentQuestionnaireAnswers\n",
    "            Student_ID: Int (Foreign Key) - references student from the Student table\n",
    "            Code: String (Foreign Key) - references question code from StudentQuestionnaireEntries table\n",
    "            Answer: String - contains the answer to the question\n",
    "\n",
    "            SchoolQuestionnaireEntries\n",
    "            Code: String (Primary Key) - unique code of a question\n",
    "            Question: String - contains content of the question\n",
    "            Type: String - describes a category of a question. There are several questions in each category. The categories are: Instructional Time, Reading in Your School, School Emphasis on Academic Success, School Enrollment and Characteristics, Students’ Literacy Readiness, Principal Experience and Education, COVID-19 Pandemic, Resources and Technology, School Discipline and Safety\n",
    "\n",
    "            SchoolQuestionnaireAnswers\n",
    "            School_ID: Int (Composite Key) - references school from Schools table\n",
    "            Code: String (Composite Key) - references score code from SchoolQuestionnaireEntries table\n",
    "            Answer: String - answer to the question from the school\n",
    "\n",
    "            TeacherQuestionnaireEntries\n",
    "            Code: String (Primary Key)\n",
    "            Question: String\n",
    "            Type: String\n",
    "\n",
    "            TeacherQuestionnaireAnswers\n",
    "            Teacher_ID: Int (Foreign Key) - references teacher from Teachers table\n",
    "            Code: String (Foreign Key) - references score code from TeacherQuestionnaireEntries table\n",
    "            Answer: String - answer to the question from the teacher\n",
    "\n",
    "            HomeQuestionnaireEntries\n",
    "            Code: String (Primary Key)\n",
    "            Question: String\n",
    "            Type: String\n",
    "\n",
    "            HomeQuestionnaireAnswers\n",
    "            Home_ID: Int (Foreign Key)\n",
    "            Code: String (Foreign Key)\n",
    "            Answer: String\n",
    "\n",
    "            CurriculumQuestionnaireEntries\n",
    "            Code: String (Primary Key)\n",
    "            Question: String\n",
    "            Type: String\n",
    "\n",
    "            CurriculumQuestionnaireAnswers\n",
    "            Curriculum_ID: Int (Foreign Key)\n",
    "            Code: String (Foreign Key)\n",
    "            Answer: String\n",
    "\n",
    "            Schools\n",
    "            School_ID: Int (Primary Key) - uniquely identifies a School\n",
    "            Country_ID: Int (Foreign Key) - uniquely identifies a country\n",
    "\n",
    "            Teachers\n",
    "            Teacher_ID: Int (Primary Key) - uniquely identifies a Teacher\n",
    "            School_ID: Int (Foreign Key) - uniquely identifies a School\n",
    "\n",
    "            StudentTeachers\n",
    "            Teacher_ID: Int (Foreign Key)\n",
    "            Student_ID: Int (Foreign Key)\n",
    "\n",
    "            Homes\n",
    "            Home_ID: Int (Primary Key) - uniquely identifies a Home\n",
    "\n",
    "            Curricula\n",
    "            Curriculum_ID: Int (Primary Key)\n",
    "            Country_ID: Int (Foreign Key)\n",
    "\n",
    "            StudentScoreEntries\n",
    "            Code: String (Primary Key) - See below for examples of codes\n",
    "            Name: String\n",
    "            Type: String\n",
    "\n",
    "            StudentScoreResults\n",
    "            Student_ID: Int (Foreign Key) - references student from Students table\n",
    "            Code: String (Foreign Key) - references score code from StudentScoreEntries table\n",
    "            Score: Float - the numeric score for a student\n",
    "\n",
    "            Benchmarks\n",
    "            Benchmark_ID: Int (Primary Key) - uniquely identifies benchmark\n",
    "            Score: Int - the lower bound of the benchmark. Students that are equal to or above this value are of that category\n",
    "            Name: String - name of the category. Possible values are: Intermediate International Benchmark,\n",
    "            Low International Benchmark, High International Benchmark, Advanced International Benchmark\n",
    "\n",
    "            Countries\n",
    "            Country_ID: Int (Primary Key) - uniquely identifies a country\n",
    "            Name: String - full name of the country\n",
    "            Code: String - 3 letter code of the country\n",
    "            Benchmark: Boolean - boolean value saying if the country was a benchmark country. \n",
    "            TestType: String - describes the type of test taken in this country. It's either digital or paper.\n",
    "\n",
    "            # Content & Connections\n",
    "            Generally Entries tables contain questions themselves and Answers tables contain answers to those question. \n",
    "            For example StudentQuestionnaireEntries table contains questions asked in the students' questionnaire and \n",
    "            StudentQuestionnaireAnswers table contains answers to those question.\n",
    "\n",
    "            All those tables usually can be joined using the Code column present in both Entries and Answers.\n",
    "\n",
    "            Example connections:\n",
    "            Students with StudentQuestionnaireAnswers on Student_ID and StudentQuestionnaireAnswers with StudentQuestionnaireEntries on Code.\n",
    "            Schools with SchoolQuestionnaireAnswers on School_ID and SchoolQuestionnaireAnswers with SchoolQuestionnaireEntries on Code.\n",
    "            Teachers with TeacherQuestionnaireAnswers on Teacher_ID and TeacherQuestionnaireAnswers with TeacherQuestionnaireEntries on Code.\n",
    "            Homes with HomeQuestionnaireAnswers on Home_ID and HomeQuestionnaireAnswers with HomeQuestionnaireEntries on Code.\n",
    "            Curricula with CurriculumQuestionnaireAnswers on Home_ID and CurriculumQuestionnaireAnswers with CurriculumQuestionnaireEntries on Code.\n",
    "\n",
    "            In the student evaluation process 5 distinct scores were measured. The measured codes in StudentScoreEntries are:\n",
    "            - ASRREA_avg and ASRREA_std describe the overall reading score average and standard deviation\n",
    "            - ASRLIT_avg and ASRLIT_std describe literary experience score average and standard deviation\n",
    "            - ASRINF_avg and ASRINF_std describe the score average and standard deviation in acquiring and information usage\n",
    "            - ASRIIE_avg and ASRIIE_std describe the score average and standard deviation in interpreting, integrating and evaluating\n",
    "            - ASRRSI_avg and ASRRSI_avg describe the score average and standard deviation in retrieving and straightforward inferencing\n",
    "\n",
    "            Benchmarks table cannot be joined with any other table but it keeps useful information about how to interpret\n",
    "            student score as one of the 4 categories.   \n",
    "\n",
    "            # Example Approach for retrieving COVID-19 related data\n",
    "            1. **Retrieve COVID-19 Related Records**: Start by fetching entries from the `School Questionnaire Entries` table that are associated with the **COVID-19 Pandemic**. This step helps narrow down our focus to pandemic-related questions.\n",
    "            2. **Identify the Relevant Question Code**: After reviewing the questions retrieved in the previous step, identify and note the **Code** for the question that inquires about the number of weeks normal primary school operations were impacted by the COVID-19 Pandemic. This code will be crucial for filtering responses in the next steps.\n",
    "            3. **Filter Responses by Question Code**: With the question code in hand, proceed to filter records in the `School Questionnaire Answers` table. Ensure you're only selecting entries that respond to our identified question regarding the pandemic's impact on school operations.\n",
    "            4. **Extract Unique Answers**: For the final step, refine your query to return only distinct values of **Answer** column from the filtered responses. This will provide a clear view of all unique answers given to the question, offering insights into the varied impacts of the pandemic on schools.\n",
    "\n",
    "            # Examples\n",
    "            1) A students' gender is stored as an answer to one of the questions in StudentQuestionnaireEntries table.\n",
    "            The code of the question is \"ASBG01\" and the answer to this question can be \"Boy\", \"Girl\",\n",
    "            \"nan\", \"<Other>\" or \"Omitted or invalid\".\n",
    "\n",
    "            A simple query that returns the gender for each student can look like this:\n",
    "            ```\n",
    "            SELECT S.Student_ID,\n",
    "               CASE \n",
    "                   WHEN SQA.Answer = 'Boy' THEN 'Male'\n",
    "                   WHEN SQA.Answer = 'Girl' THEN 'Female'\n",
    "               ELSE NULL\n",
    "            END AS \"gender\"\n",
    "            FROM Students AS S\n",
    "            JOIN StudentQuestionnaireAnswers AS SQA ON SQA.Student_ID = S.Student_ID\n",
    "            JOIN StudentQuestionnaireEntries AS SQE ON SQE.Code = SQA.Code\n",
    "            WHERE SQA.Code = 'ASBG01'\n",
    "            ```\n",
    "\n",
    "            2) A simple query that answers the question 'What percentage of students in Egypt reached the Low International Benchmark?' can look like this:\n",
    "            '''\n",
    "            WITH benchmark_score AS (\n",
    "                SELECT Score FROM Benchmarks\n",
    "                WHERE Name = 'Low International Benchmark'\n",
    "            )\n",
    "            SELECT SUM(CASE WHEN SSR.score >= bs.Score THEN 1 ELSE 0 END) / COUNT(*)::float as percentage\n",
    "            FROM Students AS S\n",
    "            JOIN Countries AS C ON C.Country_ID = S.Country_ID\n",
    "            JOIN StudentScoreResults AS SSR ON SSR.Student_ID = S.Student_ID\n",
    "            CROSS JOIN benchmark_score AS bs\n",
    "            WHERE C.Name = 'Egypt' AND SSR.Code = 'ASRREA_avg'\n",
    "            '''\n",
    "\n",
    "            3) A simple query that answers the question 'Which country had an average reading score between 549 and 550 for its students?' can look like this:\n",
    "            '''\n",
    "            SELECT C.Name AS Country\n",
    "            FROM Students as S\n",
    "            JOIN Countries as C ON S.Country_ID = C.Country_ID\n",
    "            JOIN StudentScoreResults SSR ON S.Student_ID = SSR.Student_ID\n",
    "            WHERE SSR.Code = 'ASRREA_avg'\n",
    "            GROUP BY C.Name\n",
    "            HAVING AVG(ssr.Score) BETWEEN 549 AND 550;\n",
    "            '''\n",
    "            \"\"\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Add the system message at the start of the conversation\n",
    "    messages = [system_message] + messages\n",
    "\n",
    "    # Pass the messages to the model\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43628a20-2a51-405a-8d8c-16387ddeb1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the average reading scores for the top 10 countries? Please consider weighted results (e.g. TOTWGT).\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  query_database (toolu_bdrk_0119h4oj6v4qo4tA53gLgqtR)\n",
      " Call ID: toolu_bdrk_0119h4oj6v4qo4tA53gLgqtR\n",
      "  Args:\n",
      "    query: WITH WeightedScores AS (\n",
      "    SELECT \n",
      "        C.Name AS Country,\n",
      "        SUM(SSR.Score * SQA.Answer::float) / SUM(SQA.Answer::float) AS WeightedAvgScore\n",
      "    FROM \n",
      "        Students S\n",
      "    JOIN \n",
      "        Countries C ON S.Country_ID = C.Country_ID\n",
      "    JOIN \n",
      "        StudentScoreResults SSR ON S.Student_ID = SSR.Student_ID\n",
      "    JOIN \n",
      "        StudentQuestionnaireAnswers SQA ON S.Student_ID = SQA.Student_ID\n",
      "    WHERE \n",
      "        SSR.Code = 'ASRREA_avg'\n",
      "        AND SQA.Code = 'TOTWGT'\n",
      "    GROUP BY \n",
      "        C.Name\n",
      ")\n",
      "SELECT \n",
      "    Country,\n",
      "    CAST(WeightedAvgScore AS DECIMAL(10,2)) AS WeightedAvgScore\n",
      "FROM \n",
      "    WeightedScores\n",
      "ORDER BY \n",
      "    WeightedAvgScore DESC\n",
      "LIMIT 10;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: query_database\n",
      "\n",
      "Query: WITH WeightedScores AS (\n",
      "    SELECT \n",
      "        C.Name AS Country,\n",
      "        SUM(SSR.Score * SQA.Answer::float) / SUM(SQA.Answer::float) AS WeightedAvgScore\n",
      "    FROM \n",
      "        Students S\n",
      "    JOIN \n",
      "        Countries C ON S.Country_ID = C.Country_ID\n",
      "    JOIN \n",
      "        StudentScoreResults SSR ON S.Student_ID = SSR.Student_ID\n",
      "    JOIN \n",
      "        StudentQuestionnaireAnswers SQA ON S.Student_ID = SQA.Student_ID\n",
      "    WHERE \n",
      "        SSR.Code = 'ASRREA_avg'\n",
      "        AND SQA.Code = 'TOTWGT'\n",
      "    GROUP BY \n",
      "        C.Name\n",
      ")\n",
      "SELECT \n",
      "    Country,\n",
      "    CAST(WeightedAvgScore AS DECIMAL(10,2)) AS WeightedAvgScore\n",
      "FROM \n",
      "    WeightedScores\n",
      "ORDER BY \n",
      "    WeightedAvgScore DESC\n",
      "LIMIT 10;\n",
      "Result: \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  query_database (toolu_bdrk_01PwUFD89PjSTXCrJcFQmwat)\n",
      " Call ID: toolu_bdrk_01PwUFD89PjSTXCrJcFQmwat\n",
      "  Args:\n",
      "    query: SELECT \n",
      "    C.Name AS Country,\n",
      "    CAST(AVG(SSR.Score) AS DECIMAL(10,2)) AS AvgScore\n",
      "FROM \n",
      "    Students S\n",
      "JOIN \n",
      "    Countries C ON S.Country_ID = C.Country_ID\n",
      "JOIN \n",
      "    StudentScoreResults SSR ON S.Student_ID = SSR.Student_ID\n",
      "WHERE \n",
      "    SSR.Code = 'ASRREA_avg'\n",
      "GROUP BY \n",
      "    C.Name\n",
      "ORDER BY \n",
      "    AvgScore DESC\n",
      "LIMIT 10;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: query_database\n",
      "\n",
      "Query: SELECT \n",
      "    C.Name AS Country,\n",
      "    CAST(AVG(SSR.Score) AS DECIMAL(10,2)) AS AvgScore\n",
      "FROM \n",
      "    Students S\n",
      "JOIN \n",
      "    Countries C ON S.Country_ID = C.Country_ID\n",
      "JOIN \n",
      "    StudentScoreResults SSR ON S.Student_ID = SSR.Student_ID\n",
      "WHERE \n",
      "    SSR.Code = 'ASRREA_avg'\n",
      "GROUP BY \n",
      "    C.Name\n",
      "ORDER BY \n",
      "    AvgScore DESC\n",
      "LIMIT 10;\n",
      "Result: Moscow City, Russian Federation, 599.01\n",
      "Singapore, 583.01\n",
      "Ireland, 578.49\n",
      "Hong Kong SAR, 574.54\n",
      "Russian Federation, 571.96\n",
      "Northern Ireland, 567.03\n",
      "Croatia, 559.34\n",
      "United Kingdom, 556.96\n",
      "United States, 554.77\n",
      "Quebec, Canada, 553.74\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your question about the average reading scores for the top 10 countries, considering weighted results. I'll provide you with the results and explain the approach I took to obtain this information.\n",
      "\n",
      "First, I attempted to calculate the weighted average scores using the TOTWGT (Total Weight) variable. However, the query didn't return any results, which suggests there might be an issue with the data or the way the weights are stored in the database. \n",
      "\n",
      "Given this situation, I proceeded to calculate the unweighted average reading scores for the top 10 countries. Here are the results:\n",
      "\n",
      "| Rank | Country | Average Reading Score |\n",
      "|------|---------|------------------------|\n",
      "| 1 | Moscow City, Russian Federation | 599.01 |\n",
      "| 2 | Singapore | 583.01 |\n",
      "| 3 | Ireland | 578.49 |\n",
      "| 4 | Hong Kong SAR | 574.54 |\n",
      "| 5 | Russian Federation | 571.96 |\n",
      "| 6 | Northern Ireland | 567.03 |\n",
      "| 7 | Croatia | 559.34 |\n",
      "| 8 | United Kingdom | 556.96 |\n",
      "| 9 | United States | 554.77 |\n",
      "| 10 | Quebec, Canada | 553.74 |\n",
      "\n",
      "These results are based on the average ASRREA_avg scores, which represent the overall reading score for each student. \n",
      "\n",
      "A few important points to note:\n",
      "\n",
      "1. Moscow City (Russian Federation) is listed separately from the Russian Federation, likely because it was assessed as a benchmark participant.\n",
      "\n",
      "2. Some entries, like Northern Ireland and Quebec (Canada), appear to be regions rather than countries. This suggests that the PIRLS study sometimes provides data for specific regions within countries.\n",
      "\n",
      "3. The scores range from about 553 to 599, with Moscow City having a notably higher average score than the other top performers.\n",
      "\n",
      "4. The difference between the highest (Moscow City) and the 10th highest (Quebec) is about 45 points, indicating a significant spread even among the top performers.\n",
      "\n",
      "It's important to keep in mind that these are unweighted averages, which means each student's score is given equal importance in the calculation. Weighted averages, had we been able to calculate them, might have provided a slightly different ranking or scores, as they would have accounted for the sampling design and any oversampling of certain populations.\n",
      "\n",
      "For a more comprehensive analysis, it would be beneficial to:\n",
      "\n",
      "1. Investigate why the weighted calculation didn't work and try to resolve that issue.\n",
      "2. Look at the distribution of scores within each country, not just the average.\n",
      "3. Consider other factors that might influence these scores, such as socioeconomic status, urban vs. rural settings, or educational policies in these countries.\n",
      "4. Examine how these results compare to previous PIRLS assessments to identify any trends or significant changes.\n",
      "\n",
      "Is there any specific aspect of these results you'd like me to explore further?\n"
     ]
    }
   ],
   "source": [
    "# example with a single tool call\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"What are the average reading scores for the top 10 countries? Please consider weighted results (e.g. TOTWGT).\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849db08c-e420-4c31-8fca-ae844031466f",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4483624-3a16-40a7-9ea5-dbeb6a9c644e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "\n",
    "@tool\n",
    "def create_quickchart_url(\n",
    "    chart_input: dict\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Sends a POST request to the QuickChart API (https://quickchart.io/chart) to generate a chart, and returns the URL for the created chart.\n",
    "\n",
    "    Args:\n",
    "        chart_input (dict): A dictionary containing the configuration for the chart, including chart type, data, labels, and styling options.\n",
    "\n",
    "    Returns:\n",
    "        str: The URL of the generated chart if the request is successful.\n",
    "             If the request fails, an error message with the status code and response text is returned.\n",
    "\n",
    "    Example of `chart_input`:\n",
    "        {\n",
    "            \"format\": \"svg\",  # Specifies the image format (e.g., 'png' or 'svg')\n",
    "            \"chart\": {\n",
    "                \"type\": \"bar\",  # Type of the chart, such as 'bar', 'line', or 'pie'\n",
    "                \"data\": {\n",
    "                    \"labels\": [\"Income Level\", \"Parental Education\", \"School Funding\"],  # X-axis labels for chart categories\n",
    "                    \"datasets\": [\n",
    "                        {\n",
    "                            \"label\": \"Low Performance\",  # Dataset label for low performance group\n",
    "                            \"data\": [60, 65, 58],  # Corresponding values for the low performance group\n",
    "                            \"backgroundColor\": \"#DA9A8B\"  # Color for the dataset bar (red)\n",
    "                        },\n",
    "                        {\n",
    "                            \"label\": \"Medium Performance\",  # Dataset label for medium performance group\n",
    "                            \"data\": [75, 78, 76],  # Corresponding values for the medium performance group\n",
    "                            \"backgroundColor\": \"#DCBB7C\"  # Color for the dataset bar (orange)\n",
    "                        },\n",
    "                        {\n",
    "                            \"label\": \"High Performance\",  # Dataset label for high performance group\n",
    "                            \"data\": [90, 88, 85],  # Corresponding values for the high performance group\n",
    "                            \"backgroundColor\": \"#4FB293\"  # Color for the dataset bar (green)\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"options\": {\n",
    "                    \"title\": {\n",
    "                        \"display\": True,\n",
    "                        \"text\": \"Reading Scores vs Socioeconomic Factors\"  # Chart title\n",
    "                    },\n",
    "                    \"scales\": {\n",
    "                        \"xAxes\": [{\n",
    "                            \"scaleLabel\": {\n",
    "                                \"display\": True,\n",
    "                                \"labelString\": \"Socioeconomic Factors\"  # Label for the x-axis\n",
    "                            }\n",
    "                        }],\n",
    "                        \"yAxes\": [{\n",
    "                            \"scaleLabel\": {\n",
    "                                \"display\": True,\n",
    "                                \"labelString\": \"Reading Scores\"  # Label for the y-axis\n",
    "                            }\n",
    "                        }]\n",
    "                    },\n",
    "                    \"legend\": {\n",
    "                        \"display\": True,  # Determines if the legend should be displayed\n",
    "                        \"position\": \"bottom\"  # Position of the legend\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    Example usage:\n",
    "        create_quickchart_url(chart_input)\n",
    "\n",
    "    \"\"\"\n",
    "    api_url = 'https://quickchart.io/chart/create'\n",
    "\n",
    "    try:\n",
    "        # Send POST request with the chart input\n",
    "        response = requests.post(api_url, json=chart_input, timeout=10)\n",
    "        response.raise_for_status()  # Raise HTTPError if the response status code is 4xx or 5xx\n",
    "\n",
    "        # Parse the response JSON and extract the chart URL\n",
    "        result = response.json()\n",
    "        if \"url\" in result:\n",
    "            return result[\"url\"]\n",
    "        else:\n",
    "            return \"No URL returned by the QuickChart API.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle any exceptions during the request\n",
    "        return f\"Request to QuickChart API failed: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "22f1218f-8099-4ca9-b6c6-9b45d6c204b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [create_quickchart_url]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "049cb4c8-d3a0-40d8-81d3-9f81c007529c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c1fc9178-13cc-4b05-b7ef-9f54074b84bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Background information to guide the LLM's behavior\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"\"\"\n",
    "            Provide a link to a visualization that helps to answer the following question:    \n",
    "            {user_question}\n",
    "\n",
    "            You are an expert in creating compelling and accurate data visualizations for the Progress in International Reading Literacy Study (PIRLS) project.\n",
    "            Your visualizations are essential for conveying complex data insights in an easily digestible format for both researchers and the public.\n",
    "            You have a strong understanding of statistical principles, chart design, and how to translate raw data into meaningful visuals.\n",
    "            You work closely with the data engineer, writer, and other team members to ensure that the visualizations complement the research findings and provide added value.\n",
    "            You thrive on precision, and you take pride in transforming numbers and datasets into clear, actionable visual stories.\n",
    "            ALWAYS ensure the visualizations are easy to interpret and align with the overall research narrative.\n",
    "            ALWAYS consider the audience when selecting the type of visualization, focusing on clarity and simplicity.\n",
    "            ONLY reply with the url for the visualization.\n",
    "            \n",
    "            Create a visual representation of the data related to the most important research finding:\n",
    "    \n",
    "            The visualization should aim to provide clear insights into the dataset, making complex patterns, trends, or comparisons easy to understand.\n",
    "\n",
    "            When creating the visualization, always:\n",
    "            - Ensure the visual aligns with the overall research narrative and conclusions.\n",
    "            - Choose the most appropriate chart type (e.g., bar chart, line graph, heat map) for the data presented.\n",
    "            - Use clear labels, titles, and legends to make the visualization self-explanatory.\n",
    "            - Simplify the design to avoid overwhelming the viewer with unnecessary details.\n",
    "            \"\"\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Add the system message at the start of the conversation\n",
    "    messages = [system_message] + messages\n",
    "\n",
    "    # Pass the messages to the model\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4cea3795-ec0e-4d6d-b0c5-a1fd6b40101e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which country had a reading score closest to 547 for fourth-grade students in the PIRLS 2021 study?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  create_quickchart_url (toolu_bdrk_017nwFbQ5CNhT8SdKEw6EpLD)\n",
      " Call ID: toolu_bdrk_017nwFbQ5CNhT8SdKEw6EpLD\n",
      "  Args:\n",
      "    chart_input: {'format': 'png', 'chart': {'type': 'bar', 'data': {'labels': ['Singapore', 'Hong Kong SAR', 'Russia', 'Taiwan', 'England', 'Finland', 'Poland', 'Sweden', 'Bulgaria', 'Norway', 'Italy', 'Latvia', 'Hungary', 'Lithuania', 'Australia', 'Czech Republic', 'Austria', 'Denmark', 'Germany', 'Slovenia', 'Canada', 'Croatia', 'Ireland', 'Slovak Republic', 'Israel', 'Portugal', 'Spain', 'Northern Ireland', 'New Zealand', 'France', 'Belgium (Flemish)', 'United Arab Emirates', 'Bahrain', 'Albania', 'Malta', 'Cyprus', 'Georgia', 'North Macedonia', 'Montenegro', 'Serbia', 'Azerbaijan', 'Saudi Arabia', 'Kosovo', 'Iran', 'Oman', 'Kazakhstan', 'Qatar', 'Egypt', 'Morocco', 'South Africa'], 'datasets': [{'label': 'Reading Score', 'data': [587, 573, 567, 559, 558, 555, 549, 544, 542, 541, 537, 532, 532, 530, 525, 524, 524, 524, 524, 522, 520, 519, 517, 514, 510, 504, 504, 504, 503, 501, 501, 501, 499, 497, 495, 492, 488, 486, 485, 485, 472, 466, 453, 428, 418, 401, 398, 378, 358, 288], 'backgroundColor': 'rgba(75, 192, 192, 0.6)', 'borderColor': 'rgba(75, 192, 192, 1)', 'borderWidth': 1}]}, 'options': {'title': {'display': True, 'text': 'PIRLS 2021 Reading Scores for Fourth-Grade Students by Country'}, 'scales': {'xAxes': [{'ticks': {'autoSkip': False, 'maxRotation': 90, 'minRotation': 90}}], 'yAxes': [{'ticks': {'beginAtZero': True}, 'scaleLabel': {'display': True, 'labelString': 'Reading Score'}}]}, 'annotation': {'annotations': [{'type': 'line', 'mode': 'horizontal', 'scaleID': 'y-axis-0', 'value': 547, 'borderColor': 'red', 'borderWidth': 2, 'label': {'content': 'Target Score: 547', 'enabled': True, 'position': 'left'}}]}}}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: create_quickchart_url\n",
      "\n",
      "https://quickchart.io/chart/render/sf-81a255cd-e102-4403-8451-3929ee5bb1e0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n"
     ]
    }
   ],
   "source": [
    "# example with a single tool call\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"Which country had a reading score closest to 547 for fourth-grade students in the PIRLS 2021 study?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1795c37-b383-4933-8bc5-29ef3f966f82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chart_input = {'type': 'bar', 'data': {'labels': ['Hungary', 'Taiwan', 'Sweden', 'Dubai, UAE', 'Finland'], 'datasets': [{'label': 'Average Reading Score', 'data': [545.75, 548.27, 545.72, 545.44, 549.94], 'backgroundColor': 'rgba(54, 162, 235, 0.8)'}, {'label': 'Target Score (547)', 'data': [547, 547, 547, 547, 547], 'type': 'line', 'borderColor': 'rgba(255, 99, 132, 1)', 'borderWidth': 2, 'fill': False}]}, 'options': {'title': {'display': True, 'text': 'Countries with Reading Scores Closest to 547 in PIRLS 2021'}, 'scales': {'yAxes': [{'ticks': {'beginAtZero': False, 'min': 540, 'max': 555}, 'scaleLabel': {'display': True, 'labelString': 'Reading Score'}}], 'xAxes': [{'scaleLabel': {'display': True, 'labelString': 'Country'}}]}, 'legend': {'display': True, 'position': 'bottom'}}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6baafcc-3b5e-4c96-b265-cff9be2f7669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = create_quickchart_url(chart_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d4d737e-d1a5-4df8-96c7-8dc43681ee62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Request to QuickChart API failed: HTTPSConnectionPool(host='quickchart.io', port=443): Read timed out. (read timeout=10)\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddc6d9-b916-4e6f-962c-ed3d1fa462a8",
   "metadata": {},
   "source": [
    "### UNESCO API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33929588-366c-40ab-8019-06d49b17d05b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_unesco_data(indicators: list, geo_units: list, start: str = '2021', end: str = '2021', indicator_metadata: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Sends a GET request to the UNESCO API (https://api.uis.unesco.org/api/public) to retrieve data for multiple indicators.\n",
    "\n",
    "    Args:\n",
    "        indicators (list): A list of indicator codes to query.\n",
    "        geo_units (list): A list of geographic units (countries) to include in the query.\n",
    "        start (str): The start year for the data query. Defaults to '2021'.\n",
    "        end (str): The end year for the data query. Defaults to '2021'.\n",
    "        indicator_metadata (bool, optional): Whether to include indicator metadata in the response. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON response from the UNESCO API if the request is successful.\n",
    "              If the request fails, an error message with the status code and response text is returned.\n",
    "\n",
    "    Example usage:\n",
    "        get_unesco_data(indicators=['XGDP.FSGOV', 'XGDP.EDU'], geo_units=['BRA', 'USA', 'DEU'])\n",
    "    \"\"\"\n",
    "    base_url = 'https://api.uis.unesco.org/api/public/data/indicators'\n",
    "    params = {\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'indicatorMetadata': str(indicator_metadata).lower()\n",
    "    }\n",
    "\n",
    "    # Add indicator parameters\n",
    "    for indicator in indicators:\n",
    "        params.setdefault('indicator', []).append(indicator)\n",
    "\n",
    "    # Add geoUnit parameters\n",
    "    for geo_unit in geo_units:\n",
    "        params.setdefault('geoUnit', []).append(geo_unit)\n",
    "\n",
    "    try:\n",
    "        # Send GET request with the specified parameters\n",
    "        response = requests.get(base_url, params=params, timeout=10)\n",
    "        response.raise_for_status()  # Raise HTTPError if the response status code is 4xx or 5xx\n",
    "\n",
    "        # Parse the response JSON\n",
    "        return response.json()\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle any exceptions during the request\n",
    "        return {\"error\": f\"Request to UNESCO API failed: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "578126c8-dcbb-437e-889f-fa9183d70a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [get_unesco_data]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "add85c03-c779-4e41-8925-6e0f3481a3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3b0a909f-754c-4f2e-80df-2d5e19c3f0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Background information to guide the LLM's behavior\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"\"\"\n",
    "            Answer the following question:    \n",
    "            {user_question}\n",
    "\n",
    "            When applicable, search for relevant data in the UNESCO API.\n",
    "\n",
    "            When answering, always:    \n",
    "            - Do not initiate research for topics outside the area of your expertise.     \n",
    "            - Ensure that your dataset queries are accurate and relevant to the research questions.\n",
    "            - Unless instructed otherwise, explain how you come to your conclusions and provide evidence to support your claims with specific data.\n",
    "            - Relevant words should be highlighted in the output.\n",
    "            - Cite https://data.uis.unesco.org/ as a source within the text as a footnote.\n",
    "            - Prioritize specific findings including numbers and percentages in line with best practices in statistics\n",
    "            - Data and numbers should be provided in tables to increase readability.\n",
    "            - Prioritize your findings based on correlation\n",
    "            - ALWAYS limit your output to the most important finding (1 paragraph). Keep it short!\n",
    "            - \n",
    "            \n",
    "            expected_output:\n",
    "            A complete answer to the scientific questions from the domain expert with additional context on correlations and causations.\n",
    "            \n",
    "            ## RELEVANT INDICATORS\n",
    "            CR.1,\"Completion rate, primary education, both sexes (%)\"\n",
    "            XGDP.FSGOV,\"Government expenditure on education as a percentage of GDP (%)\"\n",
    "            XGDP.FSHH.FFNTR,\"Initial private expenditure on education (household) as a percentage of GDP (%)\"\n",
    "            XUNIT.GDPCAP.1.FSGOV.FFNTR,\"Initial government funding per primary student as a percentage of GDP per capita\"\n",
    "            XUNIT.GDPCAP.02.FSGOV.FFNTR,\"Initial government funding per pre-primary student as a percentage of GDP per capita\"\n",
    "            YADULT.PROFILITERACY,\"Proportion of population achieving at least a fixed level of proficiency in functional literacy skills, both sexes (%)\"\n",
    "            YEARS.FC.COMP.02,\"Number of years of compulsory pre-primary education guaranteed in legal frameworks\"\n",
    "            YEARS.FC.COMP.1T3,\"Number of years of compulsory primary and secondary education guaranteed in legal frameworks\"\n",
    "            TRTP.1,\"Proportion of teachers with the minimum required qualifications in primary education, both sexes (%)\"\n",
    "            TRTP.02,\"Proportion of teachers with the minimum required qualifications in pre-primary education, both sexes (%)\"\n",
    "            TPROFD.1,\"Percentage of teachers in primary education who received in-service training in the last 12 months by type of trained, both sexes\"\n",
    "            TATTRR.1,\"Teacher attrition rate from primary education, both sexes (%)\"\n",
    "            SCHBSP.1.WINFSTUDIS,\"Proportion of primary schools with access to adapted infrastructure and materials for students with disabilities (%)\"\n",
    "            SCHBSP.1.WINTERN,\"Proportion of primary schools with access to Internet for pedagogical purposes (%)\"\n",
    "            SCHBSP.1.WCOMPUT,\"Proportion of primary schools with access to computers for pedagogical purposes (%)\"\n",
    "            SCHBSP.1.WELEC,\"Proportion of primary schools with access to electricity (%)\"\n",
    "            ROFST.1.GPIA.CP,\"Out-of-school rate for children of primary school age, adjusted gender parity index (GPIA)\"\n",
    "            READ.PRIMARY.LANGTEST,\"Proportion of students at the end of primary education achieving at least a minimum proficiency level in reading, spoke the language of the test at home, both sexes (%)\"\n",
    "            READ.PRIMARY,\"Proportion of students at the end of primary education achieving at least a minimum proficiency level in reading, both sexes (%)\"\n",
    "            PREPFUTURE.1.MATH,\"Proportion of children/young people at the age of primary education prepared for the future in mathematics, both sexes (%)\"\n",
    "            PREPFUTURE.1.READ,\"Proportion of children/young people at the age of primary education prepared for the future in reading, both sexes (%)\"\n",
    "            POSTIMUENV,\"Percentage of children under 5 years experiencing positive and stimulating home learning environments, both sexes (%)\"\n",
    "            PER.BULLIED.2,\"Percentage of students experiencing bullying in the last 12 months in lower secondary education, both sexes (%)\"\n",
    "            MATH.PRIMARY,\"Proportion of students at the end of primary education achieving at least a minimum proficiency level in mathematics, both sexes (%)\"\n",
    "            LR.AG15T24,\"Youth literacy rate, population 15-24 years, both sexes (%)\"\n",
    "            FHLANGILP.G2T3,\"Percentage of students in early grades who have their first or home language as language of instruction, both sexes (%)\"\n",
    "            DL,\"Percentage of youth/adults who have achieved at least a minimum level of proficiency in digital literacy skills (%)\"\n",
    "            ADMI.ENDOFPRIM.READ,\" Administration of a nationally-representative learning assessment at the end of primary in reading (number)\"\n",
    "            NY.GDP.MKTP.CD,\"GDP (current US$)\"\n",
    "            NY.GDP.PCAP.CD,\"GDP per capita (current US$)\"\n",
    "            READ.G2.LOWSES,\"Proportion of students in Grade 2 achieving at least a minimum proficiency level in reading, very poor socioeconomic background, both sexes (%)\"\n",
    "            READ.PRIMARY.RURAL,\"Proportion of students at the end of primary education achieving at least a minimum proficiency level in reading, rural areas, both sexes (%)\"\n",
    "            READ.PRIMARY.URBAN,\"Proportion of students at the end of primary education achieving at least a minimum proficiency level in reading, urban areas, both sexes (%)\"\n",
    "            READ.PRIMARY.WPIA,\"Proportion of students at the end of primary education achieving at least a minimum proficiency level in reading, adjusted wealth parity index (WPIA)\"\n",
    "            \n",
    "            \"\"\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Add the system message at the start of the conversation\n",
    "    messages = [system_message] + messages\n",
    "\n",
    "    # Pass the messages to the model\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "737ffeed-c43b-4710-bd4e-4f1acdc2f176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the main drivers for reading performance in DEU?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_unesco_data (toolu_bdrk_01AmBCy36yE3uVAP56P2v7Qr)\n",
      " Call ID: toolu_bdrk_01AmBCy36yE3uVAP56P2v7Qr\n",
      "  Args:\n",
      "    indicators: ['READ.PRIMARY', 'XGDP.FSGOV', 'TRTP.1', 'SCHBSP.1.WINTERN', 'SCHBSP.1.WCOMPUT', 'POSTIMUENV', 'XUNIT.GDPCAP.1.FSGOV.FFNTR']\n",
      "    geo_units: ['DEU']\n",
      "    start: 2015\n",
      "    end: 2021\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_unesco_data\n",
      "\n",
      "{\"hints\": [], \"records\": [{\"indicatorId\": \"READ.PRIMARY\", \"geoUnit\": \"DEU\", \"year\": 2016, \"value\": 94.50744628672335, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"READ.PRIMARY\", \"geoUnit\": \"DEU\", \"year\": 2021, \"value\": 93.5873729906259, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"SCHBSP.1.WCOMPUT\", \"geoUnit\": \"DEU\", \"year\": 2015, \"value\": 78.14476013183594, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"SCHBSP.1.WCOMPUT\", \"geoUnit\": \"DEU\", \"year\": 2016, \"value\": 64.6906967163086, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"SCHBSP.1.WCOMPUT\", \"geoUnit\": \"DEU\", \"year\": 2019, \"value\": 73.46466827392578, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"SCHBSP.1.WCOMPUT\", \"geoUnit\": \"DEU\", \"year\": 2021, \"value\": 53.96931076049805, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XGDP.FSGOV\", \"geoUnit\": \"DEU\", \"year\": 2015, \"value\": 4.85515022277832, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XGDP.FSGOV\", \"geoUnit\": \"DEU\", \"year\": 2016, \"value\": 4.839230060577393, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XGDP.FSGOV\", \"geoUnit\": \"DEU\", \"year\": 2017, \"value\": 4.871829986572266, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XGDP.FSGOV\", \"geoUnit\": \"DEU\", \"year\": 2018, \"value\": 4.979330062866211, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XGDP.FSGOV\", \"geoUnit\": \"DEU\", \"year\": 2019, \"value\": 5.115520000457764, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XGDP.FSGOV\", \"geoUnit\": \"DEU\", \"year\": 2020, \"value\": 5.590380191802979, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XGDP.FSGOV\", \"geoUnit\": \"DEU\", \"year\": 2021, \"value\": 5.45488977432251, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XUNIT.GDPCAP.1.FSGOV.FFNTR\", \"geoUnit\": \"DEU\", \"year\": 2015, \"value\": 17.68191909790039, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XUNIT.GDPCAP.1.FSGOV.FFNTR\", \"geoUnit\": \"DEU\", \"year\": 2016, \"value\": 17.58173942565918, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XUNIT.GDPCAP.1.FSGOV.FFNTR\", \"geoUnit\": \"DEU\", \"year\": 2017, \"value\": 17.48191070556641, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XUNIT.GDPCAP.1.FSGOV.FFNTR\", \"geoUnit\": \"DEU\", \"year\": 2018, \"value\": 17.88187026977539, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XUNIT.GDPCAP.1.FSGOV.FFNTR\", \"geoUnit\": \"DEU\", \"year\": 2019, \"value\": 18.65299987792969, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XUNIT.GDPCAP.1.FSGOV.FFNTR\", \"geoUnit\": \"DEU\", \"year\": 2020, \"value\": 20.19095039367676, \"magnitude\": null, \"qualifier\": null}, {\"indicatorId\": \"XUNIT.GDPCAP.1.FSGOV.FFNTR\", \"geoUnit\": \"DEU\", \"year\": 2021, \"value\": 20.39542007446289, \"magnitude\": null, \"qualifier\": null}], \"indicatorMetadata\": []}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the data from the UNESCO Institute for Statistics[^1], several factors appear to be driving reading performance in Germany (DEU). The **proportion of students achieving at least a minimum proficiency level in reading** at the end of primary education remained relatively high, at **93.59%** in 2021, although it showed a slight decrease from 94.51% in 2016.\n",
      "\n",
      "A key driver of this performance appears to be **government expenditure on education**. The data shows a consistent increase in government spending on education as a percentage of GDP, rising from 4.86% in 2015 to 5.45% in 2021. This increased investment is reflected in the **initial government funding per primary student**, which grew from 17.68% of GDP per capita in 2015 to 20.40% in 2021.\n",
      "\n",
      "However, it's worth noting that the **proportion of primary schools with access to computers for pedagogical purposes** decreased from 78.14% in 2015 to 53.97% in 2021. This decline in technological resources could potentially impact future reading performance if not addressed.\n",
      "\n",
      "[^1]: https://data.uis.unesco.org/\n"
     ]
    }
   ],
   "source": [
    "# example with a single tool call\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"What are the main drivers for reading performance in DEU?\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03c69384-54db-4cc7-8710-e6a821b68589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>regionGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AIA</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALA</td>\n",
       "      <td>Åland Islands</td>\n",
       "      <td>NATIONAL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>WB: Sub-Saharan Africa (IDA &amp; IBRD)</td>\n",
       "      <td>Sub-Saharan Africa (IDA &amp; IBRD)</td>\n",
       "      <td>REGIONAL</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>WB: Sub-Saharan Africa (excluding high income)</td>\n",
       "      <td>Sub-Saharan Africa (excluding high income)</td>\n",
       "      <td>REGIONAL</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>WB: Upper middle income (July 2023)</td>\n",
       "      <td>Upper middle income (July 2023)</td>\n",
       "      <td>REGIONAL</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>WB: Upper middle income (July 2024)</td>\n",
       "      <td>Upper middle income (July 2024)</td>\n",
       "      <td>REGIONAL</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>WB: World</td>\n",
       "      <td>World</td>\n",
       "      <td>REGIONAL</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 id  \\\n",
       "0                                               ABW   \n",
       "1                                               AFG   \n",
       "2                                               AGO   \n",
       "3                                               AIA   \n",
       "4                                               ALA   \n",
       "..                                              ...   \n",
       "470             WB: Sub-Saharan Africa (IDA & IBRD)   \n",
       "471  WB: Sub-Saharan Africa (excluding high income)   \n",
       "472             WB: Upper middle income (July 2023)   \n",
       "473             WB: Upper middle income (July 2024)   \n",
       "474                                       WB: World   \n",
       "\n",
       "                                           name      type regionGroup  \n",
       "0                                         Aruba  NATIONAL         NaN  \n",
       "1                                   Afghanistan  NATIONAL         NaN  \n",
       "2                                        Angola  NATIONAL         NaN  \n",
       "3                                      Anguilla  NATIONAL         NaN  \n",
       "4                                 Åland Islands  NATIONAL         NaN  \n",
       "..                                          ...       ...         ...  \n",
       "470             Sub-Saharan Africa (IDA & IBRD)  REGIONAL          WB  \n",
       "471  Sub-Saharan Africa (excluding high income)  REGIONAL          WB  \n",
       "472             Upper middle income (July 2023)  REGIONAL          WB  \n",
       "473             Upper middle income (July 2024)  REGIONAL          WB  \n",
       "474                                       World  REGIONAL          WB  \n",
       "\n",
       "[475 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(response)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55b7d767-2bc0-49e0-8be7-599b699f81c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pirls_2021_participants = [\n",
    "    \"Australia\", \"Austria\", \"Azerbaijan\", \"Bahrain\", \"Belgium (Flemish)\", \"Belgium (French)\", \"Bulgaria\", \n",
    "    \"Canada\", \"Chile\", \"Chinese Taipei\", \"Croatia\", \"Cyprus\", \"Czech Republic\", \"Denmark\", \"Egypt\", \n",
    "    \"England\", \"Finland\", \"France\", \"Georgia\", \"Germany\", \"Hong Kong SAR\", \"Hungary\", \"Iran\", \"Ireland\", \n",
    "    \"Israel\", \"Italy\", \"Japan\", \"Kazakhstan\", \"Kuwait\", \"Latvia\", \"Lithuania\", \"Macao SAR\", \"Malta\", \n",
    "    \"Morocco\", \"Netherlands\", \"New Zealand\", \"North Macedonia\", \"Norway\", \"Oman\", \"Poland\", \"Portugal\", \n",
    "    \"Qatar\", \"Russian Federation\", \"Saudi Arabia\", \"Serbia\", \"Singapore\", \"Slovak Republic\", \"Slovenia\", \n",
    "    \"South Africa\", \"Spain\", \"Sweden\", \"Turkey\", \"United Arab Emirates\", \"United States\", \"Uzbekistan\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d4bf8aca-e06e-42b5-92ba-f3d04b1ac1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZE</td>\n",
       "      <td>Azerbaijan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BGR</td>\n",
       "      <td>Bulgaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BHR</td>\n",
       "      <td>Bahrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAN</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHL</td>\n",
       "      <td>Chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CYP</td>\n",
       "      <td>Cyprus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DEU</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DNK</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EGY</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ESP</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FIN</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FRA</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GEO</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HRV</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HUN</td>\n",
       "      <td>Hungary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IRL</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISR</td>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ITA</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>JPN</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KAZ</td>\n",
       "      <td>Kazakhstan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KWT</td>\n",
       "      <td>Kuwait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LTU</td>\n",
       "      <td>Lithuania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LVA</td>\n",
       "      <td>Latvia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MAR</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MKD</td>\n",
       "      <td>North Macedonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MLT</td>\n",
       "      <td>Malta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NOR</td>\n",
       "      <td>Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NZL</td>\n",
       "      <td>New Zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>OMN</td>\n",
       "      <td>Oman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PRT</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>QAT</td>\n",
       "      <td>Qatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RUS</td>\n",
       "      <td>Russian Federation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SAU</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SGP</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SRB</td>\n",
       "      <td>Serbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SVN</td>\n",
       "      <td>Slovenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SWE</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>UZB</td>\n",
       "      <td>Uzbekistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ZAF</td>\n",
       "      <td>South Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                  name\n",
       "0   ARE  United Arab Emirates\n",
       "1   AUS             Australia\n",
       "2   AUT               Austria\n",
       "3   AZE            Azerbaijan\n",
       "4   BGR              Bulgaria\n",
       "5   BHR               Bahrain\n",
       "6   CAN                Canada\n",
       "7   CHL                 Chile\n",
       "8   CYP                Cyprus\n",
       "9   DEU               Germany\n",
       "10  DNK               Denmark\n",
       "11  EGY                 Egypt\n",
       "12  ESP                 Spain\n",
       "13  FIN               Finland\n",
       "14  FRA                France\n",
       "15  GEO               Georgia\n",
       "16  HRV               Croatia\n",
       "17  HUN               Hungary\n",
       "18  IRL               Ireland\n",
       "19  ISR                Israel\n",
       "20  ITA                 Italy\n",
       "21  JPN                 Japan\n",
       "22  KAZ            Kazakhstan\n",
       "23  KWT                Kuwait\n",
       "24  LTU             Lithuania\n",
       "25  LVA                Latvia\n",
       "26  MAR               Morocco\n",
       "27  MKD       North Macedonia\n",
       "28  MLT                 Malta\n",
       "29  NOR                Norway\n",
       "30  NZL           New Zealand\n",
       "31  OMN                  Oman\n",
       "32  POL                Poland\n",
       "33  PRT              Portugal\n",
       "34  QAT                 Qatar\n",
       "35  RUS    Russian Federation\n",
       "36  SAU          Saudi Arabia\n",
       "37  SGP             Singapore\n",
       "38  SRB                Serbia\n",
       "39  SVN              Slovenia\n",
       "40  SWE                Sweden\n",
       "41  UZB            Uzbekistan\n",
       "42  ZAF          South Africa"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"name\"].isin(pirls_2021_participants)][[\"id\", \"name\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c0766-185f-400c-8c2d-9a9b2dd06f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
