{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c377f6-1d2b-4c4d-87b7-bc068281daea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crewai\n",
      "  Downloading crewai-0.67.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting uvicorn==0.30.1 (from -r ../requirements.txt (line 1))\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fastapi==0.110.3 (from -r ../requirements.txt (line 2))\n",
      "  Downloading fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting python-dotenv==1.0.0 (from -r ../requirements.txt (line 3))\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting crewai\n",
      "  Downloading crewai-0.51.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain==0.2.15 (from -r ../requirements.txt (line 5))\n",
      "  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-aws==0.1.17 (from -r ../requirements.txt (line 6))\n",
      "  Downloading langchain_aws-0.1.17-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting sqlalchemy==2.0.31 (from -r ../requirements.txt (line 7))\n",
      "  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting tiktoken==0.7.0 (from -r ../requirements.txt (line 8))\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pydantic==2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r ../requirements.txt (line 9)) (2.8.2)\n",
      "Collecting durationpy==0.6 (from -r ../requirements.txt (line 10))\n",
      "  Downloading durationpy-0.6-py3-none-any.whl.metadata (365 bytes)\n",
      "Collecting async-timeout (from -r ../requirements.txt (line 11))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting psycopg2-binary==2.9.9 (from -r ../requirements.txt (line 12))\n",
      "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting anthropic (from -r ../requirements.txt (line 13))\n",
      "  Downloading anthropic-0.36.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting appdirs<2.0.0,>=1.4.4 (from crewai)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from crewai) (8.1.7)\n",
      "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
      "  Downloading embedchain-0.1.123-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting instructor==1.3.3 (from crewai)\n",
      "  Downloading instructor-1.3.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting json-repair<0.26.0,>=0.25.2 (from crewai)\n",
      "  Downloading json_repair-0.25.3-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonref<2.0.0,>=1.1.0 (from crewai)\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting openai<2.0.0,>=1.13.3 (from crewai)\n",
      "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai)\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting regex<2024.0.0,>=2023.12.25 (from crewai)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn==0.30.1->-r ../requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn==0.30.1->-r ../requirements.txt (line 1)) (4.12.2)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi==0.110.3->-r ../requirements.txt (line 2))\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain==0.2.15->-r ../requirements.txt (line 5)) (6.0.1)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading aiohttp-3.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.35 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading langsmith-0.1.132-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain==0.2.15->-r ../requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain==0.2.15->-r ../requirements.txt (line 5)) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting boto3<1.35.0,>=1.34.131 (from langchain-aws==0.1.17->-r ../requirements.txt (line 6))\n",
      "  Downloading boto3-1.34.162-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy==2.0.31->-r ../requirements.txt (line 7))\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic==2.8.2->-r ../requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic==2.8.2->-r ../requirements.txt (line 9)) (2.20.1)\n",
      "Collecting docstring-parser<0.17,>=0.16 (from instructor==1.3.3->crewai)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jiter<0.5.0,>=0.4.1 (from instructor==1.3.3->crewai)\n",
      "  Downloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from instructor==1.3.3->crewai) (13.8.1)\n",
      "Collecting typer<1.0.0,>=0.9.0 (from instructor==1.3.3->crewai)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic->-r ../requirements.txt (line 13)) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic->-r ../requirements.txt (line 13))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic->-r ../requirements.txt (line 13)) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anthropic->-r ../requirements.txt (line 13)) (1.3.1)\n",
      "Collecting tokenizers>=0.13.0 (from anthropic->-r ../requirements.txt (line 13))\n",
      "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5)) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading yarl-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic->-r ../requirements.txt (line 13)) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic->-r ../requirements.txt (line 13)) (1.2.2)\n",
      "Collecting botocore<1.35.0,>=1.34.162 (from boto3<1.35.0,>=1.34.131->langchain-aws==0.1.17->-r ../requirements.txt (line 6))\n",
      "  Downloading botocore-1.34.162-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws==0.1.17->-r ../requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws==0.1.17->-r ../requirements.txt (line 6)) (0.10.2)\n",
      "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from embedchain<0.2.0,>=0.1.114->crewai) (4.12.3)\n",
      "Collecting chromadb<0.5.0,>=0.4.24 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading cohere-5.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.26.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
      "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting embedchain<0.2.0,>=0.1.114 (from crewai)\n",
      "  Downloading embedchain-0.1.122-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.6 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting mem0ai<0.2.0,>=0.1.15 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mem0ai-0.1.19-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting posthog<4.0.0,>=3.0.2 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from embedchain<0.2.0,>=0.1.114->crewai) (0.7.7)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic->-r ../requirements.txt (line 13)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic->-r ../requirements.txt (line 13)) (1.0.5)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.35->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.35->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tqdm>4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from openai<2.0.0,>=1.13.3->crewai) (4.66.4)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai) (6.11.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from opentelemetry-proto==1.27.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai) (4.25.4)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.2.15->-r ../requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.2.15->-r ../requirements.txt (line 5)) (2.2.2)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.0->anthropic->-r ../requirements.txt (line 13))\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain<0.2.0,>=0.1.114->crewai) (2.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.162->boto3<1.35.0,>=1.34.131->langchain-aws==0.1.17->-r ../requirements.txt (line 6)) (2.9.0)\n",
      "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (6.4.0)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sagemaker<3.0.0,>=2.232.1 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading sagemaker-2.232.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_api_core-2.21.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting cachetools (from gptcache<0.2.0,>=0.1.43->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic->-r ../requirements.txt (line 13)) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic->-r ../requirements.txt (line 13)) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai) (3.19.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain==0.2.15->-r ../requirements.txt (line 5)) (3.0.0)\n",
      "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pandas>=1.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai) (1.5.3)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai) (0.9.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.3.0,>=0.2.6->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community<0.3.0,>=0.2.6 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
      "INFO: pip is looking at multiple versions of mem0ai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mem0ai<0.2.0,>=0.1.15 (from embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mem0ai-0.1.18-py3-none-any.whl.metadata (9.9 kB)\n",
      "  Downloading mem0ai-0.1.17-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting neo4j<6.0.0,>=5.23.1 (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading neo4j-5.25.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pytz<2025.0,>=2024.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai) (2024.1)\n",
      "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading qdrant_client-1.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting rank-bm25<0.3.0,>=0.2.2 (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<4.0.0,>=3.0.2->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (2.18.0)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.9.0->instructor==1.3.3->crewai)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.2.15->-r ../requirements.txt (line 5))\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (2.0.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (4.7.2)\n",
      "Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "INFO: pip is looking at multiple versions of kubernetes to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading langchain_experimental-0.3.1.post1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading langchain_experimental-0.3.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading langchain_experimental-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading langchain_experimental-0.0.65-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_experimental-0.0.64-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor==1.3.3->crewai) (0.1.2)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.13.0)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (72.1.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (2.2.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.2.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (4.23.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (4.2.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (6.0.0)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.0.4)\n",
      "Collecting sagemaker-mlflow (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.0.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Mako->alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.114->crewai) (2.1.5)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.66.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.65.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.64.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai) (4.1.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai) (0.6.0)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.19.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.70.16)\n",
      "Collecting mlflow>=2.8 (from sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mlflow-2.16.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->embedchain<0.2.0,>=0.1.114->crewai) (1.3.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai) (4.0.0)\n",
      "Collecting mlflow-skinny==2.16.2 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading mlflow_skinny-2.16.2-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.0.3)\n",
      "Collecting graphene<4 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.9.1)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (17.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.5.1)\n",
      "Requirement already satisfied: scipy<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.14.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.1.4)\n",
      "Collecting gunicorn<24 (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading databricks_sdk-0.34.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.8.2)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (9.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai) (3.5.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading crewai-0.51.1-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading langchain-0.2.15-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_aws-0.1.17-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading durationpy-0.6-py3-none-any.whl (3.5 kB)\n",
      "Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading instructor-1.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading anthropic-0.36.0-py3-none-any.whl (939 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading boto3-1.34.162-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading embedchain-0.1.122-py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading json_repair-0.25.3-py3-none-any.whl (12 kB)\n",
      "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Downloading langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.0/397.0 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.132-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.162-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.11.0-py3-none-any.whl (249 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_cohere-0.1.9-py3-none-any.whl (35 kB)\n",
      "Downloading langchain_community-0.2.15-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mem0ai-0.1.17-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m843.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.6/309.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.5/273.5 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.21.0-py3-none-any.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.1/239.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.9/341.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_experimental-0.0.64-py3-none-any.whl (204 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading neo4j-5.25.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading qdrant_client-1.12.0-py3-none-any.whl (266 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.4/266.4 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading sagemaker-2.232.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow-2.16.2-py3-none-any.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.16.2-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.34.0-py3-none-any.whl (565 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.6/565.6 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading sqlparse-0.5.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m459.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=7827d0945c923036caa2b7ae64e22393cad3e3b934fe5925ecc352b26ba7b204\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, appdirs, wrapt, websockets, uvloop, uvicorn, types-requests, tenacity, sqlparse, smmap, shellingham, shapely, regex, rank-bm25, python-dotenv, pysbd, pyproject_hooks, pypdf, pyasn1-modules, pulsar-client, psycopg2-binary, proto-plus, propcache, portalocker, parameterized, packaging, orjson, opentelemetry-util-http, opentelemetry-proto, oauthlib, neo4j, mypy-extensions, multidict, mmh3, markdown, Mako, jsonref, jsonpatch, json-repair, jiter, humanfriendly, httpx-sse, httptools, grpcio, greenlet, graphql-core, googleapis-common-protos, google-crc32c, frozenlist, fastavro, docstring-parser, distro, chroma-hnswlib, cachetools, bcrypt, backoff, async-timeout, asgiref, aiohappyeyeballs, yarl, watchfiles, typing-inspect, tiktoken, starlette, sqlalchemy, requests-toolbelt, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, marshmallow, huggingface-hub, gunicorn, grpcio-tools, grpcio-status, graphql-relay, gptcache, google-resumable-media, google-auth, gitdb, deprecated, coloredlogs, build, botocore, aiosignal, typer, tokenizers, opentelemetry-api, openai, onnxruntime, langsmith, kubernetes, grpc-google-iam-v1, graphene, google-api-core, gitpython, fastapi, dataclasses-json, databricks-sdk, alembic, aiohttp, qdrant-client, opentelemetry-semantic-conventions, opentelemetry-instrumentation, langchain-core, instructor, google-cloud-core, boto3, anthropic, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-text-splitters, langchain-openai, langchain-aws, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mlflow-skinny, langchain, google-cloud-aiplatform, mlflow, langchain-community, chromadb, sagemaker-mlflow, mem0ai, langchain-experimental, sagemaker, cohere, langchain-cohere, embedchain, crewai\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.35.16\n",
      "    Uninstalling botocore-1.35.16:\n",
      "      Successfully uninstalled botocore-1.35.16\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.35.16\n",
      "    Uninstalling boto3-1.35.16:\n",
      "      Successfully uninstalled boto3-1.35.16\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.231.0\n",
      "    Uninstalling sagemaker-2.231.0:\n",
      "      Successfully uninstalled sagemaker-2.231.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.34.16 requires botocore==1.35.16, but you have botocore 1.34.162 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.5 aiohappyeyeballs-2.4.3 aiohttp-3.10.9 aiosignal-1.3.1 alembic-1.13.3 anthropic-0.36.0 appdirs-1.4.4 asgiref-3.8.1 async-timeout-4.0.3 backoff-2.2.1 bcrypt-4.2.0 boto3-1.34.162 botocore-1.34.162 build-1.2.2.post1 cachetools-5.5.0 chroma-hnswlib-0.7.3 chromadb-0.4.24 cohere-5.11.0 coloredlogs-15.0.1 crewai-0.51.1 databricks-sdk-0.34.0 dataclasses-json-0.6.7 deprecated-1.2.14 distro-1.9.0 docstring-parser-0.16 durationpy-0.6 embedchain-0.1.122 fastapi-0.110.3 fastavro-1.9.7 flatbuffers-24.3.25 frozenlist-1.4.1 gitdb-4.0.11 gitpython-3.1.43 google-api-core-2.21.0 google-auth-2.35.0 google-cloud-aiplatform-1.70.0 google-cloud-bigquery-3.26.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.5 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.65.0 gptcache-0.1.44 graphene-3.3 graphql-core-3.2.4 graphql-relay-3.2.0 greenlet-3.1.1 grpc-google-iam-v1-0.13.1 grpcio-1.66.2 grpcio-status-1.62.3 grpcio-tools-1.62.3 gunicorn-23.0.0 httptools-0.6.1 httpx-sse-0.4.0 huggingface-hub-0.25.2 humanfriendly-10.0 instructor-1.3.3 jiter-0.4.2 json-repair-0.25.3 jsonpatch-1.33 jsonref-1.1.0 kubernetes-30.1.0 langchain-0.2.15 langchain-aws-0.1.17 langchain-cohere-0.1.9 langchain-community-0.2.15 langchain-core-0.2.41 langchain-experimental-0.0.64 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 langsmith-0.1.132 markdown-3.7 marshmallow-3.22.0 mem0ai-0.1.17 mlflow-2.16.2 mlflow-skinny-2.16.2 mmh3-5.0.1 monotonic-1.6 multidict-6.1.0 mypy-extensions-1.0.0 neo4j-5.25.0 oauthlib-3.2.2 onnxruntime-1.16.3 openai-1.51.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-exporter-otlp-proto-http-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.7 packaging-24.1 parameterized-0.9.0 portalocker-2.10.1 posthog-3.7.0 propcache-0.2.0 proto-plus-1.24.0 psycopg2-binary-2.9.9 pulsar-client-3.5.0 pyasn1-modules-0.4.1 pypdf-4.3.1 pypika-0.48.9 pyproject_hooks-1.2.0 pysbd-0.3.4 python-dotenv-1.0.0 qdrant-client-1.12.0 rank-bm25-0.2.2 regex-2023.12.25 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 sagemaker-2.232.2 sagemaker-mlflow-0.1.0 shapely-2.0.6 shellingham-1.5.4 smmap-5.0.1 sqlalchemy-2.0.31 sqlparse-0.5.1 starlette-0.37.2 tenacity-8.5.0 tiktoken-0.7.0 tokenizers-0.20.0 typer-0.12.5 types-requests-2.32.0.20240914 typing-inspect-0.9.0 uvicorn-0.30.1 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.1 wrapt-1.16.0 yarl-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install crewai -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19ca588-14bc-4d46-9086-10b5b8422964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dotenv\n",
    "assert dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e00ba9-af60-43b0-a8b0-748963360371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# Set up the model ID for Claude\n",
    "#MODEL_ID = \"meta.llama3-8b-instruct-v1:0\"\n",
    "#MODEL_ID = \"meta.llama3-70b-instruct-v1:0\"\n",
    "#MODEL_ID = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "#MODEL_ID = \"mistral.mixtral-8x7b-instruct-v0:1\"\n",
    "MODEL_ID2 = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "MODEL_ID = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "\n",
    "# Initialize the ChatBedrock instance\n",
    "llm = ChatBedrock(model_id=MODEL_ID, model_kwargs={'temperature': 0})\n",
    "llm2 = ChatBedrock(model_id=MODEL_ID2, model_kwargs={'temperature': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03bd6269-aef1-4820-afb1-7820de10d09d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Based on the PIRLS 2021 results, COVID-19 generally had a negative impact on reading abilities:\\n\\n1. Overall decline: Many countries saw a decline in average reading scores compared to previous PIRLS cycles.\\n\\n2. Varied impact: The extent of the impact varied across countries, with some experiencing more significant declines than others.\\n\\n3. Learning loss: School closures and disruptions to education likely contributed to learning losses in reading skills.\\n\\n4. Widened gaps: Existing achievement gaps between advantaged and disadvantaged students may have widened in some cases.\\n\\n5. Digital divide: Differences in access to technology and online learning resources during lockdowns potentially exacerbated inequalities.\\n\\nHowever, it's important to note that not all countries experienced declines, and the full long-term impact of COVID-19 on reading abilities is still being studied.\" additional_kwargs={'usage': {'prompt_tokens': 40, 'completion_tokens': 190, 'total_tokens': 230}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'} response_metadata={'usage': {'prompt_tokens': 40, 'completion_tokens': 190, 'total_tokens': 230}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'} id='run-b93b9e5e-20fd-4026-9c28-c6739006864e-0' usage_metadata={'input_tokens': 40, 'output_tokens': 190, 'total_tokens': 230}\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    (\"system\", \"You are a helpful assistant that provides concise information on PIRLS 2021 results.\"),\n",
    "    (\"human\", \"What impact did COVID-19 have on reading abilities?'\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93575cb-b4ff-48ed-91cf-c8383802abf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from crewai import Agent, Crew, Process, Task\n",
    "from crewai.project import agent, crew, task\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2f7d30-2ec1-4f4f-b2b4-451ba8b94c19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DS01_Test_Web_Crawler_Agent.ipynb',\n",
       " 'DS01_EDA.ipynb',\n",
       " 'tools',\n",
       " 'documents',\n",
       " 'tasks_dev.yaml',\n",
       " 'DS01_Test_Agentic_System.ipynb',\n",
       " 'static',\n",
       " '.ipynb_checkpoints',\n",
       " 'agents_dev.yaml']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e77f5bd-0e7c-415c-824f-eca6c49ae709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install 'crewai[tools]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06454e7f-7796-442f-8e38-dd25ba371ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tools.database as db_tools\n",
    "import tools.web_crawl as web_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db685500-24ab-40c6-80ab-e3f1455147f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from crewai import Agent, Crew, Process, Task\n",
    "from crewai.project import CrewBase, agent, crew, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9682e2e0-bacb-476c-b506-3a780d8875bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade36993-35bb-487c-ac0a-0cdd1dfa7423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ec2-user/SageMaker/GDSC/dev')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ROOT = Path('.').resolve()\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82bb7ad2-96af-48c5-8760-1de4c14c52e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@CrewBase\n",
    "class DevPIRLSCrew:\n",
    "    \"\"\"Data Analysis Crew for the GDSC project.\"\"\"\n",
    "    # Load the files from the config directory\n",
    "    agents_config = PROJECT_ROOT / 'agents_dev.yaml'\n",
    "    tasks_config = PROJECT_ROOT / 'tasks_dev.yaml'\n",
    "\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "\n",
    "    def run(self, prompt: str) -> str:\n",
    "        return self.crew().kickoff(inputs={'user_question': prompt}).raw\n",
    "\n",
    "    @agent\n",
    "    def lead_data_analyst(self) -> Agent:\n",
    "        a = Agent(\n",
    "            config=self.agents_config['lead_data_analyst'],\n",
    "            llm=self.llm,\n",
    "            allow_delegation=False,\n",
    "            verbose=True,\n",
    "            tools=[\n",
    "                web_tools.scrape_paragraph_text\n",
    "            ]\n",
    "        )\n",
    "        return a\n",
    "\n",
    "    @agent\n",
    "    def data_engineer(self) -> Agent:\n",
    "        a = Agent(\n",
    "            config=self.agents_config['data_engineer'],\n",
    "            llm=self.llm,\n",
    "            allow_delegation=False,\n",
    "            verbose=True,\n",
    "            tools=[\n",
    "                db_tools.query_database,\n",
    "                db_tools.get_possible_answers_to_question,\n",
    "                db_tools.get_questions_of_given_type\n",
    "            ]\n",
    "        )\n",
    "        return a\n",
    "    \n",
    "    # @agent\n",
    "    # def web_researcher(self) -> Agent:\n",
    "    #     a = Agent(\n",
    "    #         config=self.agents_config['web_researcher'],\n",
    "    #         llm=llm2,\n",
    "    #         allow_delegation=False,\n",
    "    #         verbose=True,\n",
    "    #         tools=[\n",
    "    #             web_tools.find_relevant_links\n",
    "    #         ]\n",
    "    #     )\n",
    "    #     return a\n",
    "    \n",
    "    # @agent\n",
    "    # def report_compiler(self) -> Agent:\n",
    "    #     a = Agent(\n",
    "    #         config=self.agents_config['report_compiler'],\n",
    "    #         llm=self.llm,\n",
    "    #         allow_delegation=False,\n",
    "    #         verbose=True\n",
    "    #     )\n",
    "    #     return a\n",
    "\n",
    "    @task\n",
    "    def answer_question_task(self) -> Task:\n",
    "        t = Task(\n",
    "            config=self.tasks_config['answer_question_task'],\n",
    "            agent=self.data_engineer()\n",
    "        )\n",
    "        return t\n",
    "    \n",
    "    # @task\n",
    "    # def find_relevant_links_task(self) -> Task:\n",
    "    #     t = Task(\n",
    "    #         config=self.tasks_config['find_relevant_links_task'],\n",
    "    #         agent=self.web_researcher()\n",
    "    #     )\n",
    "    #     return t\n",
    "    \n",
    "    @task\n",
    "    def analyze_findings_task(self) -> Task:\n",
    "        t = Task(\n",
    "            config=self.tasks_config['analyze_findings_task'],\n",
    "            agent=self.lead_data_analyst()\n",
    "        )\n",
    "        return t\n",
    "\n",
    "    @crew\n",
    "    def crew(self) -> Crew:\n",
    "        \"\"\"Creates the data analyst crew\"\"\"\n",
    "        return Crew(\n",
    "            agents=self.agents,\n",
    "            tasks=self.tasks,\n",
    "            process=Process.sequential,\n",
    "            verbose=True,\n",
    "            max_iter=5,\n",
    "            cache=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af86f1c4-4a45-4955-9bef-bc4bf94a4d13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m [2024-10-09 22:16:18][DEBUG]: == Working Agent: data engineer\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [2024-10-09 22:16:18][INFO]: == Starting Task: Answer the following question:     Give me a chocolate cake recipe.\n",
      "When applicable, search for relevant data in the PIRLS 2021 dataset.\n",
      "When answering, always:     - Do not initiate research for topics outside the area of your expertise.      - Ensure that your dataset queries are accurate and relevant to the research questions. - Unless instructed otherwise, explain how you come to your conclusions and provide evidence to support your claims with specific data. - Prioritize specific findings including numbers and percentages in line with best practices in statistics - Data and numbers should be provided in tables to increase readability. - Try to go the extra mile for open questions (e.g. correlate data with socioeconomic status, compare across countries within a region, integrate suggestions that you have into your query)\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I apologize, but I cannot provide a chocolate cake recipe or search for it in the PIRLS 2021 dataset. The PIRLS (Progress in International Reading Literacy Study) database contains information about reading literacy achievement and related factors for fourth-grade students. It does not contain any information about recipes or cooking. As a data engineer focused on the PIRLS project, I should clarify that this request is outside the scope of the dataset and my expertise.\n",
      "\n",
      "Final Answer: I apologize, but I cannot provide a chocolate cake recipe or search for it in the PIRLS 2021 dataset. The PIRLS (Progress in International Reading Literacy Study) database is focused on reading literacy achievement for fourth-grade students and related educational factors. It does not contain any information about recipes or cooking.\n",
      "\n",
      "As a data engineer specializing in the PIRLS project, my expertise and the data available to me are limited to educational statistics and reading literacy information. The database includes data on student performance, school characteristics, teaching practices, and home environments as they relate to reading achievement. It does not include culinary information.\n",
      "\n",
      "If you have any questions related to reading literacy, educational practices, or student achievement in fourth-grade reading across different countries, I would be happy to assist you by querying the PIRLS 2021 dataset. For recipe-related inquiries, I recommend consulting cooking websites or cookbooks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [2024-10-09 22:16:26][DEBUG]: == [data engineer\n",
      "] Task output: I apologize, but I cannot provide a chocolate cake recipe or search for it in the PIRLS 2021 dataset. The PIRLS (Progress in International Reading Literacy Study) database is focused on reading literacy achievement for fourth-grade students and related educational factors. It does not contain any information about recipes or cooking.\n",
      "\n",
      "As a data engineer specializing in the PIRLS project, my expertise and the data available to me are limited to educational statistics and reading literacy information. The database includes data on student performance, school characteristics, teaching practices, and home environments as they relate to reading achievement. It does not include culinary information.\n",
      "\n",
      "If you have any questions related to reading literacy, educational practices, or student achievement in fourth-grade reading across different countries, I would be happy to assist you by querying the PIRLS 2021 dataset. For recipe-related inquiries, I recommend consulting cooking websites or cookbooks.\n",
      "\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [2024-10-09 22:16:26][DEBUG]: == Working Agent: PIRLS lead data analyst\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m [2024-10-09 22:16:26][INFO]: == Starting Task: Answer the following question:     Give me a chocolate cake recipe.\n",
      "When answering, always (unless forbidden by the user question):     - Do not reply to topics outside the area of your expertise.      - Ensure that your analysis is accurate and relevant to the research questions. - scrape the PIRLS website for data that is not available in the dataset (e.g. trend data) to find an answer. - Unless instructed otherwise, explain how you come to your conclusions and provide evidence to support your claims with specific data. - Prioritize specific findings from the data engineer in the final output including numbers and percentages - Data and numbers should be provided in tables to increase readability. - Use markdown format for your final answer. - always summarize the findings first in a short TL;DR in the style of brutal simplicity (like a headline in a tabloid) - finish with a sections on further links - highlight the most important word or word group in each sentence by setting them to a bold font (e.g. **important**) - use capital letters for headlines but no heading font - make use of tables to easily summarize the data - use horizontal rules to separate paragraphs - Your answer should not exceed 3 paragraphs. Keep it concise!\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I apologize, but I cannot provide a chocolate cake recipe using the PIRLS dataset or website. This request is completely outside the scope of PIRLS, which focuses on reading literacy achievement for fourth-grade students. I should explain this politely and suggest where the user might find such information instead.\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "TL;DR: **PIRLS can't bake cakes, only analyze reading skills!**\n",
      "\n",
      "🍫 NO CHOCOLATE CAKE HERE\n",
      "\n",
      "I apologize, but as the **PIRLS lead data analyst**, I cannot provide a chocolate cake recipe. The **Progress in International Reading Literacy Study (PIRLS)** focuses exclusively on **fourth-grade reading achievement** and related educational factors. Our dataset contains no information about cooking or baking.\n",
      "\n",
      "🔍 WHERE TO FIND RECIPES\n",
      "\n",
      "For delicious chocolate cake recipes, I recommend checking:\n",
      "\n",
      "- **Cooking websites** like AllRecipes or Food Network\n",
      "- **Baking cookbooks** from your local library\n",
      "- **YouTube tutorials** for visual step-by-step instructions\n",
      "\n",
      "---\n",
      "\n",
      "If you have any questions about **international reading literacy**, **educational practices**, or **student achievement** in fourth-grade reading, I'd be happy to assist using the PIRLS 2021 dataset.\n",
      "\n",
      "📚 FURTHER LINKS\n",
      "\n",
      "- PIRLS 2021 Results: https://pirls2021.org/results\n",
      "- PIRLS Encyclopedia: https://pirls2021.org/encyclopedia/\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[1m\u001b[92m [2024-10-09 22:16:35][DEBUG]: == [PIRLS lead data analyst\n",
      "] Task output: TL;DR: **PIRLS can't bake cakes, only analyze reading skills!**\n",
      "\n",
      "🍫 NO CHOCOLATE CAKE HERE\n",
      "\n",
      "I apologize, but as the **PIRLS lead data analyst**, I cannot provide a chocolate cake recipe. The **Progress in International Reading Literacy Study (PIRLS)** focuses exclusively on **fourth-grade reading achievement** and related educational factors. Our dataset contains no information about cooking or baking.\n",
      "\n",
      "🔍 WHERE TO FIND RECIPES\n",
      "\n",
      "For delicious chocolate cake recipes, I recommend checking:\n",
      "\n",
      "- **Cooking websites** like AllRecipes or Food Network\n",
      "- **Baking cookbooks** from your local library\n",
      "- **YouTube tutorials** for visual step-by-step instructions\n",
      "\n",
      "---\n",
      "\n",
      "If you have any questions about **international reading literacy**, **educational practices**, or **student achievement** in fourth-grade reading, I'd be happy to assist using the PIRLS 2021 dataset.\n",
      "\n",
      "📚 FURTHER LINKS\n",
      "\n",
      "- PIRLS 2021 Results: https://pirls2021.org/results\n",
      "- PIRLS Encyclopedia: https://pirls2021.org/encyclopedia/\n",
      "\n",
      "\u001b[00m\n",
      "TL;DR: **PIRLS can't bake cakes, only analyze reading skills!**\n",
      "\n",
      "🍫 NO CHOCOLATE CAKE HERE\n",
      "\n",
      "I apologize, but as the **PIRLS lead data analyst**, I cannot provide a chocolate cake recipe. The **Progress in International Reading Literacy Study (PIRLS)** focuses exclusively on **fourth-grade reading achievement** and related educational factors. Our dataset contains no information about cooking or baking.\n",
      "\n",
      "🔍 WHERE TO FIND RECIPES\n",
      "\n",
      "For delicious chocolate cake recipes, I recommend checking:\n",
      "\n",
      "- **Cooking websites** like AllRecipes or Food Network\n",
      "- **Baking cookbooks** from your local library\n",
      "- **YouTube tutorials** for visual step-by-step instructions\n",
      "\n",
      "---\n",
      "\n",
      "If you have any questions about **international reading literacy**, **educational practices**, or **student achievement** in fourth-grade reading, I'd be happy to assist using the PIRLS 2021 dataset.\n",
      "\n",
      "📚 FURTHER LINKS\n",
      "\n",
      "- PIRLS 2021 Results: https://pirls2021.org/results\n",
      "- PIRLS Encyclopedia: https://pirls2021.org/encyclopedia/\n"
     ]
    }
   ],
   "source": [
    "pythonCrew = DevPIRLSCrew(llm=llm)\n",
    "\n",
    "print(pythonCrew.run(\"Give me a chocolate cake recipe.\")) # According to the PIRLS 2021 study, how did the COVID pandemic impact students' reading habits? , Are boys or girls most lagging behind in reading abilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8913427a-d100-4a8e-a1fe-e7c6b29c746f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from crewai import Agent, tool\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09d68a12-d305-481b-a38f-cecd1c2353b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_text_from_website(url: str, query: str) -> list:\n",
    "    \"\"\"\n",
    "    Reads all text from the given URL and its subpages, filtering out non-text content,\n",
    "    and finds subpages relevant to the user query.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the website to read text from.\n",
    "        query (str): The user query to search for relevant subpages.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing the text of relevant subpages and their URLs.\n",
    "    \"\"\"\n",
    "    relevant_subpages = []\n",
    "    \n",
    "    def extract_text(soup: BeautifulSoup) -> str:\n",
    "        \"\"\"\n",
    "        Extracts readable text from a BeautifulSoup object, filtering out non-text content.\n",
    "\n",
    "        Args:\n",
    "            soup (BeautifulSoup): The BeautifulSoup object to extract text from.\n",
    "\n",
    "        Returns:\n",
    "            str: The extracted readable text.\n",
    "        \"\"\"\n",
    "        text_elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li'])\n",
    "        text = ' '.join(element.get_text() for element in text_elements)\n",
    "        return text\n",
    "\n",
    "    def find_relevant_subpages(text: str, url: str) -> None:\n",
    "        \"\"\"\n",
    "        Finds subpages relevant to the user query and stores them with their URLs.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to search for relevant subpages.\n",
    "            url (str): The URL of the webpage where the text was found.\n",
    "        \"\"\"\n",
    "        if query.lower() in text.lower():\n",
    "            relevant_subpages.append((text, url))\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    main_text = extract_text(soup)\n",
    "    find_relevant_subpages(main_text, url)\n",
    "    \n",
    "    # Find all links to subpages and read their text\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        subpage_url = urljoin(url, link['href'])\n",
    "        subpage_response = requests.get(subpage_url)\n",
    "        subpage_soup = BeautifulSoup(subpage_response.content, 'html.parser')\n",
    "        subpage_text = extract_text(subpage_soup)\n",
    "        find_relevant_subpages(subpage_text, subpage_url)\n",
    "    \n",
    "    return relevant_subpages\n",
    "\n",
    "# Example usage\n",
    "# url = \"https://example.com\"\n",
    "# query = \"specific topic\"\n",
    "# results = read_text_from_website(url, query)\n",
    "# for text, link in results:\n",
    "#     print(f\"Found subpage: {link}\\nText: {text[:200]}...\\n\")  # Print first 200 characters for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09d16977-2b6a-462a-bb3d-abacdb303472",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 13:01:00,767 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:02,789 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:02,822 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:02,988 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:03,402 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:03,444 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:03,468 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:03,955 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:03,996 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,035 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,079 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,116 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,156 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,201 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,232 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,293 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,332 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,373 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,409 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,557 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,586 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "2024-10-07 13:01:04,620 - 140699525551936 - dammit.py-dammit:615 - WARNING: Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found subpage: https://pirls2021.org/results\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#content\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://timssandpirls.bc.edu/latest-news.html\n",
      "Text: \n",
      "Home \n",
      " \n",
      "About\n",
      "\n",
      "About the center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " \n",
      "TIMSS (current)\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "Advanced\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " \n",
      "PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " \n",
      "Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 - PASEC\n",
      "Rosetta Stone 2019 - ERCE\n",
      "\n",
      " \n",
      "Publications\n",
      " \n",
      "Databases\n",
      " \n",
      "IEA\n",
      " Latest News  The PIRLS 2026 Assessment Frameworks publication is now available as a PDF download For each cycle of PIRLS, the TIMSS & PIRLS International Study Center collaborates with participating countries and international experts to update the frameworks and design.The PIRLS 2026 Assessment Frameworks also incorporates current research on reading curricula, instruction, and assessment. Publication of COVID-19 Research Resources in PIRLS 2021 COVID-19 Research Resources in PIRLS 2021, the second report in the PIRLS Insights series, is now available. This guide for researchers describes how the onset of the COVID-19 pandemic in 2020 impacted PIRLS 2021 and outlines the contextual data related to COVID-19 collected in the study. Read the full report here. Publication of Aspects of Student Well-Being and Reading Achievement in PIRLS 2021 Aspects of Student Well-Being and Reading Achievement in PIRLS 2021 is now available at pirls2021.org/insights. Publication of PIRLS 2021 International Results in Reading PIRLS 2021 International Results in Reading is now available at pirls2021.org/results. The highly anticipated results from the latest cycle of IEA’s PIRLS were released on May 16, 2023 in a live launch hosted by IEA Amsterdam. PIRLS 2021 results present achievement and contextual data from the nearly 60 countries that participated in the 5th cycle of PIRLS. Videos of example texts and items are also available at pirls2021.org Publication of the PIRLS 2021 Encyclopedia: Education Policy and Curriculum in Reading The PIRLS 2021 Encyclopedia: Education Policy and Curriculum in Reading is now available at pirls2021.org/encyclopedia. Describing the education systems and reading curricula in PIRLS 2021 countries, the PIRLS 2021 Encyclopedia is a richly detailed qualitative counterpart to forthcoming PIRLS 2021 international results.  Publication of the TIMSS 2023 Environmental Attitudes and Behaviors Framework The TIMSS 2023 Environmental Attitudes and Behaviors Framework is now available for download from the TIMSS & PIRLS International Study Center website. This document describes the expansion of TIMSS 2023 Context Questionnaires to include information about the environmental attitudes and behaviors of students as well as the environmental practices of parents, teachers, and schools. Publication of TIMSS 2023 Assessment Frameworks The volume containing the TIMSS 2023 Assessment Frameworks is now available for download from the TIMSS & PIRLS International Study Center website. It outlines the mathematics and science topics that will be assessed among fourth and eighth grade students in TIMSS 2023, as well as plans for collecting contextual data and the assessment design. Environmental Awareness in TIMSS 2019 Around the world there has been increasing awareness of the need to protect the environment. To learn what the TIMSS 2019 science assessment tells us about students’ understanding of the environment, the TIMSS & PIRLS International Study Center constructed environmental awareness scales. Watch the video for a summary of the overall results across TIMSS 2019 countries, and for some examples of TIMSS items that relate to human activities that can harm or benefit the environment. Release of Findings from the TIMSS 2019 Problem Solving and Inquiry Tasks On October 27, 2021, the TIMSS & PIRLS International Study Center released Findings from the TIMSS 2019 Problem Solving and Inquiry Tasks. This report expands significantly on student achievement and engagement with the TIMSS 2019 Problem Solving and Inquiry (PSI) Tasks, providing insight into the higher-order mathematics and science skills students demonstrated while working through the interactive tasks and how students navigated through the digital assessment. TIMSS 2023 Preparations Begin Preparations for TIMSS 2023 are well underway. National Research Coordinators (NRCs) convened virtually February 9-12 for the combined 1st/2nd TIMSS 2023 NRC meeting. Over 250 representatives from countries around the world gathered for updates on TIMSS 2023 plans and procedures and to write new TIMSS 2023 mathematics and science items.   TIMSS 2019 International Database Available The TIMSS & PIRLS International Study Center has released the TIMSS 2019 International Database. This publicly available database contains a rich array of fourth and eighth grade achievement and contextual data from the latest TIMSS cycle to support and promote secondary analyses aimed at improving mathematics and science education. The international database comprises student achievement data and student, home, teacher, school, and national context questionnaire data for the 64 countries and 8 benchmarking systems that participated in TIMSS 2019.  Coming December 8: TIMSS 2019 Results The full international report—TIMSS 2019 International Results in Mathematics and Science—will be released on December 8, 2020, at 10am Central European Time at timss2019.org. In addition to detailed results for the TIMSS countries, the report will include infographics highlighting major findings. Videos that summarize major findings will also be released at the same time, on the TIMSS & PIRLS International Study Center website, and will be available on YouTube. Release of the TIMSS 2019 Encyclopedia: Education Policy and Curriculum in Mathematics and Science The TIMSS 2019 Encyclopedia: Education Policy and Curriculum in Mathematics and Science is now available at timssandpirls.bc.edu/timss2019/encyclopedia. The Encyclopedia describes the education systems of the TIMSS 2019 countries, and is an essential qualitative counterpart to the international achievement results. Each participating country has its own chapter in the Encyclopedia, authored by a country representative, which describes various features of the country’s education system.  PIRLS 2021 Countries Prepare for Data Collection On August 3–5, representatives of PIRLS 2021 countries met virtually for the 5th PIRLS 2021 National Research Coordinators (NRCs) Meeting. Originally planned for Warsaw, Poland, the meeting marked the first all-virtual PIRLS NRC meeting. More than 140 representatives from the PIRLS countries attended the meeting, during which they deliberated and discussed the proposed reading passages, items, and questionnaires for the PIRLS 2021 data collection based on recommendations from the Reading Development Group and Questionnaire Development Group. Countries Prepare for Release of TIMSS 2019 Results The 8th TIMSS 2019 National Research Coordinators Meeting was held June 22–25, with more than 140 participants. During this first-ever virtual TIMSS NRC meeting, NRCs prepared for the release of the TIMSS 2019 results on December 8, 2020. The TIMSS 2019 report—TIMSS 2019 International Results in Mathematics and Science—will present student achievement in mathematics and science in the fourth and eighth grades, as well as home and school contexts and classroom contexts for learning in 64 countries and 8 benchmarking systems. PIRLS 2021 Countries Participate in Field Test Scoring Training in Belgrade National Research Coordinators convened in Belgrade, Serbia, from March 1st – March 6th for the 4th National Research Coordinators Meeting for PIRLS 2021. Hosted by Serbia’s Institute for Education Quality and Evaluation and the Ministry of Education, Science and Technological Development, over 130 attendees gathered to prepare for the PIRLS 2021 field test and to train in scoring PIRLS constructed-response items. In Morocco, Countries Review Report Exhibits and Prepare for Next Year’s Release of TIMSS 2019 Results Representatives of the TIMSS countries met in Agadir, Morocco, in December 2019 for the 7th TIMSS 2019 National Research Coordinators Meeting, hosted by the Ministry of National Education, Vocational Training, Higher Education, and Scientific Research. The participants reviewed their preliminary TIMSS 2019 data and draft exhibits for the TIMSS international report, which will be released in December 2020 In Rome, Countries Prepare for PIRLS 2021 Field Test Representatives of the PIRLS countries met in Rome, Italy, in June 2019 for the PIRLS 2021 3rd National Research Coordinators Meeting. The participants reviewed PIRLS 2021 passages, items, scoring guides, draft questionnaires, and survey operations for the field test, which will be conducted in March-April 2020.\n",
      "\n",
      "                    Roberto Ricci, Head of Research at INVALSI, welcomed the attendees to Rome. Spotlight: Italy Italy has participated in PIRLS since the first administration in 2001. In fact, PIRLS was Italy’s first major primary school reading assessment, preceding the inception of its national assessments. “PIRLS was one of the main sources of inspiration for the construction of our national framework,” according to Laura Palmerio, Italy’s National Research Coordinator for PIRLS and TIMSS and Head of the International Surveys Unit at INVALSI. Schools Share Experiences with Debuting eTIMSS on Social Media IEA's eTIMSS is making its global debut with TIMSS 2019. A digital version of TIMSS, eTIMSS provides interactive assignments that are colorful, animated, and dynamic, delivering an engaging and visually attractive assessment experience that can motivate students. Here are some schools from around the world that have shared their experiences with eTIMSS on social media. TIMSS 2019 Countries Train in Constructed Response Scoring in Limassol TIMSS 2019 countries assembled in Limassol, Cyprus, in March to train in scoring constructed response mathematics and science items. The Deputy Director General of Cyprus’ Ministry of Education and Culture, Athina Michailidou, welcomed and addressed more than 200 representatives from 60-plus countries to the TIMSS 2019 6th National Research Coordinators Meeting. PIRLS 2021 Countries Develop Items and Scoring Guides in Taipei City PIRLS 2021 countries gathered in Taipei City, Taiwan, in December to review reading passages and draft achievement items for the field test. The PIRLS 2021 2nd National Research Coordinators Meeting was hosted by Taiwan's National Academy for Educational Research, and Nan-Shyan Chu, Chief Secretary of Taiwan's Ministry of Education, delivered the welcome address.  Spotlight: Taiwan Since 2006, Taiwan has used PIRLS data to inform and shape how reading is taught in schools. Over the next 10 years Taiwan saw reading achievement rise, and in 2016 officials assessed students’ online reading skills with ePIRLS. Hwawei Ko, PIRLS National Research Coordinator since 2006, reflected on how Taiwan used PIRLS results to change the way children learn reading in schools.\n",
      "                   TIMSS Southern Hemisphere Countries Participate In Scoring Training in South Africa Hosted by The Human Sciences Research Council, IEA's TIMSS & PIRLS International Study Center at Boston College conducted training in Cape Town, South Africa, for scoring mathematics and science constructed response items for the TIMSS 2019 Data Collection. Countries Finalize TIMSS 2019 Data Collection Materials in Stockholm TIMSS 2019 countries met in Stockholm, Sweden, to finalize the assessment materials for data collection. The TIMSS 2019 5th National Research Coordinators Meeting was hosted by Skolverket, the National Agency for Education. Representatives of all participating countries spent the week reviewing mathematics and science items and problem solving and inquiry tasks, as well as scoring guides. Spotlight: Sweden With TIMSS 2015, education officials and researchers in Sweden saw the break in mathematics and science trends they had been waiting for. The country has participated in TIMSS since the assessment’s beginnings in 1995, with results that continued to decline each cycle. Officials have been analyzing the wealth of data from TIMSS 2015, and look eagerly toward TIMSS 2019. PIRLS 2021 Reading Development Group Meets in Rotterdam In May 2018, the PIRLS 2021 Reading Development Group (RDG) held its 1st Meeting in Rotterdam, The Netherlands. The RDG reviewed the updated PIRLS 2021 Framework and Item Writing Guidelines, and reviewed and revised literary and informational passages for PIRLS 2021. Explore the PIRLS 2016 Results and Try Taking ePIRLS Yourself With 50 participating countries and 11 benchmarking entities spanning the globe, the PIRLS 2016 International Results in Reading provide a comprehensive picture of how well fourth grade children can read. The 2016 cycle also marked the inauguration of ePIRLS. Try ePIRLS out for yourself — read online texts and navigate through websites before answering questions posed by a teacher avatar. AIR's RISE Webinar Delves into PIRLS & ePIRLS 2016 International Results The webinar by the American Institutes for Research (AIR) explored the reading achievement of fourth grade students across the globe, and examined some United States results and trends in particular. It also featured the results of ePIRLS, an innovative assessment of online reading comprehension. PIRLS Executive Directors Ina V.S. Mullis and Michael O. Martin served as presenters. TIMSS 2019 Countries Train in Item Scoring in Madrid Hosted by the Instituto Nacional de Evaluación Educativa, nearly 200 representatives from the TIMSS 2019 countries met in Madrid, Spain, at the TIMSS 2019 4th National Research Coordinators Meeting. They spent the week training to score mathematics and science constructed-response items. Spotlight: Spain Having participated in TIMSS in 1995, 2011, and 2015, Spain’s education officials are keen on learning more about their students’ achievement by participating in TIMSS and eTIMSS 2019.\n",
      "\n",
      "                    “We’re very happy to participate because we really believe in assessment as a tool to improve our education,” said Carmen Tovar Sánchez, Director of the Instituto Nacional de Evaluación Educativa. In Hamburg, PIRLS 2016 International Database Training and Launching PIRLS 2021 Participating countries concluded PIRLS and ePIRLS 2016 with International Database training, and kicked off PIRLS 2021 by updating the framework and reviewing informational and literary passages and context questionnaires. Looking Back on PIRLS 2016 and Ahead to PIRLS 2021 IEA Hamburg researchers trained PIRLS 2016 countries in the IEA International Database Analyzer, commenting on the possibilities for analyzing PIRLS data. As PIRLS 2021 began, longtime National Research Coordinators reflected on 15 years of PIRLS. PIRLS 2016 Release Held at UNESCO Headquarters in Paris The International Release of PIRLS 2016 and ePIRLS 2016 was held at UNESCO Headquarters in Paris on December 5, 2017. IEA and UNESCO officials delivered opening remarks. Ina V.S. Mullis and Michael O. Martin of the TIMSS & PIRLS International Study Center presented the results of PIRLS and ePIRLS 2016. TIMSS 2019 Countries Review Items and Scoring Guides in Melbourne Representatives from the more than 60 countries in TIMSS 2019 traveled to Melbourne, Australia, in November 2017 to review mathematics and science items and scoring guides together, along with Problem Solving and Inquiry Tasks for eTIMSS 2019. Spotlight: Australia Australia has learned much about its students in the areas of mathematics and science education, with participation stretching to TIMSS' beginnings in 1995. “One of the big benefits of TIMSS is it provides us with background information that we don’t get from any other studies,” said Dr. Sue Thomson of ACER. Denmark Prepares for PIRLS 2016 International Reports As the PIRLS 2016 International Release approaches, Denmark is particularly busy preparing its national report, having opted in on all three fronts — PIRLS, PIRLS Literacy, and ePIRLS. National Research Coordinator Jan Mejding spoke about preparations for the report and what the results mean for Denmark. Italy Analyzes 20 Years of TIMSS Mathematics and Science Trends Italy has participated in IEA’s TIMSS since it was first launched in 1995 and amassed 20 years of achievement trends — the longest of any international educational assessment. For National Research Coordinator Laura Palmerio, the trends provide a wealth of data that can be used to analyze and improve education. PIRLS 2016 Countries Conduct Final Review of Exhibits PIRLS 2016 countries reviewed exhibits and draft international reports at the 8th National Research Coordinators Meeting in Riga, Latvia, in late June. Līga Lejiņa, State Secretary of Latvia's Ministry of Education and Science, addressed the meeting as it opened. Spotlight: Latvia When Latvia participated in the inaugural cycle of PIRLS in 2001, there was surprise and rejoicing over its unexpectedly high achievement. That elation gave way to concern in PIRLS 2006, when gender differences were extremely wide in favor of girls. As Latvia works to improve its national curriculum, education officials are looking to trends in the PIRLS 2016 report to inform their decisions. Coming Soon: Results of PIRLS 2016 and ePIRLS 2016 Mark your calendars for the International Release! Learn more about PIRLS and the debuting ePIRLS assessment of online reading, and what to expect from the reports in December 2017. Here are some key facts and figures, as well as a more in-depth look. TIMSS 2019 Countries Develop Mathematics and Science Items in Hamburg At the TIMSS 2019 2nd National Research Coordinators Meeting in Hamburg, Germany, representatives of participating countries worked together to develop mathematics and science items for the assessment. In Hamburg, TIMSS 2015 International Database Training and Launching TIMSS 2019 Hosted by the IEA in Hamburg, countries concluded TIMSS 2015 and TIMSS Advanced 2015 with International Database training, and kicked off TIMSS 2019 and eTIMSS 2019 with discussions of updating mathematics and science assessments. PIRLS Countries Assemble to Review Exhibits in Agadir Morocco's Ministry of National Education and Vocational Training hosted the PIRLS 2016 7th National Research Coordinators Meeting, attended by representatives of more than 50 countries in Agadir in December.  TIMSS 2015 Release Marks 20 Years of Trends IEA's TIMSS & PIRLS International Study Center at Boston College released the results of TIMSS 2015 and TIMSS Advanced 2015 on November 29, 2016. The release marked 20 years of trends for TIMSS, which was first conducted in 1995. Graduating Into Profession Increasingly Rigorous For Teachers Worldwide, TIMSS 2015 Encyclopedia Finds Across the world, requirements for becoming a teacher have become increasingly stringent and more technology is making its way into curricula and instruction, according to the TIMSS 2015 Encyclopedia, a comprehensive report of worldwide mathematics and science education. In Québec City, Wrapping Up TIMSS and TIMSS Advanced 2015 TIMSS and TIMSS Advanced 2015 entered their final stages as representatives from IEA, the TIMSS & PIRLS International Study Center, and more than 60 participating countries and benchmarking participants met in Québec City to review draft International Reports and exhibits. SMIRC Conducts Scale Anchoring For TIMSS In Seoul The Science and Mathematics Item Review Committee (SMIRC) met in Seoul, Korea, in May to conduct scale anchoring for TIMSS and TIMSS Advanced. SMIRC members reviewed student performance on hundreds of mathematics and science items before writing descriptions of the International Benchmark levels. Coming Soon: Results of of TIMSS 2015 and TIMSS Advanced 2015 Mark your calendars for the International Release! Whether you are new to TIMSS and TIMSS Advanced and their extensive scope, or simply looking ahead to the International Release in November, here are some key facts and figures. PIRLS and ePIRLS Around the World From Canada to Bahrain to Finland and more, Twitter is abuzz as schools participate this spring in PIRLS 2016 and ePIRLS 2016. Take a look at the reading and electronic reading assessments in action at schools across the globe. PIRLS Scoring Training a Success in Hong Kong Representatives of participating PIRLS countries and benchmarking participants convened in Hong Kong SAR from late February to early March. They trained together in scoring the PIRLS 2016 and ePIRLS 2016 assessments, which are now being conducted around the world. Spotlight: Hong Kong SAR Hong Kong SAR has been a success story in reading achievement — following a modest performance in PIRLS 2001, it shot to the top in PIRLS 2006 and stayed there in PIRLS 2011. Dr. Shek Kam Tse of the University of Hong Kong reflected on Hong Kong's path to success and looked ahead to PIRLS 2016. TIMSS Countries Collaborate in Lisbon Representatives from more than 60 participating countries and benchmarking participants met in Lisbon, Portugal. Together, they reviewed exhibits for the TIMSS 2015 and TIMSS Advanced 2015 International Reports and Encyclopedia, and were introduced to eTIMSS and LaNA, IEA's Literacy and Numeracy Assessment. Spotlight: Portugal In a nation that prizes its tradition of learning, educators have seen student achievement rise in recent years but continue to evaluate and seek ways to improve. Dr. João Marôco, of the Instituto de Avaliação Educativa, I.P., shared thoughts on what Portugal has learned from previous assessments, and what his country hopes to learn from TIMSS and PIRLS for 2015 and 2016. A Meeting of the PIRLS Minds in Jyväskylä The PIRLS NRC meeting August 9–14 was a huge success as representatives of participating countries and benchmarking participants gathered in Jyväskylä, Finland, to make final decisions about the contents of the PIRLS 2016 assessment, including PIRLS, PIRLS Literacy, and ePIRLS. Spotlight: Finland PIRLS 2011 showed that Finland is one of the countries with the best readers at the primary level. Education officials and researchers there, however, have not grown complacent. Jouni Välijärvi and and Inga Arffman of the Finnish Institute for Educational Research reflect on PIRLS 2011 findings and eagerly anticipate PIRLS 2016. ePIRLS: From Vision to Reality IEA's ePIRLS—a forward-thinking computer-based extension to PIRLS in 2016—provides an opportunity for countries to examine how well their fourth grade students read, comprehend, interpet, and critique online information. After a successful field test in April 2015, the ePIRLS assessment will be conducted during the 2015–2016 school year. TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                    Tel +1-617-552-1600\n",
      "                    Fax +1-617-552-1203 \n",
      "\n",
      " © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "          International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/encyclopedia\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Encyclopedia PIRLS 2021 Encyclopedia Education Policy and Curriculum in Reading Katherine A. Reynolds, Erin Wry, Ina V.S. Mullis, and Matthias von Davier, Editors Introduction Download Introduction PDF The PIRLS 2021 Encyclopedia: Education Policy and Curriculum in Reading presents a profile of reading and language instruction in PIRLS 2021 countries and benchmarking systems. Representatives from each country and benchmarking participant completed the PIRLS 2021 curriculum questionnaire and prepared a chapter describing the country’s education system and reading curriculum, as well as the educational challenges and innovations arising from the COVID-19 pandemic. Together, the curriculum questionnaire data and country chapters present a concise yet rich portrait of reading education around the world. The PIRLS 2021 countries differ from one another in fundamental ways, including their education systems, and these differences are important to acknowledge when interpreting the PIRLS achievement results. The PIRLS 2021 Encyclopedia provides information about these differences and serves as a more qualitative companion to the PIRLS 2021 student achievement results. For PIRLS 2021, the Encyclopedia also includes information about the COVID-19 pandemic across countries. This important contextual information can be used by researchers, policymakers, and educators in conjunction with the PIRLS 2021 achievement results to inform education policy and curricula around the world. Organization of the PIRLS 2021 Encyclopedia The PIRLS 2021 Encyclopedia includes two different types of data: exhibits showing results from the PIRLS 2021 curriculum questionnaire, and chapters prepared by individual countries and benchmarking participants. Curriculum Questionnaire Exhibits Each cycle of PIRLS includes a curriculum questionnaire to collect background information about language/reading curricula and education policies from each country and benchmarking participant. Data from this questionnaire support the encyclopedia chapters by providing information about these topics in a format that is comparable across countries and benchmarking systems. The PIRLS 2021 Encyclopedia includes ten exhibits presenting information from the curriculum questionnaire about different aspects of countries’ education systems: Exhibit 1: Years of Schooling Exhibit 2: National Policies on Age of School Entry and Promotion Exhibit 3: Official Languages and Languages of Instruction Exhibit 4: Status of the Fourth Grade Language/Reading Curriculum Exhibit 5: Purposes for Reading Emphasized in the Intended Language/Reading Curriculum Exhibit 6: Digital Reading Skills Emphasized in the Intended Language/Reading Curriculum Exhibit 7: Policies/Statements About Digital Literacy in the Language/Reading Curriculum Exhibit 8: Main Preparation Routes and Current Requirements for Fourth Grade Teachers Exhibit 9: Current Requirements for Principals of Schools with Fourth Grade Students Exhibit 10: Level of Government Responsible for Decision-Making During the COVID-19 Pandemic Complete data from the PIRLS 2021 curriculum questionnaire will be available for download in the PIRLS 2021 International Database. Country Chapters Each chapter in the PIRLS 2021 Encyclopedia was written by a representative (or representatives) of a PIRLS 2021 country or benchmarking system, including experts from ministries of education, research institutes, and institutions of higher education, all with extensive knowledge about each country’s education system. Chapters provide more in-depth information about the structure of countries’ education systems, national use and impact of PIRLS results, language/reading curricula, teacher professional development, monitoring student progress in reading, and special reading initiatives. For PIRLS 2021, chapters also include information about countries’ education systems during the COVID-19 pandemic. PIRLS 2021 Countries’ and Benchmarking Participants’ Chapters Demographic and Economic Characteristics of the PIRLS 2021 Countries The PIRLS 2021 countries are geographically and economically diverse, as shown in the following table Selected Characteristics of the PIRLS 2021 Countries. These data are taken primarily from the World Bank’s DataBank, a repository of databases that include a range of economic, education, and human development indicators. The PIRLS 2021 countries vary widely in population size and geographic area. There is also some variation in life expectancy at birth, although this is 70 years or higher in all but one country. Economic indicators, such as the gross national income per capita (in US dollars), also show great variation across countries, ranging from 78,290 USD in Norway to 1,740 USD in Uzbekistan as of June 2022. With respect to public expenditure on education, countries spend anywhere from 2% (Bahrain) to 8% (Denmark, Norway, and Sweden) of their gross domestic product (GDP). Enrollment in primary education is relatively high, with all of the PIRLS 2021 countries having an enrollment rate greater than 80%, and many having an enrollment rate greater than 95%. View Fullscreen PDF Download PDF Highlights from the Curriculum Questionnaire School Entry Policies After entering primary school, children in many of the PIRLS 2021 countries can continue schooling for twelve to thirteen years, although compulsory school often ends after nine or ten years (see Exhibit 1). Children in the PIRLS 2021 countries most often begin primary school at age six, though specific policies differ across countries (for example, some policies state that children start school in the calendar year of their sixth birthday, while others require children to turn six by a particular date). There is some variation in the age at which students begin primary school across countries, with students in some countries beginning primary school at ages four, five, or seven (see Exhibit 2). Most of the PIRLS 2021 countries allow for some parental discretion on when children begin primary school, with policies typically allowing for slightly earlier or later entry depending upon the child’s development. Language of Instruction The PIRLS 2021 countries differ in the variety of languages in which reading instruction is offered for fourth grade students. About one-third of countries offer reading instruction only in the country’s official language(s). The other two-thirds of countries incorporate additional languages into reading instruction through a variety of means, including bilingual instruction that utilizes two languages, instruction in indigenous or other minority languages for particular communities, or allowing local schools to determine the language of instruction based on local language use. In some countries, the language of instruction also differs between public and private schools (see Exhibit 3). Fourth Grade Language/Reading Curriculum A large majority of the PIRLS 2021 countries have a national curriculum for fourth grade language/reading instruction. Reading is often incorporated into language instruction, although a small number of countries treat reading instruction as a separate curriculum area. Many countries’ language/reading curricula were introduced to classrooms within the past ten years, and about half of the PIRLS 2021 countries are currently revising their language/reading curricula (see Exhibit 4). About half of the PIRLS 2021 countries’ curricula specify a specific percentage of instructional time to be devoted to reading; among these, two-thirds of the countries’ curricula specify that 25 percent of instructional time or more should be devoted to reading instruction.\n",
      "Most countries’ fourth grade language/reading curricula place at least some emphasis on four broad purposes of reading: improving reading skills and comprehension, literary experience, acquiring information, and enjoyment. Twenty-seven countries place a major emphasis on all four of these purposes (see Exhibit 5). About two-thirds of the PIRLS 2021 countries’ curricula place some emphasis on at least one of the following three digital reading skills: 1) strategies for reading digital texts, 2) looking up information to research a topic online, and 3) critical evaluation of information on websites (see Exhibit 6). This finding is similar to PIRLS 2016. In addition, about half of the PIRLS 2021 countries have explicit statements about digital literacy in their fourth grade language/reading curricula. Of these, the majority also have one or more of the following: specific student goals or standards for digital literacy; recommendations or mandates for specific digital literacy curricular resources; recommendations or mandates for using digital devices in reading instruction; and safety or privacy requirements for use of digital devices (see Exhibit 7). Teacher and Principal Preparation A large majority of PIRLS 2021 countries require a university degree to become a teacher at the fourth grade. Many countries have additional teacher preparation routes that are common, including a specialized teaching program following a separate degree, a graduate degree, or a teacher’s college or normal school degree. As was the case in PIRLS 2016, the majority of PIRLS 2021 countries require that prospective teachers complete a supervised practicum during their teacher preparation program, although the length of this practicum varies across countries. Over half of the PIRLS 2021 countries require passing a qualifying exam, completion of a probationary teaching period or completion of a mentoring or induction program for new teachers of fourth grade students (see Exhibit 8). Requiring completion of a mentoring or induction program for new teachers, in particular, has become more popular among the PIRLS countries since 2016. The majority of PIRLS 2021 countries require that principals of schools with fourth grade students have teaching experience. Over half of the countries require completion of a specialized school leadership training program (see Exhibit 9). COVID-19 Pandemic Across the PIRLS 2021 countries, different authorities were responsible for different types of decisions related to the operation of schools during the COVID-19 pandemic. In over two-thirds of the PIRLS 2021 countries, decisions about closing or reopening schools were made at the national level, especially in the early part of the pandemic. In other countries, these decisions were made at the state/provincial or local levels. There was more variation across countries in the authority responsible for determining the format of remote instruction when schools were closed. In about one-third of the PIRLS 2021 countries, decisions about the format of remote instruction were made by individual schools, while in another third of the countries, these decisions were made at the national level. Decisions about the format of remote instruction were made at the state/provincial or local levels for the remaining countries. For many countries, there was considerable overlap in decision-making responsibility, with both national and local input for decisions about opening and closing schools, particularly as the pandemic progressed (see Exhibit 10). Highlights from the Country Chapters Reading Curricula in the PIRLS 2021 Countries Improving children’s reading skills is a high priority across the PIRLS 2021 countries, with many countries having national strategies to promote literacy development (e.g., the Language Council Reading Comprehension in Belgium’s Flemish region, Croatia’s National Strategy to Revive Book Reading). Countries’ language/reading curricula emphasize reading for different purposes including the two overarching purposes central to PIRLS: literary and informational reading. Furthermore, the four processes of comprehension measured in PIRLS (focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements) are well-represented across language/reading curricula of the PIRLS 2021 countries. Many of the PIRLS 2021 countries’ reading curricula are specified in terms of what students should be able to do by the end of a given grade (or set of grades). For example, the National Curriculum of the Republic of Azerbaijan states that by the end of the fourth grade, students should be able to “determine the main idea of the text and analyze the characters” and “retell the text in a creative form,” among other skills. In France’s curricula, skills that students should demonstrate are organized under broader categories, such as “build up the characteristics and specificities of literary genres” and “use experience and knowledge of the world to express a reaction, a point of view, or a judgment on a text or book,” which are both grouped under “understand a literary text and make it his/her own.” Latvia’s language and reading curricula are organized around questions with which students should engage, including “How do you express your opinion and justify it?” and “How do the means and methods of expression used in literary and other works of art differ?” Some of the PIRLS 2021 countries explicitly discuss digital reading skills in their language/reading curricula. Often the curricula only state that students should be able to read texts both in print and digitally; however, there are some countries with additional digital literacy specifications. For example, in Denmark, by the end of fourth grade students should be able to “find relevant information on age-appropriate websites and assess the relevance and credibility of that information.” Special Reading Initiatives Because literacy development is a high priority across countries, many of the PIRLS 2021 countries’ Encyclopedia chapters describe special initiatives to promote reading among primary school students. These programs often aim to increase the amount of time that students spend reading as well as improve students’ attitudes towards reading. For example, in Ireland, children participate in programs such as Drop Everything and Read (DEAR) to create a sense of enjoyment from reading. In Finland, the Finnish Reading Center arranges author visits to schools to increase student engagement with books. Some countries report reading initiatives that target families and emphasize parental involvement in the development of children’s literacy skills. In Chinese Taipei, multiple programs aim to increase the amount of time parents spend reading to young children, including Bookstart (sponsored by libraries) and Reach Out and Read Taiwan, in which pediatricians teach parents the benefits of reading aloud to children. Another example of this is in New Zealand, where a program called Reading Together strives to promote coordination between parents and schools to improve students’ reading achievement. In Poland, parents are also encouraged to read to their children through the All of Poland Reads to Kids initiative Some countries also host national festivals or celebrations to promote reading. For example, 2021 was Croatia’s Year of Reading, which included a national book month and international book fair. Similarly, in Kazakhstan in 2021, the Year of Support for Children’s and Youth Reading was announced, which highlighted notable works from Kazakhstani authors through national readings. Another prominent theme across PIRLS 2021 countries is national initiatives to provide books for students. In 2020, Uzbekistan provided over three million books to children as part of the Caravan of Enlightenment. Hong Kong SAR has an annual book fair that attracts hundreds of thousands of attendees and includes different exhibitions, seminars, and events. Teacher Professional Development Teachers are integral players in improving children’s reading skills and teachers in many of the PIRLS 2021 countries have various opportunities for teacher professional development. Teacher professional development is offered through a variety of providers across countries, including government agencies and private organizations. Whether or not ongoing professional development is required and, if so, how many hours, varies across countries. For example, Australia has no national mandates for teacher professional development, but jurisdictions are free to set their own guidelines. Israel requires that primary school teachers complete at least 60 hours of professional development over the course of each school year. In the Czech Republic, teachers have the option to use up to 12 work days for professional development each school year. In some countries, participation in professional development leads to career advancement for teachers. For example, in Georgia, teachers can earn a certain number of professional development credits to advance to the status of a senior teacher. Professional development hours are also required to move among the six teaching ranks in private schools in Macao SAR. COVID-19 Pandemic The COVID-19 pandemic has been an immense disruption to schooling worldwide. All of the PIRLS 2021 countries experienced some degree of school closure during the first half of 2020. In addition to this initial period, many countries had additional closures over the course of the following year as the pandemic situation evolved. For example, after fully reopening in September of 2020, England’s schools closed again in the early months of 2021 before reopening in March. In some countries, additional school closures occurred at the regional level after the initial closures of early 2020. In Italy, primary schools in some regions were open for the entire 2020-2021 school year, while others were open for less than half of the days planned. During periods of school closure, countries utilized various forms of remote instruction to minimize the disruption to students’ education. Many countries opted for some form of online instruction, either through a videoconferencing software where students could interact with their teacher synchronously, or other online lessons and portals. The efficacy of these online strategies varied, and many countries reported that students of low socioeconomic status struggled to keep up with instruction. Online instruction was not the only format of remote instruction used in the PIRLS 2021 countries. For example, in Morocco, lessons were broadcasted to students via television. Television was also used to deliver lessons to students in South Africa, as well as regional radio. Although the impact of the COVID-19 pandemic on students’ long-term academic development remains to be seen, some of the PIRLS 2021 countries have made initial strides in evaluating the impact of the pandemic on student learning and other education indicators. An early analysis in Bulgaria found that students’ digital skills improved after distance learning during the pandemic, but that social skills declined and students experienced high levels of distraction and low motivation. In Portugal, early work has found that students seem to show a lower level of academic performance in 2021 compared to before the pandemic in 2019. Education policy changes in the PIRLS 2021 countries during the COVID-19 pandemic tended to focus on the permanent application of some form of online or digital learning, often with a goal of improving the accessibility of these resources for all students. For example, in the United States, school closures in response to the pandemic drew additional attention to the “digital divide” among families in different regions of the country. A similar divide was observed in Ireland, which led to supplementing an Information and Communications Technology (ICT) grant to purchase digital devices for students or support remote learning platforms. \n",
      "Introduction\n",
      " \n",
      "Overview\n",
      " \n",
      "Organization of the PIRLS 2021 Encyclopedia\n",
      " \n",
      "Demographic and Economic Characteristics of the PIRLS 2021 Countries\n",
      " \n",
      "Highlights from the Curriculum Questionnaire\n",
      " \n",
      "Highlights from the Country Chapters\n",
      " Related Links Download Center Suggested Citation Reynolds, K.A., Wry, E., Mullis, I.V.S., & von Davier, M. (2022). PIRLS 2021 Encyclopedia: Education Policy and Curriculum in Reading. Retrieved from Boston College, TIMSS & PIRLS International Study Center website: https://pirls2021.org/encyclopedia ISBN: 978-1-889938-66-0 Library of Congress Catalog Card Number: 2022919305 TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/exhibit-1\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Exhibit 1 PIRLS 2021 Encyclopedia Education Policy and Curriculum in Reading Exhibit 1 Years of Schooling View Fullscreen PDF Download PDF \n",
      "Curriculum Questionnaire Exhibits\n",
      " \n",
      "Exhibit 1: Years of Schooling\n",
      " \n",
      "Exhibit 2: National Policies on Age of School Entry and Promotion\n",
      " \n",
      "Exhibit 3: Official Languages and Languages of Instruction\n",
      " \n",
      "Exhibit 4: Status of the Fourth Grade Language/Reading Curriculum\n",
      " \n",
      "Exhibit 5: Purposes for Reading Emphasized in the Intended Language/Reading Curriculum\n",
      " \n",
      "Exhibit 6: Digital Reading Skills Emphasized in the Intended Language/Reading Curriculum\n",
      " \n",
      "Exhibit 7: Policies/Statements About Digital Literacy in the Language/Reading Curriculum\n",
      " \n",
      "Exhibit 8: Main Preparation Routes and Current Requirements for Fourth Grade Teachers\n",
      " \n",
      "Exhibit 9: Current Requirements for Principals of Schools with Fourth Grade Students\n",
      " \n",
      "Exhibit 10: Level of Government Responsible for Decision-Making During the COVID-19 Pandemic\n",
      " Related Links Download Center Suggested Citation Reynolds, K.A., Wry, E., Mullis, I.V.S., & von Davier, M. (2022). PIRLS 2021 Encyclopedia: Education Policy and Curriculum in Reading. Retrieved from Boston College, TIMSS & PIRLS International Study Center website: https://pirls2021.org/encyclopedia ISBN: 978-1-889938-66-0 Library of Congress Catalog Card Number: 2022919305 TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/download\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Download PIRLS 2021 Encyclopedia Education Policy and Curriculum in Reading download center PIRLS 2021 Encyclopedia\n",
      "\n",
      "\n",
      "\n",
      " Introduction 2. Curriculum Questionnaire\n",
      "                                        Exhibits \n",
      "\n",
      "Exhibit 1 Years of Schooling\n",
      "Exhibit 2 National Policies on Age of\n",
      "                                                School Entry and Promotion\n",
      "Exhibit 3 Official Languages and Languages\n",
      "                                                of Instruction\n",
      "Exhibit 4 Status of the Fourth Grade\n",
      "                                                Language/Reading Curriculum\n",
      "Exhibit 5 Purposes for Reading Emphasized in the Intended Language/Reading Curriculum\n",
      "Exhibit 6 Digital Reading Skills Emphasized\n",
      "                                                in the Intended Language/Reading Curriculum\n",
      "Exhibit 7 Policies/Statements About Digital\n",
      "                                                Literacy in the Language/Reading Curriculum\n",
      "Exhibit 8 Main Preparation Routes and\n",
      "                                                Current Requirements for Fourth Grade Teachers\n",
      "Exhibit 9 Current Requirements for Principals of Schools with Fourth Grade Students\n",
      "Exhibit 10 Level of Government Responsible\n",
      "                                                for Decision-Making During the COVID-19 Pandemic\n",
      " Exhibit 1 Years of Schooling Exhibit 2 National Policies on Age of\n",
      "                                                School Entry and Promotion Exhibit 3 Official Languages and Languages\n",
      "                                                of Instruction Exhibit 4 Status of the Fourth Grade\n",
      "                                                Language/Reading Curriculum Exhibit 5 Purposes for Reading Emphasized in the Intended Language/Reading Curriculum Exhibit 6 Digital Reading Skills Emphasized\n",
      "                                                in the Intended Language/Reading Curriculum Exhibit 7 Policies/Statements About Digital\n",
      "                                                Literacy in the Language/Reading Curriculum Exhibit 8 Main Preparation Routes and\n",
      "                                                Current Requirements for Fourth Grade Teachers Exhibit 9 Current Requirements for Principals of Schools with Fourth Grade Students Exhibit 10 Level of Government Responsible\n",
      "                                                for Decision-Making During the COVID-19 Pandemic 2. Country Chapters \n",
      "\n",
      "Albania\n",
      "Australia\n",
      "Austria\n",
      "Azerbaijan\n",
      "Bahrain\n",
      "Belgium Flemish\n",
      "Belgium French\n",
      "Brazil\n",
      "Bulgaria\n",
      "Canada\n",
      "Chile\n",
      "Chinese Taipei\n",
      "Croatia\n",
      "Cyprus\n",
      "Czech Republic\n",
      "Denmark\n",
      "Dubai, United Arab EmiratesDubai, United Arab Emirates\n",
      "England\n",
      "Finland\n",
      "France\n",
      "Georgia\n",
      "Germany\n",
      "Hong Kong SAR\n",
      "Hungary\n",
      "Ireland\n",
      "Islamic Republic of Iran\n",
      "Israel\n",
      "Italy\n",
      "Jordan\n",
      "Kazakhstan\n",
      "Latvia\n",
      "Lithuania\n",
      "Macao SAR\n",
      "Malta\n",
      "Montenegro\n",
      "Morocco\n",
      "Netherlands\n",
      "New Zealand\n",
      "North Macedonia\n",
      "Northern Ireland\n",
      "Norway\n",
      "Oman\n",
      "Poland\n",
      "Portugal\n",
      "Qatar\n",
      "Russian Federation\n",
      "Saudi Arabia\n",
      "Serbia\n",
      "Singapore\n",
      "Slovak Republic\n",
      "Slovenia\n",
      "South AfricaSpain Albania Australia Austria Azerbaijan Bahrain Belgium Flemish Belgium French Brazil Bulgaria Canada Chile Chinese Taipei Croatia Cyprus Czech Republic Denmark Dubai, United Arab EmiratesDubai, United Arab Emirates England Finland France Georgia Germany Hong Kong SAR Hungary Ireland Islamic Republic of Iran Israel Italy Jordan Kazakhstan Latvia Lithuania Macao SAR Malta Montenegro Morocco Netherlands New Zealand North Macedonia Northern Ireland Norway Oman Poland Portugal Qatar Russian Federation Saudi Arabia Serbia Singapore Slovak Republic Slovenia South Africa Sweden Türkiye United Arab Emirates \n",
      "United States\n",
      " \n",
      "Uzbekistan\n",
      " 3.\n",
      "                                Benchmarking Participants’ Chapters \n",
      "\n",
      "Ontario Canada\n",
      "Quebec Canada\n",
      "Moscow City Russian Federation\n",
      "Abu Dhabi UAE\n",
      "\n",
      "Dubai UAE\n",
      "\n",
      "\n",
      " Ontario Canada Quebec Canada Moscow City Russian Federation Abu Dhabi UAE \n",
      "Dubai UAE\n",
      " Download PDF  TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/methods\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Methods and Procedures: PIRLS 2021 Technical Report Methods and Procedures:\n",
      "PIRLS 2021 Technical Report Matthias von Davier, Ina V.S. Mullis, Bethany Fishbein, and Pierre Foy, Editors This technical report documents the methods and procedures used to develop, implement, and report the results of PIRLS 2021. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade, including transitioning from paper to digital assessment and implementing a group adaptive assessment design. There were substantial challenges in the implementation, analysis, and reporting of PIRLS 2021 due to the COVID-19 pandemic. PIRLS 2021 data collection occurred over a two-year period, with schools worldwide facing many disruptions to normal instruction. Despite many obstacles, most countries met standards for high quality data. A multi-step, population-based linking approach to the achievement scaling enabled reporting comparable trends for paper and digital data on the PIRLS trend scale.  PIRLS 2021 was a collaborative effort involving hundreds of individuals around the world, including the TIMSS & PIRLS International Study Center, IEA Amsterdam, IEA Hamburg, Statistics Canada, and the National Research Coordinators and their teams in the participating countries.\n",
      " Contents Assessment Development Data Collection Procedures Analysis and Reporting Contents Chapter 1:Developing Achievement Instruments Chapter 2:Updating Context Questionnaires Chapter 3:Sample Design Chapter 4:Survey Operations Procedures Chapter 5:Systems and Instrument Verification Chapter 6:Quality Assurance Program Chapter 7:Creating the International Database Chapter 8:Sampling Implementation Chapter 9:Reviewing Item Statistics Chapter 10:Achievement Scaling Methodology Chapter 11:Achievement Scaling Implementation Chapter 12:Examining Differences Between Digital and Bridge Data Chapter 13:Estimating Standard Errors Chapter 14:Scale Anchoring to Interpret Achievement Results Chapter 15:Creating Context Questionnaire Scales Suggested Citation  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/questionnaires\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Context Questionnaires PIRLS 2021 Context Questionnaires An important purpose of PIRLS 2021 is to study the home, community, school, and student factors associated with students’ reading achievement in the fourth grade. To accomplish this, data about contexts for learning are collected through questionnaires completed by students and their parents, teachers, and school principals. These datasets are all available in the PIRLS 2021 International Database. In addition, PIRLS National Research Coordinators provide information on the national contexts for learning through the Curriculum Questionnaire and their country’s chapter in the PIRLS 2021 Encyclopedia.  Download Questionnaires Each of the PIRLS 2021 Context Questionnaires can be downloaded below in PDF format. The Student, Home, Teacher, and School Questionnaires are presented as paper questionnaire booklets, although countries may have administered these digitally. The Curriculum Questionnaire PDF is a recreation of the online questionnaire. Student Questionnaire Home Questionnaire (Early Learning Survey) Teacher Questionnaire School Questionnaire Curriculum Questionnaire Student Questionnaire Each student participating in PIRLS 2021 completed a Student Questionnaire. The questionnaire asked about aspects of students’ home and school lives, including basic demographic information, their home environment, school climate for learning, and attitudes toward reading.   Home Questionnaire (Early Learning Survey) The parents or guardians of participating students completed the Early Learning Survey, often referred to as the Home Questionnaire. The questionnaire asked about home resources that support learning and information about parents’ highest level of education and employment situations, opinions about their child’s school, their child’s attendance in preprimary education programs, the emphasis on literacy activities in the home before the child attended school, and the level of their child’s literacy skills when beginning school. In PIRLS 2021, parents also provided information about their child’s learning experiences during the COVID-19 pandemic.  Teacher Questionnaire Teachers of the assessed classes responded to a Teacher Questionnaire. The questionnaire asked students’ teachers about their education, professional development, and teaching experience. It also asked about students’ readiness for instruction, the frequency of various instructional activities, difficulties in providing instruction, assessment practices, and availability of digital devices for reading instruction.  School Questionnaire The principal of each school that participated in PIRLS 2021 completed a School Questionnaire. Principals answered questions about their qualifications and experience, as well as the socioeconomic background of the students attending the school, the availability of instructional resources, the school’s emphasis on academic success, and discipline and school safety. For PIRLS 2021, principals also provided information about the school’s response to the COVID-19 pandemic.  Curriculum  Questionnaire The PIRLS 2021 National Research Coordinator within each country was responsible for completing the Curriculum Questionnaire. Questions primarily centered on national curriculum policies and practices related to the countries’ education systems and the organization and content of language/reading curricula in their country. Copyright Notice TIMSS and PIRLS are registered trademarks of IEA. Use of these trademarks without permission of IEA by others may constitute trademark infringement. Furthermore, the website and its contents, together with all online and/or printed TIMSS and PIRLS publications and restricted use items and text by IEA and TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College are and will remain the copyright of IEA.  All TIMSS and PIRLS publications and restricted use items/text by IEA and TIMSS & PIRLS International Study Center, as well as translations thereof, are for non-commercial, educational, and research purposes only. When using IEA data sources for assessment or learning materials, prior permission is required. IEA reserves the right to refuse copy deemed inappropriate or not properly sourced. All TIMSS and PIRLS publications and restricted use items/text by IEA and TIMSS & PIRLS International Study Center, as well as translations thereof, are for non-commercial, educational, and research purposes only. When using IEA data sources for assessment or learning materials, prior permission is required. IEA reserves the right to refuse copy deemed inappropriate or not properly sourced. Commercial exploitation, distribution, redistribution, reproduction and/or transmitting in any form or by any means, including electronic or mechanical methods such as photocopying, information storage and retrieval system of these publications, restricted use items/texts, translations thereof and/or part thereof are prohibited unless written permission has been provided by IEA. When quoting and/or citing from one or more publications and/or restricted use items/texts from IEA and TIMSS & PIRLS International Study Center for the sake of educational or research purposes, please include an acknowledgment of the source, including the year and name of that publication and/or restricted use item/text. Please use the following acknowledgment as an example: Please note that citing without naming the source can or will constitute plagiarism for which you can and will be held accountable.  To request permission to reuse, reproduce, or translate IEA material, please fill out the permission request form » Disclaimer Please note that the website and its contents, together with all online and/or printed publications and restricted use items/text (“works”) by IEA and TIMSS & PIRLS International Study Center, were created with the utmost care. However, the correctness of the information cannot be guaranteed at all times and IEA cannot and will not be held responsible or liable for any damages that may arise from the use of these resources, nor will IEA be liable for the wrongful use and/or interpretation of its works. Please be advised that IEA cannot authorize the use of texts or items that include third- party copyrighted materials (e.g., reading passages, photographs, images). Users of any third-party copyrighted materials must first seek and be granted copyright permission from the owner of the content as indicated in the copyright citation line. Use of IEA and TIMSS & PIRLS International Study Center publications and/or restricted items/text for research and educational purposes does not imply endorsement by IEA and TIMSS & PIRLS International Study Center of any stage of the research, including verbal and written reporting of it, or of the educational program using the items. TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/data\n",
      "Text: About WordPressAbout WordPressWordPress.orgDocumentationSupportFeedback About WordPress WordPress.org Documentation Support Feedback PIRLS 2021DashboardThemesWidgetsMenusBackground Dashboard Themes Widgets Menus Background Customize 11 update available 00 Comments in moderation NewPostMediaPageUser Post Media Page User Edit Page SEOFocus keyphrase not setFocus keyphrase: not setSEO score: Focus keyphrase not setReadability: Needs improvementFront-end SEO inspectorPremiumSEO ToolsSemrushWincherGoogle trendsHow toLearn more SEOImprove your blog postWrite better contentHelpYoast.com help sectionYoast Premium supportWordPress.org support forumsLearn more SEOSEO SettingsGeneralSettingsToolsPremiumGet Yoast SEO Premium » Focus keyphrase: not set SEO score: Focus keyphrase not set Readability: Needs improvement Front-end SEO inspectorPremium SEO ToolsSemrushWincherGoogle trends Semrush Wincher Google trends How toLearn more SEOImprove your blog postWrite better content Learn more SEO Improve your blog post Write better content HelpYoast.com help sectionYoast Premium supportWordPress.org support forumsLearn more SEO Yoast.com help section Yoast Premium support WordPress.org support forums Learn more SEO SEO SettingsGeneralSettingsToolsPremium General Settings Tools Premium Get Yoast SEO Premium » Search Howdy, seanseanEdit ProfileLog Out sean Edit Profile Log Out \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Publications International Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Private: database PIRLS 2021 International Database The PIRLS 2021 International Database is available to researchers, analysts, and any individuals interested in the data collected and analyzed as part of PIRLS 2021. The database includes student achievement data as well as student, home, teacher, school, and national context data for 57 countries and 8 benchmarking participants. PIRLS 2021 is the fifth assessment cycle of PIRLS since 2001, providing 20 years of trends in reading achievement at the fourth grade. PIRLS 2021 is the only international assessment of educational achievement at the fourth grade that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. The entire database and its supporting documents are described in the PIRLS 2021 User Guide for the International Database, 2nd   Edition (Fishbein et al., 2024) and its three supplements. The data can be analyzed using the downloadable IEA IDB Analyzer (Version 5.0), an application developed by IEA Hamburg to facilitate the analysis of PIRLS data. Because of the impact the COVID-19 pandemic had on the PIRLS 2021 data collection, users should consult the User Guide, and other PIRLS 2021 publications cited in the User Guide, for important caveats in analyzing and interpreting the data. The public use version of the database is provided below along with supporting documentation. A restricted use version of the PIRLS 2021 International Database is available to users who require access to variables removed from the public use version (see Chapter 2 of the User Guide). Users who require access to the restricted use version to conduct their analyses should contact the IEA through its Study Data Repository. PIRLS 2021 International Database Downloads* User Guide Achievement Items Documentation International Database \n",
      "\t  * As of February 28, 2024, the PIRLS 2021 International Database includes student process data files. See User Guide, 2nd Edition for more information. Copyright Notice TIMSS and PIRLS are registered trademarks of IEA. Use of these trademarks without permission of IEA by others may constitute trademark infringement. Furthermore, the website and its contents, together with all online and/or printed TIMSS and PIRLS publications and restricted use items and text by IEA and TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, are and will remain the copyright of IEA. All TIMSS and PIRLS publications and restricted use items/texts by IEA and TIMSS & PIRLS International Study Center, as well as translations thereof, are for non-commercial, educational, and research purposes only. When using IEA data sources for assessment or learning materials, prior permission is required. IEA reserves the right to refuse copy deemed inappropriate or not properly sourced. Commercial exploitation, distribution, redistribution, reproduction and/or transmission in any form or by any means, including electronic or mechanical methods such as photocopying, information storage and retrieval system of these publications, restricted use items/texts, translations thereof and/or part thereof are prohibited unless written permission has been provided by IEA. When quoting and/or citing from one or more publications and/or restricted use items/texts from IEA and TIMSS & PIRLS International Study Center for the sake of educational or research purposes, please include an acknowledgment of the source, including the year and name of that publication and/or restricted use item/text. Please use the following acknowledgment as an example: Please note that citing without naming the source can or will constitute plagiarism for which you can and will be held accountable.\n",
      "\n",
      "            To request permission to reuse, reproduce, or translate IEA material, please fill out the permission request form »\n",
      "Disclaimer\n",
      "Please note that the website and its contents, together with all online and/or printed publications and restricted use items/texts (“works”) by IEA and TIMSS & PIRLS International Study Center, were created with the utmost care. However, the correctness of the information cannot be guaranteed at all times and IEA cannot and will not be held responsible or liable for any damages that may arise from the use of these resources, nor will IEA be liable for the wrongful use and/or interpretation of its works.\n",
      "Please be advised that IEA cannot authorize the use of texts or items that include third- party copyrighted materials (e.g., reading passages, photographs, images). Users of any third-party copyrighted materials must first seek and be granted copyright permission from the owner of the content as indicated in the copyright citation line.\n",
      "Use of IEA and TIMSS & PIRLS International Study Center publications and/or restricted items/texts for research and educational purposes does not imply endorsement by IEA and TIMSS & PIRLS International Study Center of any stage of the research, including verbal and written reporting of it, or of the educational program using the items.\n",
      "\n",
      " To request permission to reuse, reproduce, or translate IEA material, please fill out the permission request form » Disclaimer Please note that the website and its contents, together with all online and/or printed publications and restricted use items/texts (“works”) by IEA and TIMSS & PIRLS International Study Center, were created with the utmost care. However, the correctness of the information cannot be guaranteed at all times and IEA cannot and will not be held responsible or liable for any damages that may arise from the use of these resources, nor will IEA be liable for the wrongful use and/or interpretation of its works. Please be advised that IEA cannot authorize the use of texts or items that include third- party copyrighted materials (e.g., reading passages, photographs, images). Users of any third-party copyrighted materials must first seek and be granted copyright permission from the owner of the content as indicated in the copyright citation line. Use of IEA and TIMSS & PIRLS International Study Center publications and/or restricted items/texts for research and educational purposes does not imply endorsement by IEA and TIMSS & PIRLS International Study Center of any stage of the research, including verbal and written reporting of it, or of the educational program using the items. Suggested Citation Fishbein, B., Yin, L., & Foy, P. (2024). PIRLS 2021 User Guide for the International Database  (2nd  ed.). Boston College, TIMSS & PIRLS International Study Center. https://pirls2021.org/data ISBN: 978-1-889938-69-1 Library of Congress Catalog Card Number: 2023909690  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/achievement/\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Countries’ Reading Achievement – PIRLS 2021 PIRLS 2021 International Results in Reading Countries’ Reading Achievement Download Section The PIRLS 2021 data about students’ reading achievement provide an extremely valuable resource for continuing research about the impact of the COVID-19 pandemic on students’ learning. PIRLS 2021 is the only large scale international assessment that successfully collected data during education’s COVID-19 disruption. Further, the achievement data is accompanied by contextual information collected from several sources: principals’ reports about school conditions, students’ attitudes toward their reading instruction, and parents’ perceptions regarding the impact of the pandemic on their children’s learning (see later sections of the report on Home Environment Support; School Composition, Resources, and Climate; and Students’ Reading Attitudes and Behaviors). The About PIRLS 2021 Section The first section, About PIRLS 2021, provides a considerable amount of information about the PIRLS 2021 international assessment of reading comprehension at fourth grade (e.g., the content of the assessment, the 57 countries and 8 benchmarking entities participating\n",
      "in PIRLS 2021, the transition to digital assessment, and the numbers of students assessed). Despite coinciding with school disruptions due to the COVID-19 pandemic, the PIRLS 2021 data collection successfully included nearly 400,000 students in 57 countries worldwide. Although the pandemic necessitated changes in school operations, frequently leading to school closures (see Exhibit 3 in About PIRLS 2021), the countries were able to make various adjustments in their data collection schedules, ranging from minor changes to essentially heroic efforts.  Exhibit 5 in About PIRLS 2021 shows the chronology of the PIRLS 2021 data collection from November 2020 through July 2022. Fortunately, modifying the schedules had minimal impact on the quality of the PIRLS 2021 data. The thorough and well documented adjudications of the PIRLS 2021 sampling procedures and data collection outcomes found that the PIRLS guidelines to ensure high quality were met for the most part, while the few exceptions were annotated appropriately (see Appendix A). The International Quality Assurance Program also monitored and documented the data collection activities (see Chapter 6 in Methods and Procedures: PIRLS 2021 Technical Report). Impacts of Modifying the Assessment Schedule on Students’ Achievement Consistently across assessment cycles, the PIRLS data collection procedures have included conducting the assessments at the end of the fourth grade school year so that as much of the curriculum has been covered as possible. In light of the data collection challenges in PIRLS 2021, 43 of the 57 countries managed to assess students at the end of the target school year, including conducting the assessment a year later than originally scheduled in a few countries (this is annotated in the exhibits with a bowtie after the countries’ names). So far, no discernible achievement differences have been identified that are associated with assessing fourth grade students one year later than initially scheduled. However, in the other 14 countries (all in the Northern Hemisphere), the necessary modifications to the data collection schedule delayed assessing students in the fourth grade cohort until the beginning of the fifth grade. In reviewing the PIRLS 2021 achievement results, it appeared that some of these countries had an achievement advantage in PIRLS 2021 that also was manifested in the relatively larger trend increases between 2016 and 2021 (see report section on Trends in Reading Achievement). Of course, the reasons for any achievement differences are unknown. However, although there was variation, the average age of students in the 14 countries that delayed assessment until the beginning of the fifth grade was half a year older on average than the average age of students assessed at the end of fourth grade. Average Ages of Students Assessed in PIRLS 2021 and PIRLS 2016 by Data Collection Period Because of rounding, some results may appear inconsistent. Beyond finding that these students were comparatively older, unfortunately, without any information about the reading achievement of the students in the 14 countries at the end of the fourth grade or their activities over the summer months, the PIRLS 2021 data in and of itself cannot be used to disentangle the extent of the impact of the delayed assessment on students’ reading achievement. Researchers may be able to use within country data and local insights to study this issue in the future. For now, however, throughout the report pink highlighting has been used to identify the results of the 14 countries where delayed assessment until the beginning of the fifth grade resulted in collecting data from a sample of comparatively older students. \n",
      "Countries’ Reading Achievement\n",
      " \n",
      "Impacts of Modifying the Assessment Schedule on Students’ Achievement\n",
      " \n",
      "Average Reading Achievement and Scale Score Distributions\n",
      " \n",
      "Average Reading Achievement by Gender\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/trends\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Trends in Reading Acheivement – PIRLS 2021 PIRLS 2021 International Results in Reading Trends in Reading Achievement Download Section Measuring trends in achievement of student populations from one assessment cycle to the next is always an extremely complicated endeavor. PIRLS 2021 is the fifth assessment of PIRLS since its inception in 2001, providing 20 years of trend data. With each new assessment cycle, PIRLS has taken the utmost care to keep the majority of the assessment the same from cycle to cycle, to evolve carefully, and to document any differences. For PIRLS 2021, however, onset of the COVID-19 pandemic disrupted school operations often through school closures (see Exhibit 3 in About PIRLS 2021), which necessitated adjustments in the data collection schedules (see Exhibit 5 in About PIRLS 2021). Data collected across the PIRLS 2021 countries to examine the impact of COVID-19 on students’ learning and their reading achievement at the end of fourth grade is somewhat limited. The situation in each country and how the pandemic was handled was monitored and documented to the extent possible, while ensuring that the PIRLS assessment remained largely unchanged. Among these efforts, PIRLS 2021 reports from school principals are valuable and describe the extent of school closures. Exhibit 3 in About PIRLS 2021 shows how closures varied from country to country as did the responses to school closures in terms of providing out-of-school learning opportunities. Parents’ reports about the impact of the pandemic on their children’s learning also varied across countries (Exhibit 4 in About PIRLS 2021), although parents reported that two-thirds of their children were negatively impacted in their learning to some degree. \n",
      "Trends in Reading Achievement\n",
      " \n",
      "Trends in Average Reading Achievement\n",
      " \n",
      "Trends in Average Reading Achievement by Gender\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K.A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/relative-achievement/\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Relative Achievement – PIRLS 2021 PIRLS 2021 International Results in Reading Relative Achievement in Reading Purposes and Comprehension Processes Download Section Published as Chapter 1 in PIRLS 2021 Assessment Frameworks, the PIRLS 2021 Reading Assessment Framework provided the guidelines for developing the assessment content. Since the inception of PIRLS in 2001, the assessment framework has been organized according to two overarching purposes for reading: For literary experience To acquire and use information As shown below, the framework also describes four cross-cutting reading comprehension processes: retrieving, straightforward inferencing, interpreting and integrating, and evaluating and critiquing. The illustration includes the targeted weights of coverage, showing that PIRLS should involve 50 percent literary texts and 50 percent informational texts as well as 20 percent, 30 percent, 30 percent, and 20 percent of the four cross-cutting reading comprehension processes.\n",
      " From country to country, as a result of the curriculum or other factors, students might have relative strengths and weaknesses in reading literary compared to informational texts. The next part of this section of the report shows countries’ relative achievement in reading literary texts compared to reading informational texts in PIRLS 2021. The second part of this section presents the relative achievement results for two broad comprehension processes—1) retrieving and straightforward inferencing and 2) interpreting, integrating, and evaluating. For information about how the subscales for the reading purposes and comprehension processes were created, see Chapter 11 in Methods and Procedures: PIRLS 2021 Technical Report. The results in the purpose and process subscales are presented to provide a more nuanced view of overall reading achievement. The comparison between overall reading achievement and particular subscales may indicate countries’ relative strengths and weaknesses within overall reading. However, the subscales are based on only half the assessment items, making them somewhat less robust than the overall reading achievement results based on the entire scale. The subscale trend results are not reported here because they are less stable than the overall trend results and could be even further influenced by COVID-19 to an unknown degree. \n",
      "Relative Achievement\n",
      " \n",
      "Relative Achievement in Reading Purposes\n",
      " \n",
      "Relative Achievement in Comprehension Processes\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/context-home/\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Home Environment Support – PIRLS 2021 PIRLS 2021 International Results in Reading Home Environment Support Download Section All of the data about Home Environment Support were collected from students’ parents via the Home Questionnaire, or “Early Learning Survey.” The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no discernable impact on the responses to the Home Questionnaire due to COVID-19 or delayed testing. However, throughout PIRLS’ history, some countries have struggled to attain high participation rates from parents, and some countries have been unable to administer the Home Questionnaire. To caution readers about low response rates, there are designations in the exhibits. If data were available for less than 40 percent of students in a country, the country is designated with a “y,” and the data are not reported. If data were available for 40–50 percent of students, the country is designated with an “x,” and the data are reported but do not contribute to the International Average. Many of the PIRLS 2021 Context Questionnaire items were combined into scales measuring a single underlying latent construct related to reading achievement. This section provides results for four scales: Home Socioeconomic Status, Home Early Literacy Activities Before Primary School, Parents Like Reading, and Could Do Early Literacy Tasks When Beginning Primary School. PIRLS used item response theory (IRT) scaling methods, specifically the Rasch partial credit model (PCM), to place items on a scale and produce scale scores (see Chapter 15 in Methods and Procedures: PIRLS 2021 Technical Report). Each context questionnaire scale enabled students to be classified into regions corresponding to high, middle, and low values on the construct. The “About the Scale” tab associated with each exhibit contains the questionnaire items and describes how the three regions reported in the exhibit were defined in terms of combinations of response categories. \n",
      "Home Environment Support\n",
      " \n",
      "Home Socioeconomic Status\n",
      " \n",
      "Early Literacy Activities\n",
      " \n",
      "Parents Like Reading\n",
      " \n",
      "Literacy Readiness for School\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/context-school/\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database School Composition, Resources, and Climate – PIRLS 2021 PIRLS 2021 International Results in Reading School Composition, Resources, and Climate Download Section The data in this section about School Composition, Resources, and Climate were collected from school principals via the PIRLS 2021 School Questionnaire. In countries where the assessment of the fourth grade cohort was delayed to the beginning of the fifth year of schooling, typically the schools had both fourth and fifth grades and principals were asked to answer in terms of the fourth grade cohort from the previous school year. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no discernable impact in the responses to the School Questionnaire due to COVID-19 or delayed testing. Many of the PIRLS 2021 Context Questionnaire items were combined into scales measuring a single underlying latent construct related to reading achievement. This section provides results for three scales: Instruction Affected by Reading Resource Shortages, School Emphasis on Academic Success, and School Discipline. PIRLS used item response theory (IRT) scaling methods, specifically the Rasch partial credit model (PCM), to place items on a scale and produce scale scores (see Chapter 15 in Methods and Procedures: PIRLS 2021 Technical Report). Each context questionnaire scale enabled students to be classified into regions corresponding to high, middle, and low values on the construct. The “About the Scale” tab associated with each exhibit contains the questionnaire items and describes how the three regions reported in the exhibit were defined in terms of combinations of response categories. \n",
      "School Composition, Resources, and Climate\n",
      " \n",
      "Socioeconomic Background of the Student Body\n",
      " \n",
      "Students Begin Primary Grades with Literacy Skills\n",
      " \n",
      "Instruction Affected by Resource Shortages\n",
      " \n",
      "School Emphasis on Academic Success\n",
      " \n",
      "School Discipline\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/context-student/\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Student Attitudes and Behaviors – PIRLS 2021 PIRLS 2021 International Results in Reading Students’ Reading Attitudes and Behaviors Download Section The results in this section about Students’ Reading Attitudes and Behaviors are based on students’ responses to the PIRLS 2021 Student Questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no discernable impact in the responses to the Student Questionnaire due to COVID-19 or delayed testing. The exhibits include the results for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021 (with the 14 countries that delayed testing highlighted in pink). Many of the PIRLS 2021 Context Questionnaire items were combined into scales measuring a single underlying latent construct related to reading achievement. This section provides results for two scales: Students Like Reading and Students Confident in Reading. PIRLS used item response theory (IRT) scaling methods, specifically the Rasch partial credit model (PCM), to place items on a scale and produce scale scores (see Chapter 15 in Methods and Procedures: PIRLS 2021 Technical Report). Each context questionnaire scale enabled students to be classified into regions corresponding to high, middle, and low values on the construct. The “About the Scale” tab associated with each exhibit contains the questionnaire items. It also describes how the three regions reported in the exhibit were defined in terms of combinations of response categories. PIRLS assessments have contributed to a considerable body of research showing that students with positive attitudes toward reading typically have higher reading achievement. However, it is unclear whether students’ positive attitudes toward reading lead to higher reading achievement or whether their positive attitudes result from higher reading achievement. There is evidence in the reading research literature that attitudes and reading achievement have a reciprocal rather than a causal relationship. \n",
      "Students’ Reading Attitudes and Behaviors\n",
      " \n",
      "Students Like Reading\n",
      " \n",
      "Students Confident in Reading\n",
      " \n",
      "Students Use Digital Devices to Find and Read Information\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#implementing\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/international-database\n",
      "Text: About WordPressAbout WordPressWordPress.orgDocumentationSupportFeedback About WordPress WordPress.org Documentation Support Feedback PIRLS 2021DashboardThemesWidgetsMenusBackground Dashboard Themes Widgets Menus Background Customize 11 update available 00 Comments in moderation NewPostMediaPageUser Post Media Page User Edit Page SEOFocus keyphrase not setFocus keyphrase: not setSEO score: Focus keyphrase not setReadability: Needs improvementFront-end SEO inspectorPremiumSEO ToolsSemrushWincherGoogle trendsHow toLearn more SEOImprove your blog postWrite better contentHelpYoast.com help sectionYoast Premium supportWordPress.org support forumsLearn more SEOSEO SettingsGeneralSettingsToolsPremiumGet Yoast SEO Premium » Focus keyphrase: not set SEO score: Focus keyphrase not set Readability: Needs improvement Front-end SEO inspectorPremium SEO ToolsSemrushWincherGoogle trends Semrush Wincher Google trends How toLearn more SEOImprove your blog postWrite better content Learn more SEO Improve your blog post Write better content HelpYoast.com help sectionYoast Premium supportWordPress.org support forumsLearn more SEO Yoast.com help section Yoast Premium support WordPress.org support forums Learn more SEO SEO SettingsGeneralSettingsToolsPremium General Settings Tools Premium Get Yoast SEO Premium » Search Howdy, seanseanEdit ProfileLog Out sean Edit Profile Log Out \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Publications International Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Private: database PIRLS 2021 International Database The PIRLS 2021 International Database is available to researchers, analysts, and any individuals interested in the data collected and analyzed as part of PIRLS 2021. The database includes student achievement data as well as student, home, teacher, school, and national context data for 57 countries and 8 benchmarking participants. PIRLS 2021 is the fifth assessment cycle of PIRLS since 2001, providing 20 years of trends in reading achievement at the fourth grade. PIRLS 2021 is the only international assessment of educational achievement at the fourth grade that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. The entire database and its supporting documents are described in the PIRLS 2021 User Guide for the International Database, 2nd   Edition (Fishbein et al., 2024) and its three supplements. The data can be analyzed using the downloadable IEA IDB Analyzer (Version 5.0), an application developed by IEA Hamburg to facilitate the analysis of PIRLS data. Because of the impact the COVID-19 pandemic had on the PIRLS 2021 data collection, users should consult the User Guide, and other PIRLS 2021 publications cited in the User Guide, for important caveats in analyzing and interpreting the data. The public use version of the database is provided below along with supporting documentation. A restricted use version of the PIRLS 2021 International Database is available to users who require access to variables removed from the public use version (see Chapter 2 of the User Guide). Users who require access to the restricted use version to conduct their analyses should contact the IEA through its Study Data Repository. PIRLS 2021 International Database Downloads* User Guide Achievement Items Documentation International Database \n",
      "\t  * As of February 28, 2024, the PIRLS 2021 International Database includes student process data files. See User Guide, 2nd Edition for more information. Copyright Notice TIMSS and PIRLS are registered trademarks of IEA. Use of these trademarks without permission of IEA by others may constitute trademark infringement. Furthermore, the website and its contents, together with all online and/or printed TIMSS and PIRLS publications and restricted use items and text by IEA and TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, are and will remain the copyright of IEA. All TIMSS and PIRLS publications and restricted use items/texts by IEA and TIMSS & PIRLS International Study Center, as well as translations thereof, are for non-commercial, educational, and research purposes only. When using IEA data sources for assessment or learning materials, prior permission is required. IEA reserves the right to refuse copy deemed inappropriate or not properly sourced. Commercial exploitation, distribution, redistribution, reproduction and/or transmission in any form or by any means, including electronic or mechanical methods such as photocopying, information storage and retrieval system of these publications, restricted use items/texts, translations thereof and/or part thereof are prohibited unless written permission has been provided by IEA. When quoting and/or citing from one or more publications and/or restricted use items/texts from IEA and TIMSS & PIRLS International Study Center for the sake of educational or research purposes, please include an acknowledgment of the source, including the year and name of that publication and/or restricted use item/text. Please use the following acknowledgment as an example: Please note that citing without naming the source can or will constitute plagiarism for which you can and will be held accountable.\n",
      "\n",
      "            To request permission to reuse, reproduce, or translate IEA material, please fill out the permission request form »\n",
      "Disclaimer\n",
      "Please note that the website and its contents, together with all online and/or printed publications and restricted use items/texts (“works”) by IEA and TIMSS & PIRLS International Study Center, were created with the utmost care. However, the correctness of the information cannot be guaranteed at all times and IEA cannot and will not be held responsible or liable for any damages that may arise from the use of these resources, nor will IEA be liable for the wrongful use and/or interpretation of its works.\n",
      "Please be advised that IEA cannot authorize the use of texts or items that include third- party copyrighted materials (e.g., reading passages, photographs, images). Users of any third-party copyrighted materials must first seek and be granted copyright permission from the owner of the content as indicated in the copyright citation line.\n",
      "Use of IEA and TIMSS & PIRLS International Study Center publications and/or restricted items/texts for research and educational purposes does not imply endorsement by IEA and TIMSS & PIRLS International Study Center of any stage of the research, including verbal and written reporting of it, or of the educational program using the items.\n",
      "\n",
      " To request permission to reuse, reproduce, or translate IEA material, please fill out the permission request form » Disclaimer Please note that the website and its contents, together with all online and/or printed publications and restricted use items/texts (“works”) by IEA and TIMSS & PIRLS International Study Center, were created with the utmost care. However, the correctness of the information cannot be guaranteed at all times and IEA cannot and will not be held responsible or liable for any damages that may arise from the use of these resources, nor will IEA be liable for the wrongful use and/or interpretation of its works. Please be advised that IEA cannot authorize the use of texts or items that include third- party copyrighted materials (e.g., reading passages, photographs, images). Users of any third-party copyrighted materials must first seek and be granted copyright permission from the owner of the content as indicated in the copyright citation line. Use of IEA and TIMSS & PIRLS International Study Center publications and/or restricted items/texts for research and educational purposes does not imply endorsement by IEA and TIMSS & PIRLS International Study Center of any stage of the research, including verbal and written reporting of it, or of the educational program using the items. Suggested Citation Fishbein, B., Yin, L., & Foy, P. (2024). PIRLS 2021 User Guide for the International Database  (2nd  ed.). Boston College, TIMSS & PIRLS International Study Center. https://pirls2021.org/data ISBN: 978-1-889938-69-1 Library of Congress Catalog Card Number: 2023909690  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/questionnaires\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Context Questionnaires PIRLS 2021 Context Questionnaires An important purpose of PIRLS 2021 is to study the home, community, school, and student factors associated with students’ reading achievement in the fourth grade. To accomplish this, data about contexts for learning are collected through questionnaires completed by students and their parents, teachers, and school principals. These datasets are all available in the PIRLS 2021 International Database. In addition, PIRLS National Research Coordinators provide information on the national contexts for learning through the Curriculum Questionnaire and their country’s chapter in the PIRLS 2021 Encyclopedia.  Download Questionnaires Each of the PIRLS 2021 Context Questionnaires can be downloaded below in PDF format. The Student, Home, Teacher, and School Questionnaires are presented as paper questionnaire booklets, although countries may have administered these digitally. The Curriculum Questionnaire PDF is a recreation of the online questionnaire. Student Questionnaire Home Questionnaire (Early Learning Survey) Teacher Questionnaire School Questionnaire Curriculum Questionnaire Student Questionnaire Each student participating in PIRLS 2021 completed a Student Questionnaire. The questionnaire asked about aspects of students’ home and school lives, including basic demographic information, their home environment, school climate for learning, and attitudes toward reading.   Home Questionnaire (Early Learning Survey) The parents or guardians of participating students completed the Early Learning Survey, often referred to as the Home Questionnaire. The questionnaire asked about home resources that support learning and information about parents’ highest level of education and employment situations, opinions about their child’s school, their child’s attendance in preprimary education programs, the emphasis on literacy activities in the home before the child attended school, and the level of their child’s literacy skills when beginning school. In PIRLS 2021, parents also provided information about their child’s learning experiences during the COVID-19 pandemic.  Teacher Questionnaire Teachers of the assessed classes responded to a Teacher Questionnaire. The questionnaire asked students’ teachers about their education, professional development, and teaching experience. It also asked about students’ readiness for instruction, the frequency of various instructional activities, difficulties in providing instruction, assessment practices, and availability of digital devices for reading instruction.  School Questionnaire The principal of each school that participated in PIRLS 2021 completed a School Questionnaire. Principals answered questions about their qualifications and experience, as well as the socioeconomic background of the students attending the school, the availability of instructional resources, the school’s emphasis on academic success, and discipline and school safety. For PIRLS 2021, principals also provided information about the school’s response to the COVID-19 pandemic.  Curriculum  Questionnaire The PIRLS 2021 National Research Coordinator within each country was responsible for completing the Curriculum Questionnaire. Questions primarily centered on national curriculum policies and practices related to the countries’ education systems and the organization and content of language/reading curricula in their country. Copyright Notice TIMSS and PIRLS are registered trademarks of IEA. Use of these trademarks without permission of IEA by others may constitute trademark infringement. Furthermore, the website and its contents, together with all online and/or printed TIMSS and PIRLS publications and restricted use items and text by IEA and TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College are and will remain the copyright of IEA.  All TIMSS and PIRLS publications and restricted use items/text by IEA and TIMSS & PIRLS International Study Center, as well as translations thereof, are for non-commercial, educational, and research purposes only. When using IEA data sources for assessment or learning materials, prior permission is required. IEA reserves the right to refuse copy deemed inappropriate or not properly sourced. All TIMSS and PIRLS publications and restricted use items/text by IEA and TIMSS & PIRLS International Study Center, as well as translations thereof, are for non-commercial, educational, and research purposes only. When using IEA data sources for assessment or learning materials, prior permission is required. IEA reserves the right to refuse copy deemed inappropriate or not properly sourced. Commercial exploitation, distribution, redistribution, reproduction and/or transmitting in any form or by any means, including electronic or mechanical methods such as photocopying, information storage and retrieval system of these publications, restricted use items/texts, translations thereof and/or part thereof are prohibited unless written permission has been provided by IEA. When quoting and/or citing from one or more publications and/or restricted use items/texts from IEA and TIMSS & PIRLS International Study Center for the sake of educational or research purposes, please include an acknowledgment of the source, including the year and name of that publication and/or restricted use item/text. Please use the following acknowledgment as an example: Please note that citing without naming the source can or will constitute plagiarism for which you can and will be held accountable.  To request permission to reuse, reproduce, or translate IEA material, please fill out the permission request form » Disclaimer Please note that the website and its contents, together with all online and/or printed publications and restricted use items/text (“works”) by IEA and TIMSS & PIRLS International Study Center, were created with the utmost care. However, the correctness of the information cannot be guaranteed at all times and IEA cannot and will not be held responsible or liable for any damages that may arise from the use of these resources, nor will IEA be liable for the wrongful use and/or interpretation of its works. Please be advised that IEA cannot authorize the use of texts or items that include third- party copyrighted materials (e.g., reading passages, photographs, images). Users of any third-party copyrighted materials must first seek and be granted copyright permission from the owner of the content as indicated in the copyright citation line. Use of IEA and TIMSS & PIRLS International Study Center publications and/or restricted items/text for research and educational purposes does not imply endorsement by IEA and TIMSS & PIRLS International Study Center of any stage of the research, including verbal and written reporting of it, or of the educational program using the items. TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/encyclopedia\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Encyclopedia PIRLS 2021 Encyclopedia Education Policy and Curriculum in Reading Katherine A. Reynolds, Erin Wry, Ina V.S. Mullis, and Matthias von Davier, Editors Introduction Download Introduction PDF The PIRLS 2021 Encyclopedia: Education Policy and Curriculum in Reading presents a profile of reading and language instruction in PIRLS 2021 countries and benchmarking systems. Representatives from each country and benchmarking participant completed the PIRLS 2021 curriculum questionnaire and prepared a chapter describing the country’s education system and reading curriculum, as well as the educational challenges and innovations arising from the COVID-19 pandemic. Together, the curriculum questionnaire data and country chapters present a concise yet rich portrait of reading education around the world. The PIRLS 2021 countries differ from one another in fundamental ways, including their education systems, and these differences are important to acknowledge when interpreting the PIRLS achievement results. The PIRLS 2021 Encyclopedia provides information about these differences and serves as a more qualitative companion to the PIRLS 2021 student achievement results. For PIRLS 2021, the Encyclopedia also includes information about the COVID-19 pandemic across countries. This important contextual information can be used by researchers, policymakers, and educators in conjunction with the PIRLS 2021 achievement results to inform education policy and curricula around the world. Organization of the PIRLS 2021 Encyclopedia The PIRLS 2021 Encyclopedia includes two different types of data: exhibits showing results from the PIRLS 2021 curriculum questionnaire, and chapters prepared by individual countries and benchmarking participants. Curriculum Questionnaire Exhibits Each cycle of PIRLS includes a curriculum questionnaire to collect background information about language/reading curricula and education policies from each country and benchmarking participant. Data from this questionnaire support the encyclopedia chapters by providing information about these topics in a format that is comparable across countries and benchmarking systems. The PIRLS 2021 Encyclopedia includes ten exhibits presenting information from the curriculum questionnaire about different aspects of countries’ education systems: Exhibit 1: Years of Schooling Exhibit 2: National Policies on Age of School Entry and Promotion Exhibit 3: Official Languages and Languages of Instruction Exhibit 4: Status of the Fourth Grade Language/Reading Curriculum Exhibit 5: Purposes for Reading Emphasized in the Intended Language/Reading Curriculum Exhibit 6: Digital Reading Skills Emphasized in the Intended Language/Reading Curriculum Exhibit 7: Policies/Statements About Digital Literacy in the Language/Reading Curriculum Exhibit 8: Main Preparation Routes and Current Requirements for Fourth Grade Teachers Exhibit 9: Current Requirements for Principals of Schools with Fourth Grade Students Exhibit 10: Level of Government Responsible for Decision-Making During the COVID-19 Pandemic Complete data from the PIRLS 2021 curriculum questionnaire will be available for download in the PIRLS 2021 International Database. Country Chapters Each chapter in the PIRLS 2021 Encyclopedia was written by a representative (or representatives) of a PIRLS 2021 country or benchmarking system, including experts from ministries of education, research institutes, and institutions of higher education, all with extensive knowledge about each country’s education system. Chapters provide more in-depth information about the structure of countries’ education systems, national use and impact of PIRLS results, language/reading curricula, teacher professional development, monitoring student progress in reading, and special reading initiatives. For PIRLS 2021, chapters also include information about countries’ education systems during the COVID-19 pandemic. PIRLS 2021 Countries’ and Benchmarking Participants’ Chapters Demographic and Economic Characteristics of the PIRLS 2021 Countries The PIRLS 2021 countries are geographically and economically diverse, as shown in the following table Selected Characteristics of the PIRLS 2021 Countries. These data are taken primarily from the World Bank’s DataBank, a repository of databases that include a range of economic, education, and human development indicators. The PIRLS 2021 countries vary widely in population size and geographic area. There is also some variation in life expectancy at birth, although this is 70 years or higher in all but one country. Economic indicators, such as the gross national income per capita (in US dollars), also show great variation across countries, ranging from 78,290 USD in Norway to 1,740 USD in Uzbekistan as of June 2022. With respect to public expenditure on education, countries spend anywhere from 2% (Bahrain) to 8% (Denmark, Norway, and Sweden) of their gross domestic product (GDP). Enrollment in primary education is relatively high, with all of the PIRLS 2021 countries having an enrollment rate greater than 80%, and many having an enrollment rate greater than 95%. View Fullscreen PDF Download PDF Highlights from the Curriculum Questionnaire School Entry Policies After entering primary school, children in many of the PIRLS 2021 countries can continue schooling for twelve to thirteen years, although compulsory school often ends after nine or ten years (see Exhibit 1). Children in the PIRLS 2021 countries most often begin primary school at age six, though specific policies differ across countries (for example, some policies state that children start school in the calendar year of their sixth birthday, while others require children to turn six by a particular date). There is some variation in the age at which students begin primary school across countries, with students in some countries beginning primary school at ages four, five, or seven (see Exhibit 2). Most of the PIRLS 2021 countries allow for some parental discretion on when children begin primary school, with policies typically allowing for slightly earlier or later entry depending upon the child’s development. Language of Instruction The PIRLS 2021 countries differ in the variety of languages in which reading instruction is offered for fourth grade students. About one-third of countries offer reading instruction only in the country’s official language(s). The other two-thirds of countries incorporate additional languages into reading instruction through a variety of means, including bilingual instruction that utilizes two languages, instruction in indigenous or other minority languages for particular communities, or allowing local schools to determine the language of instruction based on local language use. In some countries, the language of instruction also differs between public and private schools (see Exhibit 3). Fourth Grade Language/Reading Curriculum A large majority of the PIRLS 2021 countries have a national curriculum for fourth grade language/reading instruction. Reading is often incorporated into language instruction, although a small number of countries treat reading instruction as a separate curriculum area. Many countries’ language/reading curricula were introduced to classrooms within the past ten years, and about half of the PIRLS 2021 countries are currently revising their language/reading curricula (see Exhibit 4). About half of the PIRLS 2021 countries’ curricula specify a specific percentage of instructional time to be devoted to reading; among these, two-thirds of the countries’ curricula specify that 25 percent of instructional time or more should be devoted to reading instruction.\n",
      "Most countries’ fourth grade language/reading curricula place at least some emphasis on four broad purposes of reading: improving reading skills and comprehension, literary experience, acquiring information, and enjoyment. Twenty-seven countries place a major emphasis on all four of these purposes (see Exhibit 5). About two-thirds of the PIRLS 2021 countries’ curricula place some emphasis on at least one of the following three digital reading skills: 1) strategies for reading digital texts, 2) looking up information to research a topic online, and 3) critical evaluation of information on websites (see Exhibit 6). This finding is similar to PIRLS 2016. In addition, about half of the PIRLS 2021 countries have explicit statements about digital literacy in their fourth grade language/reading curricula. Of these, the majority also have one or more of the following: specific student goals or standards for digital literacy; recommendations or mandates for specific digital literacy curricular resources; recommendations or mandates for using digital devices in reading instruction; and safety or privacy requirements for use of digital devices (see Exhibit 7). Teacher and Principal Preparation A large majority of PIRLS 2021 countries require a university degree to become a teacher at the fourth grade. Many countries have additional teacher preparation routes that are common, including a specialized teaching program following a separate degree, a graduate degree, or a teacher’s college or normal school degree. As was the case in PIRLS 2016, the majority of PIRLS 2021 countries require that prospective teachers complete a supervised practicum during their teacher preparation program, although the length of this practicum varies across countries. Over half of the PIRLS 2021 countries require passing a qualifying exam, completion of a probationary teaching period or completion of a mentoring or induction program for new teachers of fourth grade students (see Exhibit 8). Requiring completion of a mentoring or induction program for new teachers, in particular, has become more popular among the PIRLS countries since 2016. The majority of PIRLS 2021 countries require that principals of schools with fourth grade students have teaching experience. Over half of the countries require completion of a specialized school leadership training program (see Exhibit 9). COVID-19 Pandemic Across the PIRLS 2021 countries, different authorities were responsible for different types of decisions related to the operation of schools during the COVID-19 pandemic. In over two-thirds of the PIRLS 2021 countries, decisions about closing or reopening schools were made at the national level, especially in the early part of the pandemic. In other countries, these decisions were made at the state/provincial or local levels. There was more variation across countries in the authority responsible for determining the format of remote instruction when schools were closed. In about one-third of the PIRLS 2021 countries, decisions about the format of remote instruction were made by individual schools, while in another third of the countries, these decisions were made at the national level. Decisions about the format of remote instruction were made at the state/provincial or local levels for the remaining countries. For many countries, there was considerable overlap in decision-making responsibility, with both national and local input for decisions about opening and closing schools, particularly as the pandemic progressed (see Exhibit 10). Highlights from the Country Chapters Reading Curricula in the PIRLS 2021 Countries Improving children’s reading skills is a high priority across the PIRLS 2021 countries, with many countries having national strategies to promote literacy development (e.g., the Language Council Reading Comprehension in Belgium’s Flemish region, Croatia’s National Strategy to Revive Book Reading). Countries’ language/reading curricula emphasize reading for different purposes including the two overarching purposes central to PIRLS: literary and informational reading. Furthermore, the four processes of comprehension measured in PIRLS (focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements) are well-represented across language/reading curricula of the PIRLS 2021 countries. Many of the PIRLS 2021 countries’ reading curricula are specified in terms of what students should be able to do by the end of a given grade (or set of grades). For example, the National Curriculum of the Republic of Azerbaijan states that by the end of the fourth grade, students should be able to “determine the main idea of the text and analyze the characters” and “retell the text in a creative form,” among other skills. In France’s curricula, skills that students should demonstrate are organized under broader categories, such as “build up the characteristics and specificities of literary genres” and “use experience and knowledge of the world to express a reaction, a point of view, or a judgment on a text or book,” which are both grouped under “understand a literary text and make it his/her own.” Latvia’s language and reading curricula are organized around questions with which students should engage, including “How do you express your opinion and justify it?” and “How do the means and methods of expression used in literary and other works of art differ?” Some of the PIRLS 2021 countries explicitly discuss digital reading skills in their language/reading curricula. Often the curricula only state that students should be able to read texts both in print and digitally; however, there are some countries with additional digital literacy specifications. For example, in Denmark, by the end of fourth grade students should be able to “find relevant information on age-appropriate websites and assess the relevance and credibility of that information.” Special Reading Initiatives Because literacy development is a high priority across countries, many of the PIRLS 2021 countries’ Encyclopedia chapters describe special initiatives to promote reading among primary school students. These programs often aim to increase the amount of time that students spend reading as well as improve students’ attitudes towards reading. For example, in Ireland, children participate in programs such as Drop Everything and Read (DEAR) to create a sense of enjoyment from reading. In Finland, the Finnish Reading Center arranges author visits to schools to increase student engagement with books. Some countries report reading initiatives that target families and emphasize parental involvement in the development of children’s literacy skills. In Chinese Taipei, multiple programs aim to increase the amount of time parents spend reading to young children, including Bookstart (sponsored by libraries) and Reach Out and Read Taiwan, in which pediatricians teach parents the benefits of reading aloud to children. Another example of this is in New Zealand, where a program called Reading Together strives to promote coordination between parents and schools to improve students’ reading achievement. In Poland, parents are also encouraged to read to their children through the All of Poland Reads to Kids initiative Some countries also host national festivals or celebrations to promote reading. For example, 2021 was Croatia’s Year of Reading, which included a national book month and international book fair. Similarly, in Kazakhstan in 2021, the Year of Support for Children’s and Youth Reading was announced, which highlighted notable works from Kazakhstani authors through national readings. Another prominent theme across PIRLS 2021 countries is national initiatives to provide books for students. In 2020, Uzbekistan provided over three million books to children as part of the Caravan of Enlightenment. Hong Kong SAR has an annual book fair that attracts hundreds of thousands of attendees and includes different exhibitions, seminars, and events. Teacher Professional Development Teachers are integral players in improving children’s reading skills and teachers in many of the PIRLS 2021 countries have various opportunities for teacher professional development. Teacher professional development is offered through a variety of providers across countries, including government agencies and private organizations. Whether or not ongoing professional development is required and, if so, how many hours, varies across countries. For example, Australia has no national mandates for teacher professional development, but jurisdictions are free to set their own guidelines. Israel requires that primary school teachers complete at least 60 hours of professional development over the course of each school year. In the Czech Republic, teachers have the option to use up to 12 work days for professional development each school year. In some countries, participation in professional development leads to career advancement for teachers. For example, in Georgia, teachers can earn a certain number of professional development credits to advance to the status of a senior teacher. Professional development hours are also required to move among the six teaching ranks in private schools in Macao SAR. COVID-19 Pandemic The COVID-19 pandemic has been an immense disruption to schooling worldwide. All of the PIRLS 2021 countries experienced some degree of school closure during the first half of 2020. In addition to this initial period, many countries had additional closures over the course of the following year as the pandemic situation evolved. For example, after fully reopening in September of 2020, England’s schools closed again in the early months of 2021 before reopening in March. In some countries, additional school closures occurred at the regional level after the initial closures of early 2020. In Italy, primary schools in some regions were open for the entire 2020-2021 school year, while others were open for less than half of the days planned. During periods of school closure, countries utilized various forms of remote instruction to minimize the disruption to students’ education. Many countries opted for some form of online instruction, either through a videoconferencing software where students could interact with their teacher synchronously, or other online lessons and portals. The efficacy of these online strategies varied, and many countries reported that students of low socioeconomic status struggled to keep up with instruction. Online instruction was not the only format of remote instruction used in the PIRLS 2021 countries. For example, in Morocco, lessons were broadcasted to students via television. Television was also used to deliver lessons to students in South Africa, as well as regional radio. Although the impact of the COVID-19 pandemic on students’ long-term academic development remains to be seen, some of the PIRLS 2021 countries have made initial strides in evaluating the impact of the pandemic on student learning and other education indicators. An early analysis in Bulgaria found that students’ digital skills improved after distance learning during the pandemic, but that social skills declined and students experienced high levels of distraction and low motivation. In Portugal, early work has found that students seem to show a lower level of academic performance in 2021 compared to before the pandemic in 2019. Education policy changes in the PIRLS 2021 countries during the COVID-19 pandemic tended to focus on the permanent application of some form of online or digital learning, often with a goal of improving the accessibility of these resources for all students. For example, in the United States, school closures in response to the pandemic drew additional attention to the “digital divide” among families in different regions of the country. A similar divide was observed in Ireland, which led to supplementing an Information and Communications Technology (ICT) grant to purchase digital devices for students or support remote learning platforms. \n",
      "Introduction\n",
      " \n",
      "Overview\n",
      " \n",
      "Organization of the PIRLS 2021 Encyclopedia\n",
      " \n",
      "Demographic and Economic Characteristics of the PIRLS 2021 Countries\n",
      " \n",
      "Highlights from the Curriculum Questionnaire\n",
      " \n",
      "Highlights from the Country Chapters\n",
      " Related Links Download Center Suggested Citation Reynolds, K.A., Wry, E., Mullis, I.V.S., & von Davier, M. (2022). PIRLS 2021 Encyclopedia: Education Policy and Curriculum in Reading. Retrieved from Boston College, TIMSS & PIRLS International Study Center website: https://pirls2021.org/encyclopedia ISBN: 978-1-889938-66-0 Library of Congress Catalog Card Number: 2022919305 TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#reporting-achievement\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/achievement#impact\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Countries’ Reading Achievement – PIRLS 2021 PIRLS 2021 International Results in Reading Countries’ Reading Achievement Download Section The PIRLS 2021 data about students’ reading achievement provide an extremely valuable resource for continuing research about the impact of the COVID-19 pandemic on students’ learning. PIRLS 2021 is the only large scale international assessment that successfully collected data during education’s COVID-19 disruption. Further, the achievement data is accompanied by contextual information collected from several sources: principals’ reports about school conditions, students’ attitudes toward their reading instruction, and parents’ perceptions regarding the impact of the pandemic on their children’s learning (see later sections of the report on Home Environment Support; School Composition, Resources, and Climate; and Students’ Reading Attitudes and Behaviors). The About PIRLS 2021 Section The first section, About PIRLS 2021, provides a considerable amount of information about the PIRLS 2021 international assessment of reading comprehension at fourth grade (e.g., the content of the assessment, the 57 countries and 8 benchmarking entities participating\n",
      "in PIRLS 2021, the transition to digital assessment, and the numbers of students assessed). Despite coinciding with school disruptions due to the COVID-19 pandemic, the PIRLS 2021 data collection successfully included nearly 400,000 students in 57 countries worldwide. Although the pandemic necessitated changes in school operations, frequently leading to school closures (see Exhibit 3 in About PIRLS 2021), the countries were able to make various adjustments in their data collection schedules, ranging from minor changes to essentially heroic efforts.  Exhibit 5 in About PIRLS 2021 shows the chronology of the PIRLS 2021 data collection from November 2020 through July 2022. Fortunately, modifying the schedules had minimal impact on the quality of the PIRLS 2021 data. The thorough and well documented adjudications of the PIRLS 2021 sampling procedures and data collection outcomes found that the PIRLS guidelines to ensure high quality were met for the most part, while the few exceptions were annotated appropriately (see Appendix A). The International Quality Assurance Program also monitored and documented the data collection activities (see Chapter 6 in Methods and Procedures: PIRLS 2021 Technical Report). Impacts of Modifying the Assessment Schedule on Students’ Achievement Consistently across assessment cycles, the PIRLS data collection procedures have included conducting the assessments at the end of the fourth grade school year so that as much of the curriculum has been covered as possible. In light of the data collection challenges in PIRLS 2021, 43 of the 57 countries managed to assess students at the end of the target school year, including conducting the assessment a year later than originally scheduled in a few countries (this is annotated in the exhibits with a bowtie after the countries’ names). So far, no discernible achievement differences have been identified that are associated with assessing fourth grade students one year later than initially scheduled. However, in the other 14 countries (all in the Northern Hemisphere), the necessary modifications to the data collection schedule delayed assessing students in the fourth grade cohort until the beginning of the fifth grade. In reviewing the PIRLS 2021 achievement results, it appeared that some of these countries had an achievement advantage in PIRLS 2021 that also was manifested in the relatively larger trend increases between 2016 and 2021 (see report section on Trends in Reading Achievement). Of course, the reasons for any achievement differences are unknown. However, although there was variation, the average age of students in the 14 countries that delayed assessment until the beginning of the fifth grade was half a year older on average than the average age of students assessed at the end of fourth grade. Average Ages of Students Assessed in PIRLS 2021 and PIRLS 2016 by Data Collection Period Because of rounding, some results may appear inconsistent. Beyond finding that these students were comparatively older, unfortunately, without any information about the reading achievement of the students in the 14 countries at the end of the fourth grade or their activities over the summer months, the PIRLS 2021 data in and of itself cannot be used to disentangle the extent of the impact of the delayed assessment on students’ reading achievement. Researchers may be able to use within country data and local insights to study this issue in the future. For now, however, throughout the report pink highlighting has been used to identify the results of the 14 countries where delayed assessment until the beginning of the fifth grade resulted in collecting data from a sample of comparatively older students. \n",
      "Countries’ Reading Achievement\n",
      " \n",
      "Impacts of Modifying the Assessment Schedule on Students’ Achievement\n",
      " \n",
      "Average Reading Achievement and Scale Score Distributions\n",
      " \n",
      "Average Reading Achievement by Gender\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/international-database\n",
      "Text: About WordPressAbout WordPressWordPress.orgDocumentationSupportFeedback About WordPress WordPress.org Documentation Support Feedback PIRLS 2021DashboardThemesWidgetsMenusBackground Dashboard Themes Widgets Menus Background Customize 11 update available 00 Comments in moderation NewPostMediaPageUser Post Media Page User Edit Page SEOFocus keyphrase not setFocus keyphrase: not setSEO score: Focus keyphrase not setReadability: Needs improvementFront-end SEO inspectorPremiumSEO ToolsSemrushWincherGoogle trendsHow toLearn more SEOImprove your blog postWrite better contentHelpYoast.com help sectionYoast Premium supportWordPress.org support forumsLearn more SEOSEO SettingsGeneralSettingsToolsPremiumGet Yoast SEO Premium » Focus keyphrase: not set SEO score: Focus keyphrase not set Readability: Needs improvement Front-end SEO inspectorPremium SEO ToolsSemrushWincherGoogle trends Semrush Wincher Google trends How toLearn more SEOImprove your blog postWrite better content Learn more SEO Improve your blog post Write better content HelpYoast.com help sectionYoast Premium supportWordPress.org support forumsLearn more SEO Yoast.com help section Yoast Premium support WordPress.org support forums Learn more SEO SEO SettingsGeneralSettingsToolsPremium General Settings Tools Premium Get Yoast SEO Premium » Search Howdy, seanseanEdit ProfileLog Out sean Edit Profile Log Out \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Publications International Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Private: database PIRLS 2021 International Database The PIRLS 2021 International Database is available to researchers, analysts, and any individuals interested in the data collected and analyzed as part of PIRLS 2021. The database includes student achievement data as well as student, home, teacher, school, and national context data for 57 countries and 8 benchmarking participants. PIRLS 2021 is the fifth assessment cycle of PIRLS since 2001, providing 20 years of trends in reading achievement at the fourth grade. PIRLS 2021 is the only international assessment of educational achievement at the fourth grade that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. The entire database and its supporting documents are described in the PIRLS 2021 User Guide for the International Database, 2nd   Edition (Fishbein et al., 2024) and its three supplements. The data can be analyzed using the downloadable IEA IDB Analyzer (Version 5.0), an application developed by IEA Hamburg to facilitate the analysis of PIRLS data. Because of the impact the COVID-19 pandemic had on the PIRLS 2021 data collection, users should consult the User Guide, and other PIRLS 2021 publications cited in the User Guide, for important caveats in analyzing and interpreting the data. The public use version of the database is provided below along with supporting documentation. A restricted use version of the PIRLS 2021 International Database is available to users who require access to variables removed from the public use version (see Chapter 2 of the User Guide). Users who require access to the restricted use version to conduct their analyses should contact the IEA through its Study Data Repository. PIRLS 2021 International Database Downloads* User Guide Achievement Items Documentation International Database \n",
      "\t  * As of February 28, 2024, the PIRLS 2021 International Database includes student process data files. See User Guide, 2nd Edition for more information. Copyright Notice TIMSS and PIRLS are registered trademarks of IEA. Use of these trademarks without permission of IEA by others may constitute trademark infringement. Furthermore, the website and its contents, together with all online and/or printed TIMSS and PIRLS publications and restricted use items and text by IEA and TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, are and will remain the copyright of IEA. All TIMSS and PIRLS publications and restricted use items/texts by IEA and TIMSS & PIRLS International Study Center, as well as translations thereof, are for non-commercial, educational, and research purposes only. When using IEA data sources for assessment or learning materials, prior permission is required. IEA reserves the right to refuse copy deemed inappropriate or not properly sourced. Commercial exploitation, distribution, redistribution, reproduction and/or transmission in any form or by any means, including electronic or mechanical methods such as photocopying, information storage and retrieval system of these publications, restricted use items/texts, translations thereof and/or part thereof are prohibited unless written permission has been provided by IEA. When quoting and/or citing from one or more publications and/or restricted use items/texts from IEA and TIMSS & PIRLS International Study Center for the sake of educational or research purposes, please include an acknowledgment of the source, including the year and name of that publication and/or restricted use item/text. Please use the following acknowledgment as an example: Please note that citing without naming the source can or will constitute plagiarism for which you can and will be held accountable.\n",
      "\n",
      "            To request permission to reuse, reproduce, or translate IEA material, please fill out the permission request form »\n",
      "Disclaimer\n",
      "Please note that the website and its contents, together with all online and/or printed publications and restricted use items/texts (“works”) by IEA and TIMSS & PIRLS International Study Center, were created with the utmost care. However, the correctness of the information cannot be guaranteed at all times and IEA cannot and will not be held responsible or liable for any damages that may arise from the use of these resources, nor will IEA be liable for the wrongful use and/or interpretation of its works.\n",
      "Please be advised that IEA cannot authorize the use of texts or items that include third- party copyrighted materials (e.g., reading passages, photographs, images). Users of any third-party copyrighted materials must first seek and be granted copyright permission from the owner of the content as indicated in the copyright citation line.\n",
      "Use of IEA and TIMSS & PIRLS International Study Center publications and/or restricted items/texts for research and educational purposes does not imply endorsement by IEA and TIMSS & PIRLS International Study Center of any stage of the research, including verbal and written reporting of it, or of the educational program using the items.\n",
      "\n",
      " To request permission to reuse, reproduce, or translate IEA material, please fill out the permission request form » Disclaimer Please note that the website and its contents, together with all online and/or printed publications and restricted use items/texts (“works”) by IEA and TIMSS & PIRLS International Study Center, were created with the utmost care. However, the correctness of the information cannot be guaranteed at all times and IEA cannot and will not be held responsible or liable for any damages that may arise from the use of these resources, nor will IEA be liable for the wrongful use and/or interpretation of its works. Please be advised that IEA cannot authorize the use of texts or items that include third- party copyrighted materials (e.g., reading passages, photographs, images). Users of any third-party copyrighted materials must first seek and be granted copyright permission from the owner of the content as indicated in the copyright citation line. Use of IEA and TIMSS & PIRLS International Study Center publications and/or restricted items/texts for research and educational purposes does not imply endorsement by IEA and TIMSS & PIRLS International Study Center of any stage of the research, including verbal and written reporting of it, or of the educational program using the items. Suggested Citation Fishbein, B., Yin, L., & Foy, P. (2024). PIRLS 2021 User Guide for the International Database  (2nd  ed.). Boston College, TIMSS & PIRLS International Study Center. https://pirls2021.org/data ISBN: 978-1-889938-69-1 Library of Congress Catalog Card Number: 2023909690  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/methods\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Methods and Procedures: PIRLS 2021 Technical Report Methods and Procedures:\n",
      "PIRLS 2021 Technical Report Matthias von Davier, Ina V.S. Mullis, Bethany Fishbein, and Pierre Foy, Editors This technical report documents the methods and procedures used to develop, implement, and report the results of PIRLS 2021. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade, including transitioning from paper to digital assessment and implementing a group adaptive assessment design. There were substantial challenges in the implementation, analysis, and reporting of PIRLS 2021 due to the COVID-19 pandemic. PIRLS 2021 data collection occurred over a two-year period, with schools worldwide facing many disruptions to normal instruction. Despite many obstacles, most countries met standards for high quality data. A multi-step, population-based linking approach to the achievement scaling enabled reporting comparable trends for paper and digital data on the PIRLS trend scale.  PIRLS 2021 was a collaborative effort involving hundreds of individuals around the world, including the TIMSS & PIRLS International Study Center, IEA Amsterdam, IEA Hamburg, Statistics Canada, and the National Research Coordinators and their teams in the participating countries.\n",
      " Contents Assessment Development Data Collection Procedures Analysis and Reporting Contents Chapter 1:Developing Achievement Instruments Chapter 2:Updating Context Questionnaires Chapter 3:Sample Design Chapter 4:Survey Operations Procedures Chapter 5:Systems and Instrument Verification Chapter 6:Quality Assurance Program Chapter 7:Creating the International Database Chapter 8:Sampling Implementation Chapter 9:Reviewing Item Statistics Chapter 10:Achievement Scaling Methodology Chapter 11:Achievement Scaling Implementation Chapter 12:Examining Differences Between Digital and Bridge Data Chapter 13:Estimating Standard Errors Chapter 14:Scale Anchoring to Interpret Achievement Results Chapter 15:Creating Context Questionnaire Scales Suggested Citation  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#about\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#overview\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#transitioning\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#framework\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#implementing\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#data-successful\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#number-students\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#summary-scaling\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#reporting-achievement\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#reporting-context\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results#quality\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/download/\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Download Center – PIRLS 2021 International Results PIRLS 2021 International Results in Reading download center Download Full Report Download PIRLS 2021 International Results in Reading (PDF) Download Report Sections About PIRLS 2021 (PDF) 1. Countries’ Reading Achievement (PDF) 2. Trends in Reading Achievement (PDF) 3. Relative Achievement in Reading Purposes and Comprehension Processes (PDF) 4. Performance at International Benchmarks (PDF) 5. Home Environment Support (PDF) 6. School Composition, Resources, and Climate (PDF) 7. Students’ Reading Attitudes and Behaviors (PDF) Appendix A: Population Coverage and Sample Participation Rates (PDF) Appendix B: Percentiles and Standard Deviations of Reading Achievement (PDF) Appendix C: Organizations and Individuals Responsible for PIRLS 2021 (PDF) Download Report Exhibits (PDF & XLSX) To download select exhibits, first check the files that you would like to download and then use the button at the bottom of the page to select your preferred download format(s). Please be patient while your files download. Download may take a few minutes. \n",
      "\n",
      "\n",
      "\n",
      "PIRLS 2021 International Results in Reading Exhibits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About PIRLS 2021\n",
      "\n",
      "\n",
      "\n",
      " 1. PIRLS 2021 Countries and Benchmarking Participants\n",
      "\n",
      "\n",
      "\n",
      " PIRLS 2021 Group Adaptive Assessment Design\n",
      "\n",
      "\n",
      "\n",
      " Weeks of Normal Primary School Operations Impacted by the COVID-19 Pandemic\n",
      "\n",
      "\n",
      "\n",
      " Parents’ Perceptions of Their Child’s Learning Progress During the COVID-19 Pandemic\n",
      "\n",
      "\n",
      "\n",
      " PIRLS 2021 Countries by Chronological Order of Data Collection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Countries’ Reading Achievement\n",
      "\n",
      "\n",
      "\n",
      " 1.1 Average Reading Achievement and Scale Score Distributions – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 1.2 Significance of Differences Between Countries’ Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 1.3 Average Reading Achievement and Scale Score Distributions – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      "\n",
      " 1.4 Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 1.5 Average Reading Achievement by Gender – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Trends in Reading Achievement\n",
      "\n",
      "\n",
      "\n",
      "2.1.1 Trend Plots of Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 2.1.2 Differences in Average Reading Achievement Across Assessment Years – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 2.2.1 Trend Plots of Average Reading Achievement – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "\n",
      "\n",
      "\n",
      " 2.2.2 Differences in Average Reading Achievement Across Assessment Years – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "\n",
      "\n",
      "\n",
      " 2.3 Trend Plots of Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      "2.4 Trend Plots of Average Reading Achievement by Gender – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "School Composition, Resources, and Climate\n",
      "\n",
      "\n",
      "\n",
      " 3.1 Relative Average Achievement in Reading Purposes – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 3.2 Relative Average Achievement in Reading Purposes – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      "\n",
      "3.3 Relative Average Achievement in Comprehension Processes – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      "3.4 Relative Average Achievement in Comprehension Processes – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Performance at PIRLS International Benchmarks\n",
      "\n",
      "\n",
      "\n",
      "4.1 Percentages of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      "4.2 Percentages of Students Reaching the PIRLS International Benchmarks – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      "\n",
      "4.3 Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      "4.4 Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home Environment Support\n",
      "\n",
      "\n",
      "\n",
      "5.1 Home Socioeconomic Status\n",
      "\n",
      "\n",
      "\n",
      "5.2 Home Early Literacy Activities Before Primary School\n",
      "\n",
      "\n",
      "\n",
      "5.3 Parents Like Reading\n",
      "\n",
      "\n",
      "\n",
      "5.4 Could Do Early Literacy Tasks When Beginning Primary School\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "School Composition, Resources, and Climate\n",
      "\n",
      "\n",
      "\n",
      "6.1 School Composition by Socioeconomic Background of the Student Body\n",
      "\n",
      "\n",
      "\n",
      "6.2 Schools Where Students Begin the Primary Grades with Literacy Skills\n",
      "\n",
      "\n",
      "\n",
      "6.3 Instruction Affected by Reading Resource Shortages – Principals’ Reports\n",
      "\n",
      "\n",
      "\n",
      "6.4 School Emphasis on Academic Success – Principals’ Reports\n",
      "\n",
      "\n",
      "\n",
      "6.5 School Discipline – Principals’ Reports\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Students’ Reading Attitudes and Behaviors\n",
      "\n",
      "\n",
      "\n",
      "7.1 Students Like Reading\n",
      "\n",
      "\n",
      "\n",
      "7.2 Students Like Reading by Gender\n",
      "\n",
      "\n",
      "\n",
      "7.3 Students Confident in Reading\n",
      "\n",
      "\n",
      "7.4 Students Confident in Reading by Gender\n",
      "\n",
      "\n",
      "\n",
      "7.5 Students Use Digital Devices to Find and Read Information\n",
      "\n",
      "\n",
      "\n",
      "7.6 Students Use Digital Devices to Find and Read Information by Gender\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appendices\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appendix A: Population Coverage and Sample Participation Rates\n",
      "\n",
      "\n",
      "\n",
      "A.1 Information About the Students Assessed in PIRLS 2021\n",
      "\n",
      "\n",
      "\n",
      "A.2 Coverage of PIRLS 2021 Target Population\n",
      "\n",
      "A.3 School Sample Sizes\n",
      " \n",
      " A.4 Student Sample Sizes\n",
      "  A.5 Participation Rates (Weighted)\n",
      " A.6 Trends in Student Populations\n",
      "\n",
      "\n",
      "\n",
      "Appendix B: Percentiles and Standard Deviations of Reading Achievement\n",
      "  B.1 Percentiles of Reading Achievement\n",
      " B.2 Standard Deviations of Reading Achievement\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appendix C: Organizations and Individuals Responsible for PIRLS 2021\n",
      "\n",
      "\n",
      " \n",
      " C.1 Organizations and Individuals Responsible for PIRLS 2021\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "About PIRLS 2021\n",
      "\n",
      "\n",
      "\n",
      " 1. PIRLS 2021 Countries and Benchmarking Participants\n",
      "\n",
      "\n",
      "\n",
      " PIRLS 2021 Group Adaptive Assessment Design\n",
      "\n",
      "\n",
      "\n",
      " Weeks of Normal Primary School Operations Impacted by the COVID-19 Pandemic\n",
      "\n",
      "\n",
      "\n",
      " Parents’ Perceptions of Their Child’s Learning Progress During the COVID-19 Pandemic\n",
      "\n",
      "\n",
      "\n",
      " PIRLS 2021 Countries by Chronological Order of Data Collection\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " 1. PIRLS 2021 Countries and Benchmarking Participants\n",
      " \n",
      "\n",
      " PIRLS 2021 Group Adaptive Assessment Design\n",
      " \n",
      "\n",
      " Weeks of Normal Primary School Operations Impacted by the COVID-19 Pandemic\n",
      " \n",
      "\n",
      " Parents’ Perceptions of Their Child’s Learning Progress During the COVID-19 Pandemic\n",
      " \n",
      "\n",
      " PIRLS 2021 Countries by Chronological Order of Data Collection\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Countries’ Reading Achievement\n",
      "\n",
      "\n",
      "\n",
      " 1.1 Average Reading Achievement and Scale Score Distributions – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 1.2 Significance of Differences Between Countries’ Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 1.3 Average Reading Achievement and Scale Score Distributions – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      "\n",
      " 1.4 Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 1.5 Average Reading Achievement by Gender – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " 1.1 Average Reading Achievement and Scale Score Distributions – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      " 1.2 Significance of Differences Between Countries’ Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      " 1.3 Average Reading Achievement and Scale Score Distributions – Includes Countries with Delayed Assessment\n",
      " \n",
      "\n",
      " 1.4 Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      " 1.5 Average Reading Achievement by Gender – Includes Countries with Delayed Assessment\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Trends in Reading Achievement\n",
      "\n",
      "\n",
      "\n",
      "2.1.1 Trend Plots of Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 2.1.2 Differences in Average Reading Achievement Across Assessment Years – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 2.2.1 Trend Plots of Average Reading Achievement – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "\n",
      "\n",
      "\n",
      " 2.2.2 Differences in Average Reading Achievement Across Assessment Years – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "\n",
      "\n",
      "\n",
      " 2.3 Trend Plots of Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      "2.4 Trend Plots of Average Reading Achievement by Gender – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "2.1.1 Trend Plots of Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      " 2.1.2 Differences in Average Reading Achievement Across Assessment Years – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      " 2.2.1 Trend Plots of Average Reading Achievement – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      " \n",
      "\n",
      " 2.2.2 Differences in Average Reading Achievement Across Assessment Years – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      " \n",
      "\n",
      " 2.3 Trend Plots of Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      "2.4 Trend Plots of Average Reading Achievement by Gender – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "School Composition, Resources, and Climate\n",
      "\n",
      "\n",
      "\n",
      " 3.1 Relative Average Achievement in Reading Purposes – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      " 3.2 Relative Average Achievement in Reading Purposes – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      "\n",
      "3.3 Relative Average Achievement in Comprehension Processes – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      "3.4 Relative Average Achievement in Comprehension Processes – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " 3.1 Relative Average Achievement in Reading Purposes – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      " 3.2 Relative Average Achievement in Reading Purposes – Includes Countries with Delayed Assessment\n",
      " \n",
      "\n",
      "3.3 Relative Average Achievement in Comprehension Processes – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      "3.4 Relative Average Achievement in Comprehension Processes – Includes Countries with Delayed Assessment\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Performance at PIRLS International Benchmarks\n",
      "\n",
      "\n",
      "\n",
      "4.1 Percentages of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      "4.2 Percentages of Students Reaching the PIRLS International Benchmarks – Includes Countries with Delayed Assessment\n",
      "\n",
      "\n",
      "\n",
      "4.3 Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year\n",
      "\n",
      "\n",
      "\n",
      "4.4 Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "4.1 Percentages of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      "4.2 Percentages of Students Reaching the PIRLS International Benchmarks – Includes Countries with Delayed Assessment\n",
      " \n",
      "\n",
      "4.3 Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year\n",
      " \n",
      "\n",
      "4.4 Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Home Environment Support\n",
      "\n",
      "\n",
      "\n",
      "5.1 Home Socioeconomic Status\n",
      "\n",
      "\n",
      "\n",
      "5.2 Home Early Literacy Activities Before Primary School\n",
      "\n",
      "\n",
      "\n",
      "5.3 Parents Like Reading\n",
      "\n",
      "\n",
      "\n",
      "5.4 Could Do Early Literacy Tasks When Beginning Primary School\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "5.1 Home Socioeconomic Status\n",
      " \n",
      "\n",
      "5.2 Home Early Literacy Activities Before Primary School\n",
      " \n",
      "\n",
      "5.3 Parents Like Reading\n",
      " \n",
      "\n",
      "5.4 Could Do Early Literacy Tasks When Beginning Primary School\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "School Composition, Resources, and Climate\n",
      "\n",
      "\n",
      "\n",
      "6.1 School Composition by Socioeconomic Background of the Student Body\n",
      "\n",
      "\n",
      "\n",
      "6.2 Schools Where Students Begin the Primary Grades with Literacy Skills\n",
      "\n",
      "\n",
      "\n",
      "6.3 Instruction Affected by Reading Resource Shortages – Principals’ Reports\n",
      "\n",
      "\n",
      "\n",
      "6.4 School Emphasis on Academic Success – Principals’ Reports\n",
      "\n",
      "\n",
      "\n",
      "6.5 School Discipline – Principals’ Reports\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "6.1 School Composition by Socioeconomic Background of the Student Body\n",
      " \n",
      "\n",
      "6.2 Schools Where Students Begin the Primary Grades with Literacy Skills\n",
      " \n",
      "\n",
      "6.3 Instruction Affected by Reading Resource Shortages – Principals’ Reports\n",
      " \n",
      "\n",
      "6.4 School Emphasis on Academic Success – Principals’ Reports\n",
      " \n",
      "\n",
      "6.5 School Discipline – Principals’ Reports\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Students’ Reading Attitudes and Behaviors\n",
      "\n",
      "\n",
      "\n",
      "7.1 Students Like Reading\n",
      "\n",
      "\n",
      "\n",
      "7.2 Students Like Reading by Gender\n",
      "\n",
      "\n",
      "\n",
      "7.3 Students Confident in Reading\n",
      "\n",
      "\n",
      "7.4 Students Confident in Reading by Gender\n",
      "\n",
      "\n",
      "\n",
      "7.5 Students Use Digital Devices to Find and Read Information\n",
      "\n",
      "\n",
      "\n",
      "7.6 Students Use Digital Devices to Find and Read Information by Gender\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "7.1 Students Like Reading\n",
      " \n",
      "\n",
      "7.2 Students Like Reading by Gender\n",
      " \n",
      "\n",
      "7.3 Students Confident in Reading \n",
      "\n",
      "7.4 Students Confident in Reading by Gender\n",
      " \n",
      "\n",
      "7.5 Students Use Digital Devices to Find and Read Information\n",
      " \n",
      "\n",
      "7.6 Students Use Digital Devices to Find and Read Information by Gender\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Appendices\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appendix A: Population Coverage and Sample Participation Rates\n",
      "\n",
      "\n",
      "\n",
      "A.1 Information About the Students Assessed in PIRLS 2021\n",
      "\n",
      "\n",
      "\n",
      "A.2 Coverage of PIRLS 2021 Target Population\n",
      "\n",
      "A.3 School Sample Sizes\n",
      " \n",
      " A.4 Student Sample Sizes\n",
      "  A.5 Participation Rates (Weighted)\n",
      " A.6 Trends in Student Populations\n",
      "\n",
      "\n",
      "\n",
      "Appendix B: Percentiles and Standard Deviations of Reading Achievement\n",
      "  B.1 Percentiles of Reading Achievement\n",
      " B.2 Standard Deviations of Reading Achievement\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appendix C: Organizations and Individuals Responsible for PIRLS 2021\n",
      "\n",
      "\n",
      " \n",
      " C.1 Organizations and Individuals Responsible for PIRLS 2021\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Appendix A: Population Coverage and Sample Participation Rates\n",
      "\n",
      "\n",
      "\n",
      "A.1 Information About the Students Assessed in PIRLS 2021\n",
      "\n",
      "\n",
      "\n",
      "A.2 Coverage of PIRLS 2021 Target Population\n",
      "\n",
      "A.3 School Sample Sizes\n",
      " \n",
      " A.4 Student Sample Sizes\n",
      "  A.5 Participation Rates (Weighted)\n",
      " A.6 Trends in Student Populations \n",
      "\n",
      "A.1 Information About the Students Assessed in PIRLS 2021\n",
      " \n",
      "\n",
      "A.2 Coverage of PIRLS 2021 Target Population\n",
      " A.3 School Sample Sizes  \n",
      " A.4 Student Sample Sizes   A.5 Participation Rates (Weighted)  A.6 Trends in Student Populations \n",
      "\n",
      "Appendix B: Percentiles and Standard Deviations of Reading Achievement\n",
      "  B.1 Percentiles of Reading Achievement\n",
      " B.2 Standard Deviations of Reading Achievement\n",
      "   B.1 Percentiles of Reading Achievement  B.2 Standard Deviations of Reading Achievement \n",
      "\n",
      "Appendix C: Organizations and Individuals Responsible for PIRLS 2021\n",
      "\n",
      "\n",
      " \n",
      " C.1 Organizations and Individuals Responsible for PIRLS 2021\n",
      "\n",
      "\n",
      " \n",
      " \n",
      " C.1 Organizations and Individuals Responsible for PIRLS 2021\n",
      " Download PDF Download EXCEL  Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://pirls2021.org/results/contents/\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database Contents – PIRLS 2021 International Results in Reading PIRLS 2021 International Results in Reading Contents About PIRLS 2021 Overview of PIRLS Transitioning to Digital Assessment in PIRLS 2021\n",
      "Exhibit 1: PIRLS 2021 Countries and Benchmarking Participants Exhibit 1: PIRLS 2021 Countries and Benchmarking Participants The PIRLS 2021 Reading Assessment Framework Implementing the Group Adaptive Design in PIRLS 2021\n",
      "Exhibit 2: PIRLS 2021 Group Adaptive Assessment Design Exhibit 2: PIRLS 2021 Group Adaptive Assessment Design PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic\n",
      "Exhibit 3: Weeks of Normal Primary School Operations Affected by the COVID-19 Pandemic\n",
      "Exhibit 4: Parents’ Perceptions of Their Child’s Learning Progress During the COVID-19 Pandemic\n",
      "Exhibit 5: PIRLS 2021 Countries by Chronological Order of Data Collection Exhibit 3: Weeks of Normal Primary School Operations Affected by the COVID-19 Pandemic Exhibit 4: Parents’ Perceptions of Their Child’s Learning Progress During the COVID-19 Pandemic Exhibit 5: PIRLS 2021 Countries by Chronological Order of Data Collection Summary of Scaling the PIRLS 2021 Data Reporting the PIRLS 2021 Achievement Results Reporting the PIRLS 2021 Context Questionnaire Data Quality Assurance Countries’ Reading Achievement Impacts of Modifying the Assessment Schedule on Students’ Achievement Average Reading Achievement and Scale Score Distributions\n",
      "Exhibit 1.1: Average Reading Achievement and Scale Score Distributions – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 1.2: Significance of Differences Between Countries’ Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 1.3: Average Reading Achievement and Scale Score Distributions – Includes Countries with Delayed Assessment Exhibit 1.1: Average Reading Achievement and Scale Score Distributions – Assessed Fourth Grade Students at the End of the School Year Exhibit 1.2: Significance of Differences Between Countries’ Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year Exhibit 1.3: Average Reading Achievement and Scale Score Distributions – Includes Countries with Delayed Assessment Average Reading Achievement by Gender\n",
      "Exhibit 1.4: Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 1.5: Average Reading Achievement by Gender – Includes Countries with Delayed Assessment Exhibit 1.4: Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year Exhibit 1.5: Average Reading Achievement by Gender – Includes Countries with Delayed Assessment Trends in Reading Achievement Trends in Average Reading Achievement\n",
      "Exhibit 2.1.1: Trend Plots of Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 2.1.2: Differences in Average Reading Achievement Across Assessment Years – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 2.2.1: Differences in Average Reading Achievement Across Assessment Years – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade\n",
      "Exhibit 2.2.2: Differences in Average Reading Achievement Across Assessment Years – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade Exhibit 2.1.1: Trend Plots of Average Reading Achievement – Assessed Fourth Grade Students at the End of the School Year Exhibit 2.1.2: Differences in Average Reading Achievement Across Assessment Years – Assessed Fourth Grade Students at the End of the School Year Exhibit 2.2.1: Differences in Average Reading Achievement Across Assessment Years – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade Exhibit 2.2.2: Differences in Average Reading Achievement Across Assessment Years – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade Trends in Average Achievement by Gender\n",
      "Exhibit 2.3: Trend Plots of Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 2.4: Trend Plots of Average Reading Achievement by Gender – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade Exhibit 2.3: Trend Plots of Average Reading Achievement by Gender – Assessed Fourth Grade Students at the End of the School Year Exhibit 2.4: Trend Plots of Average Reading Achievement by Gender – Delayed Assessment of Fourth Grade Cohort at the Beginning of Fifth Grade Relative Achievement in Reading Purposes and Comprehension Processes Relative Achievement in Reading Purposes\n",
      "Exhibit 3.1: Relative Average Achievement in Reading Purposes – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 3.2: Relative Average Achievement in Reading Purposes – Includes Countries with Delayed Assessment Exhibit 3.1: Relative Average Achievement in Reading Purposes – Assessed Fourth Grade Students at the End of the School Year Exhibit 3.2: Relative Average Achievement in Reading Purposes – Includes Countries with Delayed Assessment Relative Achievement in Comprehension Processes\n",
      "Exhibit 3.3: Relative Average Achievement in Comprehension Processes – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 3.4: Relative Average Achievement in Comprehension Processes – Includes Countries with Delayed Assessment Exhibit 3.3: Relative Average Achievement in Comprehension Processes – Assessed Fourth Grade Students at the End of the School Year Exhibit 3.4: Relative Average Achievement in Comprehension Processes – Includes Countries with Delayed Assessment Performance at International Benchmarks Descriptions of the PIRLS 2021 Texts Descriptions of Reading Achievement at the PIRLS 2021 International Benchmarks Percentages of Students Reaching the International Benchmarks\n",
      "Exhibit 4.1: Percentages of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 4.2: Percentages of Students Reaching the PIRLS International Benchmarks – Includes Countries with Delayed Assessment Exhibit 4.1: Percentages of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year Exhibit 4.2: Percentages of Students Reaching the PIRLS International Benchmarks – Includes Countries with Delayed Assessment Trends in the Distributions of Achievement at the International Benchmarks \n",
      "Exhibit 4.3: Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year\n",
      "Exhibit 4.4: Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year Exhibit 4.3: Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year Exhibit 4.4: Trends in the Distribution of Students Reaching the PIRLS International Benchmarks – Assessed Fourth Grade Students at the End of the School Year Home Environment Support Home Socioeconomic Status\n",
      "Exhibit 5.1: Home Socioeconomic Status Exhibit 5.1: Home Socioeconomic Status Home Early Literacy Activities Before Primary School\n",
      "Exhibit 5.2: Home Early Literacy Activities Before Primary School Exhibit 5.2: Home Early Literacy Activities Before Primary School Parents Like Reading\n",
      "Exhibit 5.3: Parents Like Reading Exhibit 5.3: Parents Like Reading Could Do Early Literacy Tasks When Beginning Primary School\n",
      "Exhibit 5.4: Could Do Early Literacy Tasks When Beginning Primary School Exhibit 5.4: Could Do Early Literacy Tasks When Beginning Primary School School Composition, Resources, and Climate Socioeconomic Background of the Student Body\n",
      "Exhibit 6.1: Socioeconomic Background of the Student Body Exhibit 6.1: Socioeconomic Background of the Student Body Students Begin Primary Grades with Literacy Skills\n",
      "Exhibit 6.2: Schools Where Students Begin Primary Grades with Literacy Skills Exhibit 6.2: Schools Where Students Begin Primary Grades with Literacy Skills Instruction Affected by Resource Shortages\n",
      "Exhibit 6.3: Instruction Affected by Reading Resource Shortages Exhibit 6.3: Instruction Affected by Reading Resource Shortages School Emphasis on Academic Success\n",
      "Exhibit 6.4: School Emphasis on Academic Success – Principals’ Reports Exhibit 6.4: School Emphasis on Academic Success – Principals’ Reports School Discipline\n",
      "Exhibit 6.5: School Discipline – Principals’ Reports Exhibit 6.5: School Discipline – Principals’ Reports Students’ Reading Attitudes and Behaviors Students Like Reading\n",
      "Exhibit 7.1: Students Like Reading\n",
      "Exhibit 7.2: Students Like Reading by Gender Exhibit 7.1: Students Like Reading Exhibit 7.2: Students Like Reading by Gender Students Confident in Reading\n",
      "Exhibit 7.3: Students Confident in Reading\n",
      "Exhibit 7.4: Students Confident in Reading by Gender Exhibit 7.3: Students Confident in Reading Exhibit 7.4: Students Confident in Reading by Gender Students Use Digital Devices to Find and Read Information\n",
      "Exhibit 7.5: Students Use Digital Devices to Find and Read Information\n",
      "Exhibit 7.6: Students Use Digital Devices to Find and Read Information by Gender Exhibit 7.5: Students Use Digital Devices to Find and Read Information Exhibit 7.6: Students Use Digital Devices to Find and Read Information by Gender Appendices Appendix A: Population Coverage and Sample Participation Rates\n",
      "Exhibit A.1: Information About the Students Assessed in PIRLS 2021\n",
      "Exhibit A.2: Coverage of PIRLS 2021 Target Population\n",
      "Exhibit A.3: School Sample Sizes\n",
      "Exhibit A.4: Student Sample Sizes\n",
      "Exhibit A.5: Participation Rates (Weighted)\n",
      "Exhibit A.6: Trends in Student Populations Exhibit A.1: Information About the Students Assessed in PIRLS 2021 Exhibit A.2: Coverage of PIRLS 2021 Target Population Exhibit A.3: School Sample Sizes Exhibit A.4: Student Sample Sizes Exhibit A.5: Participation Rates (Weighted) Exhibit A.6: Trends in Student Populations Appendix B: Percentiles and Standard Deviations of Reading Achievement\n",
      "Exhibit B.1: Percentiles of Reading Achievement\n",
      "Exhibit B.2: Standard Deviations of Reading Achievement Exhibit B.1: Percentiles of Reading Achievement Exhibit B.2: Standard Deviations of Reading Achievement Appendix C: Organizations and Individuals Responsible for PIRLS 2021\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n",
      "Found subpage: https://doi.org/10.6017/lse.tpisc.tr2103.kb5342\n",
      "Text: \n",
      "\t\tMain Navigation\t Home About\n",
      "\n",
      "About the Center\n",
      "Staff\n",
      "Graduate Students\n",
      "News\n",
      "Contact\n",
      "\n",
      " About the Center Staff Graduate Students News Contact TIMSS\n",
      "\n",
      "2023\n",
      "2019\n",
      "2015\n",
      "2011\n",
      "2007\n",
      "2003\n",
      "1999\n",
      "1995\n",
      "ADVANCED\n",
      "2015\n",
      "2008\n",
      "1995\n",
      "\n",
      " 2023 2019 2015 2011 2007 2003 1999 1995 ADVANCED 2015 2008 1995 PIRLS\n",
      "\n",
      "2026\n",
      "2021\n",
      "2016\n",
      "2011\n",
      "2006\n",
      "2001\n",
      "\n",
      " 2026 2021 2016 2011 2006 2001 Other Projects\n",
      "\n",
      "LaNA Special Administration 2023\n",
      "Rosetta Stone 2019 – PASEC\n",
      "Rosetta Stone 2019 – ERCE\n",
      "\n",
      " LaNA Special Administration 2023 Rosetta Stone 2019 – PASEC Rosetta Stone 2019 – ERCE Publications Databases IEA \n",
      "\n",
      " PIRLS 2021 Home Assessment Frameworks Encyclopedia Introduction Curriculum Questionnaire Exhibits Country Chapters Download Center PIRLS 2021 International Results\n",
      " Methods & Procedures Context Questionnaires International Database PIRLS 2021 International Results in Reading – About PIRLS 2021 PIRLS 2021 International Results in Reading “PIRLS 2021 provides the only internationally comparative fourth grade achievement results collected during the COVID-19 pandemic“ Selected Results from PIRLS 2021 About PIRLS 2021 Successfully conducted in 57 countries and eight benchmarking entities, PIRLS 2021 differs from previous PIRLS assessments in several ways. First, a substantial creative effort was focused on transitioning PIRLS 2021 to an innovative digital assessment with 23 colorful and engaging texts delivered to students using a new group adaptive design. Second, PIRLS 2021 data collection occurred over two years during the unprecedented COVID-19 pandemic. Although collecting data in schools faced many disruptions, most countries met the standards for high-quality data collection. This tremendous effort resulted in PIRLS 2021 providing the only internationally comparative fourth grade achievement results collected during the pandemic. Download Section Overview of PIRLS IEA’s PIRLS (Progress in International Reading Literacy Study) is an ongoing international assessment program of students’ reading achievement in their fourth year of schooling—an important transition point in their development as readers. By this time in their education, students typically have learned how to read and are now reading to learn. Conducted every five years since 2001, PIRLS is recognized as the global standard for assessing trends in reading achievement at the fourth grade. PIRLS 2021 was the fifth assessment cycle, providing 20 years of trend results. PIRLS and TIMSS are directed by IEA’s TIMSS & PIRLS International Study Center at Boston College in close cooperation with the IEA Amsterdam and IEA Hamburg offices. IEA is an independent international cooperative of national research institutions and government agencies that pioneered international assessments of student achievement in the 1960s to gain a deeper understanding of policy effects across countries’ different education systems. IEA has been conducting international assessments of reading literacy and the factors associated with proficient reading comprehension in countries around the world for about 60 years. Transitioning to Digital Assessment in PIRLS 2021 While ensuring a solid basis for trend comparisons over time, PIRLS continuously evolves with each cycle by capitalizing on advances in technology and measurement methodology to improve the assessments. Simultaneously, PIRLS pioneers new approaches to reading assessment as the internet’s ever-increasing pace of information growth constantly changes the nature of reading comprehension to encompass new online reading literacy skills. PIRLS 2021 incorporated two major advances in international reading assessment at the fourth grade: Transitioned to digital assessment (discussed here) Implemented a group adaptive design (see later section Implementing the Group Adaptive Design in PIRLS 2021). In a digital assessment, measurement can be improved through more engaging and interactive assessment materials and procedures. Aside from the advantages of a more interactive assessment, activities related to operational procedures (e.g., the digital equivalents of printing and sending materials to schools) can be accomplished with even greater consistency and efficiency once the move to digital assessments has been accomplished. PIRLS 2021 developed a state-of-the-art user interface for the digital assessment where students can freely navigate through the texts and activate a panel that presents the items (see The Amazing Octopus and The Empty Pot). In addition to incorporating texts with interactive features, the digital assessment included innovative ePIRLS tasks (see Oceans) as a continuation of the groundbreaking work begun in 2016 to assess reading comprehension in a simulated online environment. The PIRLS 2021 digital assessment systems included capabilities for text and item translation and localization, test delivery (formerly printing), administration to students, and data delivery for scoring. In PIRLS 2021, 26 countries and 7 benchmarking entities transitioned to digital assessment as their primary mode of data collection, while also administering the paper-based trend texts replicated from PIRLS 2016 to a “bridge” sample. The United States administered the PIRLS 2021 digital assessment and the PIRLS 2021 paper bridge assessment. The United States opted to report the paper bridge scores. The other 31 countries and 1 benchmarking entity continued to administer the full assessment using paper booklets. Exhibit 1 provides a list of the PIRLS 2021 participants and indicates whether their results are based on digital or paper data. Altogether, there were 57 countries in PIRLS 2021, including some distinct education systems within countries that have always participated separately throughout IEA’s long history (e.g., the French- and Dutch-speaking parts of Belgium as well as Hong Kong SAR). In addition, PIRLS 2021 included 8 benchmarking participants, mainly regions of countries that also participated in PIRLS. View Fullscreen PDF Download Excel Download PDF The PIRLS 2021 Reading Assessment Framework PIRLS 2021 assessed reading comprehension in accordance with the PIRLS 2021 Reading Assessment Framework (Chapter 1 in PIRLS 2021 Assessment Frameworks). The PIRLS reading assessment framework has been updated with each cycle to keep reading research and education developments at the forefront through reviews by the PIRLS Reading Development Group (RDG) and the National Research Coordinators (NRCs). This maintains PIRLS’ relevance and importance for teaching practice and policy. However, PIRLS is a trend study and the framework’s underlying organization has remained consistent across cycles. The framework is organized around two overarching purposes for reading: reading for literary experience and reading to acquire and use information. The framework also includes four cross-cutting reading comprehension processes: focus on and retrieve explicitly stated information, make straightforward inferences, interpret and integrate ideas and information, and evaluate and critique content and textual elements. The PIRLS 2021 Reading Assessment Framework provides information that emphasizes the growing importance of ePIRLS, the world leading assessment of online reading that was successfully launched in 14 countries in 2016 (see ePIRLS 2016 International Results in Online Informational Reading). In the ePIRLS tasks, a teacher avatar guides the students through several simulated multi-modal websites with multiple texts and interactive features to complete school-like assignments about social studies or science topics. Implementing the Group Adaptive Design in PIRLS 2021 The PIRLS 2021 group adaptive design provides better measurement through better alignment across countries between the assessment difficulty and the students’ levels of reading achievement. The group adaptive design is based on texts and items of three levels of difficulty—difficult, medium, and easy—that are combined into booklets of two difficulty levels (see Chapter 3 of the PIRLS 2021 Assessment Frameworks). The more difficult booklets include difficult and medium texts and items, and the less difficult booklets include easy and medium texts and items. All booklets are administered in each country, but countries whose students have higher reading achievement on average may give the more difficult booklets to a higher percentage of students (70%), and countries whose students have lower average reading achievement may give a higher percentage of their students the less difficult booklets. Transitioning to the PIRLS 2021 group adaptive design from PIRLS 2016 was a great success because trend blocks could be categorized as easy, medium, or difficult blocks based on data from 2016. The PIRLS 2016 design linked PIRLS blocks of passages and items with less difficult PIRLS Literacy blocks through blocks common to both assessments (see Chapter 3 of PIRLS 2016 Assessment Frameworks). For 2021, PIRLS Literacy blocks contributed content at the “easy” level, the blocks common to both PIRLS and PIRLS Literacy contributed content at the “medium” level, and the PIRLS blocks contributed content at the “difficult” level. Including the newly developed blocks for 2021, the group adaptive design in PIRLS 2021 led to a lower item non-response rate and more precise achievement estimates than the non-adaptive design in PIRLS 2016 (see Chapter 9 in Methods and Procedures: PIRLS 2021 Technical Report). Providing comprehensive coverage of the PIRLS 2021 Reading Assessment Framework and implementing the group adaptive design resulted in the most comprehensive and complex international reading assessment to date, consisting of 18 text and item sets as well as 5 ePIRLS tasks. Exhibit 2 shows the PIRLS 2021 group adaptive design for the 18 text and item sets, where 9 text and item sets assessed the literary reading purpose, and 9 text and item sets assessed the informational reading purpose. In accordance with the group adaptive design, within the 9 text and item sets for each purpose, 3 text and item sets were difficult, 3 were medium, and 3 were easy. View Fullscreen PDF Download Excel Download PDF Developing the new text and item sets for the PIRLS 2021 assessment was a considerable effort. Six new text and item sets were needed to complete the new group adaptive design requirements. To ensure all target levels were successfully met, twice as many—12 text and items sets—were developed for the field test. Also, two ePIRLS tasks were published on the PIRLS 2016 website, so two new tasks for PIRLS 2021 were developed to replace them. The field test development took nearly two years, including two RDG meetings and three NRC meetings, with one of the NRC meetings specifically devoted to item development. At the NRC item development meeting hosted by Chinese Taipei, 126 representatives from 43 countries drafted more than 600 items. Despite the initial emergence of COVID-19 in 2020 at the time scheduled for the field test, more than half the countries were able to collect field test data. Therefore, following the field test, the field test data were analyzed, PIRLS 2021 materials were selected, finalized, and assembled, and the countries continued preparations for the PIRLS 2021 main data collection. PIRLS 2021 Data Collection Successful Despite Disruptions by the COVID-19 Pandemic PIRLS 2021 is the only international assessment of educational achievement that successfully collected data during COVID-19’s disruption in students’ schooling. Consequently, the PIRLS 2021 International Database provides an extremely rich and valuable data source to research the impact of COVID-19 on teaching and learning reading. Similar to previous PIRLS assessments, to prepare for PIRLS 2021, the TIMSS & PIRLS International Study Center, IEA Hamburg, and Statistics Canada worked to select a carefully designed random sample of schools within each country and trained countries in data collection procedures designed to yield high quality data. However, as it is well known, many schools around the world faced considerable disruptions to their operations due to COVID-19, with a good number shifting to remote learning or reduced classroom sizes. Even school buildings that remained open often adopted special procedures and often reduced access to prevent the spread of COVID-19. PIRLS adapted rapidly to the situation and included context questionnaire items specifically targeted to collect information about the challenges faced by the PIRLS 2021 schools and students during COVID-19. The PIRLS 2021 Context Questionnaires can be accessed on the PIRLS 2021 website. Also, the PIRLS 2021 Encyclopedia, which includes a chapter authored by each country describing its reading education, provides information from most countries about how COVID-19 interrupted teaching and learning. School Operations At the time of the PIRLS 2021 data collection, there was considerable variation across countries in how primary school operations were affected by the COVID-19 pandemic, with some countries still experiencing school closures and others modifying how they provided in-person instruction. Exhibit 3 shows the percentages of students in the PIRLS 2021 countries by the number of weeks their principals reported that normal primary school operations were affected by the COVID-19 pandemic. Because principals in the countries with delayed assessments (see Exhibit 5) needed to recall what happened six months previously in the prior 2020-2021 school year to answer the question, the rows for those countries are colored pink. This color coding to distinguish the results based on delayed data collection is also used in subsequent exhibits.\n",
      " \n",
      "Exhibit 3\n",
      " \n",
      "About the Item\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF On average, across countries, only 14 percent of the fourth grade students attended schools where normal operations were “not affected” by the COVID-19 pandemic during the 2020-2021 school year. In contrast, 47 percent attended schools where normal operations were affected by the COVID-19 pandemic for “more than 8 weeks” of instruction. The remaining students experienced more moderate disruptions; 10 percent of students attended schools where “less than 2 weeks” of instruction were affected by the COVID-19 pandemic, 15 percent where “2 to 4 weeks” of instruction were affected, and 13 percent where “5 to 8 weeks” of instruction were affected. Parents’ Perceptions Exhibit 4 shows parents’ reports of whether or not their child stayed home from school because of the COVID-19 pandemic and their perceptions of the pandemic’s effect on their child’s learning progress. Information was collected using two items in the PIRLS 2021 Home Questionnaire (see “About the Items”). If parents reported that their child did not stay home from school because of the COVID-19 pandemic, they were not asked to respond to the item about perceptions of their child’s learning progress. Internationally, parents of most students (86%) reported that their child stayed home from school because of the COVID-19 pandemic, with the rest reporting their child did not stay home due to the pandemic (14%) and consequently not being asked any further questions. Across countries, on average, parents of two-thirds of the students (67%) reported that their child stayed home and that their child’s learning progress was adversely affected by the pandemic—either “a lot” (22%) or “somewhat” (45%). Parents of 19 percent of the students reported that their child stayed home from school because of the COVID-19 pandemic, but their child’s learning progress was “not at all” affected. \n",
      "Exhibit 4\n",
      " \n",
      "About the Items\n",
      " View Fullscreen PDF Download Excel Download PDF View Fullscreen PDF Download Excel Download PDF Despite the many challenges of conducting a school-based assessment during the COVID-19 pandemic, countries remained committed to participating in PIRLS 2021. Due to the tremendous efforts from all involved, the PIRLS 2021 countries overcame a variety of obstacles to ensure that students could take the PIRLS 2021 assessment. In all, PIRLS 2021 assessed nearly 400,000 students. As shown in Exhibit 5, most of the countries managed to collect data towards the end of students’ fourth year of schooling according to the original PIRLS 2021 schedule, which was October to December 2020 for Southern Hemisphere countries and February to July 2021 for Northern Hemisphere countries. However, some Northern Hemisphere countries had to delay assessing the cohort of fourth grade students until the beginning of the fifth grade (September to December 2021) and some countries assessed their fourth grade students one year later than originally scheduled (August to December 2021 for the Southern Hemisphere and April to July 2022 for the Northern Hemisphere).\n",
      " Across the data collection dates, most of the countries assessed fourth grade students toward the end of the school year. The exception is the 14 Northern Hemisphere countries that necessarily had to delay testing and assessed students at the beginning of the fifth grade. For the most part, the students were from the same schools that had been selected for PIRLS 2021, but because of the delay over the summer months the students were 6 months older on average than their PIRLS 2016 counterparts (see later section on Reporting the PIRLS 2021 Achievement Results). View Fullscreen PDF Download Excel Download PDF Numbers of Students Assessed Nationally representative random samples of approximately 4,000 students from 150 to 200 schools participated in PIRLS 2021. PIRLS 2021 collected data from about 400,000 students, 380,000 parents, 20,000 teachers, and 13,000 schools. A rigorous sampling adjudication provided documentation that almost all the countries met all sampling standards. Of the 57 countries and 8 benchmarking participants, nearly all the countries met the guidelines for coverage of the target population and most met the standards for low exclusion rates (less than 5%). Almost all the countries met or exceeded the school and student participation rate requirements, with only 7 needing to rely on replacement schools to reach the requirement and 4 falling short of the requirements. In summary, the PIRLS 2021 data are of high quality. It can be said that the pandemic affected almost all countries to some extent, and no assessment can provide data on how students would have performed without COVID-19 affecting schools. No assessment, including PIRLS 2021, can be designed to measure the effects of the COVID-19 pandemic on student achievement and to compare achievement with and without the pandemic. However, PIRLS 2021 provides a unique data source for studying students’ reading achievement and learning experiences around the world during the pandemic. Summary of Scaling the PIRLS 2021 Data For more detailed information about scaling the PIRLS 2021 achievement data and links to other references about the methodology, see Chapter 10 (methodology) and Chapter 11 (implementation) in Methods and Procedures: PIRLS 2021 Technical Report. PIRLS has used well-established psychometric scaling approaches to derive achievement distributions and transform the assessment results of each PIRLS data collection to the PIRLS trend scale. Among these methods, linear scale transformations and linking designs using randomly equivalent samples have been used extensively in past PIRLS cycles for analysis and reporting (described in Chapter 10 of Methods and Procedures: PIRLS 2021 Technical Report). With the transition to the digital environment in PIRLS 2021, it was necessary to adapt analytic procedures and data collection designs to accommodate the change from paper-and-pencil to digital assessment. Accordingly, countries that administered the PIRLS digital assessment implemented a data collection design that involved two student samples: the main sample of about 4,500 students and a second equivalent but smaller “bridge” sample (about 1,500 students). Students in the main sample took the 2021 digital assessment, while the bridge sample was administered the PIRLS 2021 trend items in the PIRLS 2016 paper format. This resulted in equivalent samples of students in each country responding to the trend items in the paper and digital formats, which enabled bridging the trend scale from paper-based PIRLS 2016 to digitally-based PIRLS in 2021. Although the bridge samples were smaller than the digital samples, often the students were in the same schools as those who took the digital assessments. The bridge samples were adjudicated as part of the same process used for all PIRLS 2021 countries and were judged to be the same quality as their digital counterparts. To ensure that the paper-based and digitally-based assessment results will be reported on the PIRLS trend scale, scaling the PIRLS 2021 data involved the following three steps. First, the usual concurrent calibration approach (described in Chapter 11 of Methods and Procedures: PIRLS 2021 Technical Report) was applied to the paper-based data from PIRLS 2016 and PIRLS 2021, ensuring that the PIRLS 2021 paper data was linked to the PIRLS trend scale. This procedure included all the data from trend countries that administered the paper-based PIRLS 2021 assessment as well as the paper-based bridge data from the digital countries. Second, the digital assessment data from the digital countries was linked to the PIRLS trend scale through population-based linking, which capitalizes on the availability of equivalent samples from the same populations between the digital and bridge samples. Finally, the data from the digital countries, including data from the ePIRLS items, were scaled together to link the ePIRLS data to the PIRLS achievement scale. Reporting the PIRLS 2021 Achievement Results Reading achievement results are included in PIRLS 2021 International Results in Reading for all 57 countries and 8 benchmarking entities that participated in PIRLS 2021. Concerns about the comparability of the data resulting from COVID-19 school disruptions and delayed testing complicated reporting the PIRLS 2021 results. PIRLS and TIMSS have built a reputation for reporting high quality data, but not all data collected meet the expected guidelines. In such cases, PIRLS and TIMSS use annotations to identify results based on data that for some reason fell short of meeting the expected guidelines. The goal is to be clear about issues while still reporting countries’ data. See discussion “Impacts of Modifying the Assessment Schedule on Students’ Achievement” in Countries’ Reading Achievement. The achievement results for all countries that assessed fourth grade students at the end of the school year are presented according to average achievement in Exhibit 1.1, with the countries that assessed the fourth grade students one year later annotated. Exhibit 1.1 is followed by Exhibit 1.2, which has guidelines for determining significant differences in average reading achievement between the Exhibit 1.1 countries. Exhibit 1.3 includes all the countries presented according to average achievement, with the delayed assessment countries that assessed the fourth grade cohort at the beginning of the fifth grade highlighted in pink. While PIRLS cannot determine cause and effects, in general there are downward trends in PIRLS 2021 that likely are evidence of the assessment taking place during the COVID-19 pandemic. Because the pandemic was unprecedented in the history of PIRLS trend assessments, the trends between 2016 and 2021 are shown with dotted lines. This should alert researchers that care should be taken when interpreting the PIRLS 2021 results. Similar to the approach used for the PIRLS 2021 achievement data, the trend results for the countries that assessed fourth grade students are in one exhibit, with the “one year later countries” clearly annotated as having a 6-year trend instead of a 5-year trend between 2016 and 2021. Trend results for the countries with delayed assessments at the fifth grade need to be interpreted with great care due to the age difference and are shown in a separate exhibit. Reporting the PIRLS 2021 Context Questionnaire Data The PIRLS 2021 Context Questionnaire Framework (see Chapter 2 of PIRLS 2021 Assessment Frameworks) describes the topics covered by the PIRLS 2021 Context Questionnaires. PIRLS 2021 collected extensive data about the contexts for teaching and learning reading through questionnaires administered to students, their parents, teachers, and school principals. The impact of COVID-19 on the PIRLS 2021 Context Questionnaire data is challenging to evaluate, but PIRLS 2021 did collect a considerable amount of valuable information on multiple levels. The school questionnaire results were only slightly impacted in the countries that delayed assessment to the fifth grade, because most schools had both fourth and fifth grades and the principals were asked to keep the fourth grade and the prior school year (2020–2021) in mind. The delayed assessments had the most impact on the teacher questionnaire data at the fifth grade. However, most countries tried to contact the teachers of the students from the fourth grade and asked teachers to keep the prior school year (2020–2021) in mind when responding to the questionnaire. The TIMSS & PIRLS International Study Center conducted a series of analyses to establish that there was little or no difference in the responses to the Context Questionnaires between the bulk of the PIRLS 2021 countries that assessed students at the end of fourth grade and the countries with delayed testing of the fourth grade cohort at the beginning of fifth grade. PIRLS 2021 International Results in Reading includes results for all countries for selected items in the school, home, and student questionnaires (countries with delayed assessments of students in the fifth grade are highlighted in pink). Although COVID-19 impacted data collection, resulting in less questionnaire data included here than in previous assessment cycles, all of the PIRLS 2021 Context Questionnaire data are included in the PIRLS 2021 International Database. Quality Assurance Despite the challenges that the COVID-19 pandemic introduced for schools and national research centers responsible for implementing PIRLS 2021, every effort was made to attend to the quality and comparability of the data through careful planning and documentation, cooperation among participating countries, standardized procedures, and rigorous attention to quality control throughout. The assessments were administered to nationally representative and well-documented probability samples of students in each country. Staff from Statistics Canada and IEA Hamburg worked with NRCs on all phases of sampling activities to ensure compliance with sampling and participation requirements, with a few exceptions from compliance annotated in the data exhibits. IEA Amsterdam worked with the TIMSS & PIRLS International Study Center to manage an extensive series of verification checks to ensure the comparability of translations of the assessment items and questionnaires and to conduct the International Quality Assurance Program of school visits to monitor and report on the administration of the assessment. Together with the TIMSS & PIRLS International Study Center, IEA Hamburg staff worked closely with NRCs to organize data collection operations and to check all data for accuracy and consistency within and across countries. The extensive efforts to maintain PIRLS’ quality standards during the COVID-19 pandemic were largely successful. Complete documentation of the many technical activities required to conduct PIRLS 2021 is provided in the Methods and Procedures: PIRLS 2021 Technical Report documentation. The volume includes detailed information about the processes used to develop and implement the PIRLS 2021 assessments, including sampling, translation verification, data collection, scaling, linking, and data analysis. \n",
      "About PIRLS 2021\n",
      " \n",
      "Overview of PIRLS\n",
      " \n",
      "Transitioning to Digital Assessment in PIRLS 2021\n",
      " \n",
      "The PIRLS 2021 Reading Assessment Framework\n",
      " \n",
      "Implementing the Group Adaptive Design in PIRLS 2021\n",
      " \n",
      "PIRLS 2021 Data Collection Was Successful Despite Disruptions by the COVID-19 Pandemic\n",
      " \n",
      "Numbers of Students Assessed\n",
      " \n",
      "Summary of Scaling the PIRLS 2021 Data\n",
      " \n",
      "Reporting the PIRLS 2021 Achievement Results\n",
      " \n",
      "Reporting the PIRLS 2021 Context Questionnaire Data\n",
      " \n",
      "Quality Assurance\n",
      " Related Links Appendices Download Center Contents Suggested Citation Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., & Wry, E. (2023). PIRLS 2021 International Results in Reading. Boston College, TIMSS & PIRLS International Study Center. https://doi.org/10.6017/lse.tpisc.tr2103.kb5342 ISBN: 978-1-889938-67-7 Library of Congress Catalog Card Number: 2023906665  Please read our Copyright Notice and Disclaimer » TIMSS & PIRLS International Study Center\n",
      " 188 Beacon St., Chestnut Hill, MA 02467, USA\n",
      "                  Tel +1-617-552-1600\n",
      "                  Fax +1-617-552-1203 © 2023 TIMSS & PIRLS International Study Center, Lynch School of Education and Human Development, Boston College, and\n",
      "        International Association for the Evaluation of Educational Achievement. All rights reserved....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "url = \"https://pirls2021.org/results\"\n",
    "query = \"COVID-19\"\n",
    "results = read_text_from_website(url, query)\n",
    "for text, link in results:\n",
    "    print(f\"Found subpage: {link}\\nText: {text}...\\n\")  # Print first 200 characters for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc32d58-1500-4fbc-883b-fb9f05ecfecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
